{
  "master": {
    "tasks": [
      {
        "id": "1",
        "title": "Configurazione shadcn-svelte e Sistema UI Base",
        "description": "Installare e configurare shadcn-svelte come libreria UI principale, insieme ai componenti fondamentali per l'interfaccia dell'applicazione.",
        "details": "1. Eseguire `npx shadcn-svelte@latest init` per inizializzare shadcn-svelte\n2. Configurare il file `components.json` con le preferenze di stile (default, new-york)\n3. Installare i componenti base: button, card, dialog, input, form, toast, dropdown-menu, tabs\n4. Creare la struttura delle cartelle: `src/lib/components/ui/` per componenti shadcn\n5. Configurare il tema dark/light mode con CSS variables\n6. Creare un layout base con sidebar navigation in `src/routes/+layout.svelte`\n7. Implementare le route base: dashboard (#/), brands (#/brands), extract (#/extract), edit (#/edit), publish (#/publish), settings (#/settings)\n\nPseudo-codice per layout:\n```svelte\n<script>\n  import { page } from '$app/stores';\n  const routes = [\n    { path: '#/', label: 'Dashboard', icon: 'home' },\n    { path: '#/extract', label: 'Estrai', icon: 'image' },\n    // ...\n  ];\n</script>\n<div class=\"flex h-screen\">\n  <aside class=\"w-64 border-r\">\n    {#each routes as route}\n      <a href={route.path} class:active={$page.url.hash === route.path}>{route.label}</a>\n    {/each}\n  </aside>\n  <main class=\"flex-1\"><slot /></main>\n</div>\n```",
        "testStrategy": "Test unitari per verificare il rendering dei componenti shadcn. Test di navigazione per assicurarsi che tutte le route funzionino correttamente con hash routing. Verificare che il tema dark/light switch funzioni.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": "1",
            "title": "Inizializzazione shadcn-svelte con Risoluzione Conflitti TailwindCSS v4",
            "description": "Inizializzare shadcn-svelte nel progetto gestendo la compatibilità con TailwindCSS v4 e Svelte 5 runes. Configurare components.json con le preferenze di stile e risolvere eventuali conflitti di configurazione.",
            "dependencies": [],
            "details": "1. Verificare la compatibilità di shadcn-svelte con TailwindCSS v4 (attualmente usa la sintassi @import 'tailwindcss' e @plugin)\n2. Eseguire `npx shadcn-svelte@latest init` e selezionare le opzioni appropriate\n3. Configurare components.json scegliendo lo stile (default/new-york), colori, e percorso componenti ($lib/components/ui)\n4. Se shadcn-svelte richiede TailwindCSS v3, valutare: a) downgrade a v3, b) configurazione manuale delle CSS variables\n5. Aggiornare app.css per includere le variabili CSS di shadcn mantenendo la sintassi v4\n6. Creare la struttura cartelle: src/lib/components/ui/ e src/lib/components/custom/\n7. Verificare che vite.config.ts e svelte.config.js siano configurati correttamente\n8. Testare che il build funzioni senza errori con `npm run check`",
            "status": "done",
            "testStrategy": "Eseguire `npm run check` per verificare assenza errori TypeScript. Verificare che la build vite funzioni con `npm run start`. Controllare che le CSS variables siano caricate correttamente ispezionando il DOM nel browser.",
            "parentId": "1",
            "updatedAt": "2026-01-06T21:35:02.912Z"
          },
          {
            "id": "2",
            "title": "Installazione Componenti Base shadcn-svelte",
            "description": "Installare tutti i componenti UI fondamentali richiesti: button, card, dialog, input, form, toast, dropdown-menu, tabs usando il CLI di shadcn-svelte.",
            "dependencies": [
              1
            ],
            "details": "1. Installare i componenti uno alla volta per gestire eventuali errori:\n   - `npx shadcn-svelte@latest add button`\n   - `npx shadcn-svelte@latest add card`\n   - `npx shadcn-svelte@latest add dialog`\n   - `npx shadcn-svelte@latest add input`\n   - `npx shadcn-svelte@latest add form`\n   - `npx shadcn-svelte@latest add toast` (include sonner o toaster)\n   - `npx shadcn-svelte@latest add dropdown-menu`\n   - `npx shadcn-svelte@latest add tabs`\n2. Installare dipendenze aggiuntive se richieste (bits-ui, formsnap, sveltekit-superforms per form)\n3. Verificare che tutti i componenti siano stati creati in src/lib/components/ui/\n4. Creare un file index.ts in src/lib/components/ui/ per re-export centralizzato\n5. Installare lucide-svelte per le icone: `npm install lucide-svelte`\n6. Testare l'import di ogni componente in +page.svelte temporaneamente",
            "status": "done",
            "testStrategy": "Creare una pagina test temporanea che importa e renderizza tutti i componenti. Verificare che ogni componente sia visibile e styled correttamente. Eseguire `npm run check` per confermare assenza errori di tipo.",
            "parentId": "1",
            "updatedAt": "2026-01-06T21:36:41.167Z"
          },
          {
            "id": "3",
            "title": "Configurazione Sistema Tema Dark/Light con CSS Variables e Toggle",
            "description": "Implementare un sistema completo di theming dark/light mode usando CSS variables, persistenza locale, e un componente toggle accessibile.",
            "dependencies": [
              1
            ],
            "details": "1. Estendere app.css con le CSS variables per entrambi i temi:\n   ```css\n   :root {\n     --background: 0 0% 100%;\n     --foreground: 222.2 84% 4.9%;\n     /* ... altre variabili shadcn */\n   }\n   .dark {\n     --background: 222.2 84% 4.9%;\n     --foreground: 210 40% 98%;\n   }\n   ```\n2. Creare src/lib/stores/theme.svelte.ts con Svelte 5 runes:\n   ```typescript\n   let theme = $state<'light' | 'dark'>('light');\n   export function toggleTheme() { ... }\n   export function getTheme() { return theme; }\n   ```\n3. Implementare persistenza in localStorage e rispetto di prefers-color-scheme\n4. Creare src/lib/components/custom/ThemeToggle.svelte con icone sun/moon\n5. Aggiungere script in app.html per prevenire flash of unstyled content (FOUC)\n6. Applicare classe 'dark' al tag html in base alla preferenza",
            "status": "done",
            "testStrategy": "Verificare che il toggle cambi effettivamente il tema visivamente. Testare persistenza ricaricando la pagina. Verificare che prefers-color-scheme sia rispettato al primo caricamento. Testare accessibilità del toggle con screen reader.",
            "parentId": "1",
            "updatedAt": "2026-01-06T21:38:57.337Z"
          },
          {
            "id": "4",
            "title": "Creazione Layout Sidebar con Navigazione Responsive",
            "description": "Implementare il layout principale dell'applicazione con sidebar navigation responsive, supporto mobile con hamburger menu, e indicatore di route attiva.",
            "dependencies": [
              2,
              3
            ],
            "details": "1. Creare src/routes/+layout.svelte con struttura flex:\n   ```svelte\n   <script>\n     import { page } from '$app/stores';\n     import ThemeToggle from '$lib/components/custom/ThemeToggle.svelte';\n     import { Home, Image, Edit, Send, Settings, Menu } from 'lucide-svelte';\n     \n     const routes = [\n       { path: '/', label: 'Dashboard', icon: Home },\n       { path: '/brands', label: 'Brand', icon: Folder },\n       { path: '/extract', label: 'Estrai', icon: Image },\n       { path: '/edit', label: 'Modifica', icon: Edit },\n       { path: '/publish', label: 'Pubblica', icon: Send },\n       { path: '/settings', label: 'Impostazioni', icon: Settings },\n     ];\n     let sidebarOpen = $state(true);\n   </script>\n   ```\n2. Implementare sidebar collapsible con transizioni smooth\n3. Aggiungere responsive breakpoint: sidebar nascosta sotto 768px, visibile hamburger\n4. Creare header con logo app, breadcrumb, e ThemeToggle\n5. Stilare active state per link corrente usando $page.url.pathname\n6. Aggiungere hover e focus states accessibili\n7. Implementare Sheet/Drawer da shadcn per mobile sidebar",
            "status": "done",
            "testStrategy": "Testare navigazione cliccando tutti i link. Verificare che l'active state si aggiorni correttamente. Testare responsive ridimensionando la finestra. Verificare accessibilità keyboard navigation (Tab, Enter).",
            "parentId": "1",
            "updatedAt": "2026-01-06T21:43:41.394Z"
          },
          {
            "id": "5",
            "title": "Implementazione Sistema Hash Routing per Tutte le Route",
            "description": "Creare le pagine per tutte le route dell'applicazione (dashboard, brands, extract, edit, publish, settings) sfruttando l'hash router già configurato in svelte.config.js.",
            "dependencies": [
              4
            ],
            "details": "1. Il progetto ha già hash routing configurato in svelte.config.js (router: { type: 'hash' })\n2. Creare le cartelle route in src/routes/:\n   - src/routes/+page.svelte (Dashboard - già esistente, da aggiornare)\n   - src/routes/brands/+page.svelte\n   - src/routes/extract/+page.svelte\n   - src/routes/edit/+page.svelte\n   - src/routes/publish/+page.svelte\n   - src/routes/settings/+page.svelte\n3. Ogni pagina deve avere:\n   - Titolo h1 con nome sezione\n   - Placeholder Card shadcn con descrizione funzionalità futura\n   - Layout consistente con padding appropriato\n4. Aggiornare Dashboard (+page.svelte) con cards di overview\n5. Settings deve includere placeholder per sottosezioni (LLM Providers, API Keys, Preferences)\n6. Verificare che la navigazione hash funzioni: /#/, /#/brands, /#/extract, ecc.\n7. Aggiungere meta title dinamico per ogni pagina",
            "status": "done",
            "testStrategy": "Navigare manualmente a ogni route e verificare il rendering. Testare deep linking aprendo direttamente URL come /#/settings. Verificare che il back/forward del browser funzioni. Controllare che non ci siano errori 404 in console.",
            "parentId": "1",
            "updatedAt": "2026-01-06T21:46:43.810Z"
          }
        ],
        "tags": [
          "frontend",
          "ui-framework",
          "phase-0-foundation",
          "svelte"
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi questo task in subtask che coprono: 1) Inizializzazione shadcn-svelte con risoluzione conflitti TailwindCSS v4, 2) Installazione componenti base (button, card, dialog, input, form, toast, dropdown-menu, tabs), 3) Configurazione sistema tema dark/light con CSS variables e toggle, 4) Creazione layout sidebar con navigazione responsive, 5) Implementazione sistema hash routing per tutte le route (dashboard, brands, extract, edit, publish, settings)",
        "updatedAt": "2026-01-06T21:46:43.810Z"
      },
      {
        "id": "2",
        "title": "Sistema IPC Bridge e Gestione Sicura delle Credenziali",
        "description": "Implementare il sistema IPC tra main process e renderer, includendo un servizio keychain per la memorizzazione sicura delle API keys tramite OS keychain nativo.",
        "details": "1. Estendere `electron/preload.ts` con contextBridge per esporre API sicure:\n```typescript\nimport { contextBridge, ipcRenderer } from 'electron';\ncontextBridge.exposeInMainWorld('electronAPI', {\n  // Keychain\n  saveCredential: (service: string, account: string, password: string) => \n    ipcRenderer.invoke('keychain:save', service, account, password),\n  getCredential: (service: string, account: string) => \n    ipcRenderer.invoke('keychain:get', service, account),\n  deleteCredential: (service: string, account: string) => \n    ipcRenderer.invoke('keychain:delete', service, account),\n  // Config\n  getConfig: (key: string) => ipcRenderer.invoke('config:get', key),\n  setConfig: (key: string, value: any) => ipcRenderer.invoke('config:set', key, value),\n});\n```\n2. Creare `electron/keychain.ts` usando `keytar` per macOS keychain nativo\n3. Creare `electron/ipc-handlers.ts` per gestire tutti gli handler IPC\n4. Creare `electron/config-manager.ts` per gestire configurazioni persistenti con electron-store\n5. Aggiornare `electron/main.ts` per registrare tutti gli handler IPC\n6. Installare dipendenze: `keytar`, `electron-store`\n7. Creare tipi TypeScript in `src/app.d.ts` per l'API esposta\n8. Abilitare context isolation e sandbox nel BrowserWindow",
        "testStrategy": "Test di integrazione per verificare che le credenziali vengano salvate e recuperate correttamente dal keychain. Test per assicurarsi che il context isolation sia attivo e che il renderer non possa accedere direttamente a Node.js APIs.",
        "priority": "high",
        "dependencies": [],
        "status": "in-progress",
        "subtasks": [
          {
            "id": "1",
            "title": "Installazione dipendenze native keytar ed electron-store con configurazione build",
            "description": "Installare keytar per l'accesso al keychain nativo di macOS e electron-store per la persistenza delle configurazioni, includendo la configurazione necessaria per i moduli nativi Node.",
            "dependencies": [],
            "details": "1. Eseguire `pnpm add keytar electron-store` per installare le dipendenze\n2. Aggiungere `keytar` alla configurazione `pnpm.onlyBuiltDependencies` in package.json per garantire la compilazione corretta dei moduli nativi\n3. Verificare che electron-rebuild sia disponibile o installarlo se necessario per la ricompilazione dei moduli nativi\n4. Testare che keytar venga compilato correttamente eseguendo `pnpm start`\n5. In caso di errori di build, configurare node-gyp con le dipendenze di sistema richieste (Xcode Command Line Tools su macOS)",
            "status": "pending",
            "testStrategy": "Eseguire `pnpm start` e verificare che l'app si avvii senza errori relativi a moduli nativi. Verificare che keytar e electron-store siano presenti in node_modules e che keytar abbia i binding nativi compilati.",
            "parentId": "2"
          },
          {
            "id": "2",
            "title": "Implementazione modulo keychain.ts con wrapper keytar cross-platform",
            "description": "Creare il modulo electron/keychain.ts che incapsula le operazioni di keytar per la gestione sicura delle credenziali tramite il keychain nativo del sistema operativo.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `electron/keychain.ts` con le seguenti funzioni:\n   - `saveCredential(service: string, account: string, password: string): Promise<void>`\n   - `getCredential(service: string, account: string): Promise<string | null>`\n   - `deleteCredential(service: string, account: string): Promise<boolean>`\n2. Implementare gestione degli errori con messaggi descrittivi\n3. Definire costanti per il service name dell'applicazione (es. 'com.electron-svelte.credentials')\n4. Aggiungere logging per debugging in development\n5. Gestire il caso in cui keytar non sia disponibile (fallback o errore esplicito)",
            "status": "pending",
            "testStrategy": "Test unitari per verificare save/get/delete delle credenziali. Test per gestione errori quando service o account sono vuoti. Verificare manualmente che le credenziali appaiano nel Keychain Access di macOS.",
            "parentId": "2"
          },
          {
            "id": "3",
            "title": "Implementazione config-manager.ts con electron-store per configurazioni persistenti",
            "description": "Creare il modulo electron/config-manager.ts per gestire le configurazioni persistenti dell'applicazione utilizzando electron-store con schema tipizzato.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `electron/config-manager.ts` con interfaccia tipizzata per le configurazioni:\n   ```typescript\n   interface AppConfig {\n     selectedProvider?: string;\n     selectedModel?: string;\n     theme?: 'light' | 'dark' | 'system';\n     // altre configurazioni non sensibili\n   }\n   ```\n2. Inizializzare electron-store con schema e valori di default\n3. Implementare funzioni:\n   - `getConfig<K extends keyof AppConfig>(key: K): AppConfig[K]`\n   - `setConfig<K extends keyof AppConfig>(key: K, value: AppConfig[K]): void`\n   - `getAllConfig(): AppConfig`\n4. NON memorizzare API keys in electron-store (usare keychain)\n5. Configurare la directory di storage appropriata per l'app",
            "status": "pending",
            "testStrategy": "Test unitari per get/set configurazioni. Verificare che i dati persistano tra riavvii dell'app. Test che i valori di default siano applicati correttamente. Verificare che il file JSON di configurazione sia creato nella directory corretta.",
            "parentId": "2"
          },
          {
            "id": "4",
            "title": "Creazione ipc-handlers.ts centralizzato per keychain e config",
            "description": "Implementare il modulo electron/ipc-handlers.ts che registra tutti gli handler IPC per keychain e configurazioni, centralizzando la logica di comunicazione main-renderer.",
            "dependencies": [
              2,
              3
            ],
            "details": "1. Creare `electron/ipc-handlers.ts` con funzione `registerIPCHandlers()`\n2. Registrare handler per keychain:\n   - `keychain:save` -> invoca keychain.saveCredential\n   - `keychain:get` -> invoca keychain.getCredential  \n   - `keychain:delete` -> invoca keychain.deleteCredential\n3. Registrare handler per config:\n   - `config:get` -> invoca configManager.getConfig\n   - `config:set` -> invoca configManager.setConfig\n4. Implementare validazione degli input per prevenire injection\n5. Aggiungere try-catch con messaggi di errore appropriati per ogni handler\n6. Loggare operazioni sensibili per audit trail",
            "status": "pending",
            "testStrategy": "Test di integrazione per verificare che gli handler IPC rispondano correttamente alle chiamate invoke. Test per validazione input (service/account vuoti, tipi incorretti). Verificare che errori vengano propagati correttamente al renderer.",
            "parentId": "2"
          },
          {
            "id": "5",
            "title": "Estensione preload.ts con contextBridge API sicure",
            "description": "Implementare il preload script che espone API sicure al renderer tramite contextBridge, creando un'interfaccia tipizzata per keychain e configurazioni.",
            "dependencies": [
              4
            ],
            "details": "1. Modificare `electron/preload.ts` per importare contextBridge e ipcRenderer\n2. Usare `contextBridge.exposeInMainWorld('electronAPI', {...})` per esporre:\n   - `saveCredential(service, account, password)` -> ipcRenderer.invoke('keychain:save', ...)\n   - `getCredential(service, account)` -> ipcRenderer.invoke('keychain:get', ...)\n   - `deleteCredential(service, account)` -> ipcRenderer.invoke('keychain:delete', ...)\n   - `getConfig(key)` -> ipcRenderer.invoke('config:get', ...)\n   - `setConfig(key, value)` -> ipcRenderer.invoke('config:set', ...)\n3. NON esporre ipcRenderer direttamente\n4. Aggiornare `src/app.d.ts` con dichiarazione globale:\n   ```typescript\n   interface ElectronAPI {\n     saveCredential(service: string, account: string, password: string): Promise<void>;\n     getCredential(service: string, account: string): Promise<string | null>;\n     deleteCredential(service: string, account: string): Promise<boolean>;\n     getConfig(key: string): Promise<unknown>;\n     setConfig(key: string, value: unknown): Promise<void>;\n   }\n   declare global {\n     interface Window {\n       electronAPI: ElectronAPI;\n     }\n   }\n   ```",
            "status": "pending",
            "testStrategy": "Verificare che window.electronAPI sia disponibile nel renderer. Test che le chiamate vengano correttamente inoltrate al main process. Verificare che ipcRenderer non sia esposto globalmente. Test TypeScript per la tipizzazione corretta.",
            "parentId": "2"
          },
          {
            "id": "6",
            "title": "Aggiornamento main.ts con security settings e registrazione handlers",
            "description": "Configurare BrowserWindow con le impostazioni di sicurezza Electron (context isolation, sandbox, nodeIntegration:false) e integrare la registrazione degli handler IPC.",
            "dependencies": [
              4,
              5
            ],
            "details": "1. Modificare `electron/main.ts` per importare e chiamare `registerIPCHandlers()` prima di app.on('ready')\n2. Aggiornare webPreferences di BrowserWindow:\n   ```typescript\n   webPreferences: {\n     preload: path.join(import.meta.dirname, 'preload.js'),\n     contextIsolation: true,\n     sandbox: true,\n     nodeIntegration: false,\n     webSecurity: true,\n   }\n   ```\n3. Aggiungere Content Security Policy appropriata\n4. Implementare gestione errori per la registrazione degli handler\n5. Verificare che il preload script venga caricato correttamente\n6. Aggiungere logging all'avvio per confermare che tutti i moduli siano inizializzati",
            "status": "pending",
            "testStrategy": "Test che context isolation sia attivo verificando che process e require non siano disponibili nel renderer. Test che le API esposte tramite electronAPI funzionino correttamente. Verificare in DevTools che le impostazioni di sicurezza siano applicate. Test E2E per il flusso completo: salvataggio e recupero credenziali.",
            "parentId": "2"
          }
        ],
        "tags": [
          "electron-main",
          "security",
          "phase-0-foundation",
          "electron"
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Installazione dipendenze native keytar ed electron-store con configurazione build, 2) Implementazione modulo keychain.ts con wrapper keytar cross-platform, 3) Implementazione config-manager.ts con electron-store per configurazioni persistenti, 4) Creazione ipc-handlers.ts centralizzato per keychain e config, 5) Estensione preload.ts con contextBridge API sicure, 6) Aggiornamento main.ts con security settings (context isolation, sandbox, nodeIntegration:false) e registrazione handlers",
        "updatedAt": "2026-01-06T21:41:30.351Z"
      },
      {
        "id": "3",
        "title": "UI Configurazione Provider LLM Multi-Provider",
        "description": "Creare l'interfaccia utente per configurare multipli provider LLM (Anthropic, OpenAI, Google, Perplexity) con validazione delle connessioni e memorizzazione sicura delle API keys.",
        "details": "1. Creare `src/routes/settings/llm-providers/+page.svelte` con form per ogni provider\n2. Implementare componente `src/lib/components/custom/LLMProviderCard.svelte`:\n```svelte\n<script lang=\"ts\">\n  import { Card, CardContent, CardHeader } from '$lib/components/ui/card';\n  import { Input } from '$lib/components/ui/input';\n  import { Button } from '$lib/components/ui/button';\n  \n  export let provider: { id: string; name: string; logo: string; models: string[] };\n  let apiKey = '';\n  let selectedModel = '';\n  let connectionStatus: 'idle' | 'testing' | 'success' | 'error' = 'idle';\n  \n  async function testConnection() {\n    connectionStatus = 'testing';\n    try {\n      await window.electronAPI.testLLMConnection(provider.id, apiKey, selectedModel);\n      connectionStatus = 'success';\n    } catch { connectionStatus = 'error'; }\n  }\n  \n  async function saveCredentials() {\n    await window.electronAPI.saveCredential('llm-provider', provider.id, apiKey);\n  }\n</script>\n```\n3. Creare servizio `src/lib/services/llm-config.ts` per interagire con IPC\n4. Implementare store Svelte 5 runes per stato provider: `src/lib/stores/llm-providers.svelte.ts`\n5. Creare IPC handler in main process per test connessione ai provider\n6. Provider supportati: Anthropic (Claude), OpenAI (GPT-4), Google (Gemini), Perplexity (Research)\n7. Memorizzare preferenze modello per ruolo: main, fallback, research",
        "testStrategy": "Test unitari per form validation. Test di mock per verificare che le API keys vengano salvate correttamente. Test E2E per il flusso completo: inserimento key -> test connessione -> salvataggio.",
        "priority": "high",
        "dependencies": [
          "1",
          "2"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Creazione Route Settings LLM Providers con Layout Tab",
            "description": "Creare la pagina principale di configurazione dei provider LLM con navigazione a tab per ogni provider supportato (Anthropic, OpenAI, Google, Perplexity).",
            "dependencies": [],
            "details": "1. Creare la struttura delle cartelle: `src/routes/settings/llm-providers/+page.svelte`\n2. Importare componenti shadcn-svelte: Tabs, TabsList, TabsTrigger, TabsContent\n3. Definire i 4 provider con i loro metadati (id, name, logo, modelli disponibili)\n4. Implementare layout responsive con tab orizzontali su desktop e verticali su mobile\n5. Aggiungere breadcrumb navigation: Settings > LLM Providers\n6. Configurare SvelteKit routing con hash-based navigation per Electron compatibility",
            "status": "pending",
            "testStrategy": "Verificare che la route sia accessibile, che i tab cambino correttamente e che il layout sia responsive.",
            "parentId": "3"
          },
          {
            "id": "2",
            "title": "Implementazione Componente LLMProviderCard.svelte",
            "description": "Sviluppare il componente riutilizzabile per la configurazione di ogni singolo provider LLM con form, validazione e indicatore stato connessione.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `src/lib/components/custom/LLMProviderCard.svelte` con Card shadcn-svelte\n2. Implementare form con Input per API key (tipo password con toggle visibilità)\n3. Creare Select/Dropdown per selezione modello dal provider\n4. Aggiungere stati visivi per connectionStatus: idle, testing, success, error con icone appropriate\n5. Implementare validazione form: API key required, formato minimo caratteri\n6. Usare Svelte 5 runes ($state, $derived) per gestione stato locale\n7. Aggiungere skeleton loading durante operazioni async",
            "status": "pending",
            "testStrategy": "Test unitari per validazione form, test rendering degli stati connessione, test toggle visibilità password.",
            "parentId": "3"
          },
          {
            "id": "3",
            "title": "Creazione Store llm-providers.svelte.ts con Svelte 5 Runes",
            "description": "Implementare lo store globale per la gestione dello stato dei provider LLM utilizzando Svelte 5 runes per reattività e persistenza.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `src/lib/stores/llm-providers.svelte.ts`\n2. Definire interfacce TypeScript: LLMProvider, LLMProviderState, ModelRole\n3. Implementare stato con $state rune per: providers[], selectedModels, connectionStatuses\n4. Creare $derived per computed properties: hasValidMainProvider, configuredProviders\n5. Implementare funzioni per update stato: setApiKey, setModel, updateConnectionStatus\n6. Aggiungere persistenza preferenze modello per ruolo (main, fallback, research)\n7. Creare funzione initFromStorage per caricare configurazione salvata all'avvio",
            "status": "pending",
            "testStrategy": "Test unitari per tutte le funzioni dello store, test reattività con mock data, test persistenza.",
            "parentId": "3"
          },
          {
            "id": "4",
            "title": "Implementazione IPC Handlers per Test Connessione Multi-Provider",
            "description": "Creare gli handler IPC nel main process Electron per testare la connessione ai diversi provider LLM (Anthropic, OpenAI, Google, Perplexity).",
            "dependencies": [
              2,
              3
            ],
            "details": "1. Estendere `electron/main.ts` con ipcMain.handle per 'llm:test-connection'\n2. Creare `electron/services/llm-connector.ts` con classe LLMConnector\n3. Implementare metodi specifici per ogni provider:\n   - testAnthropicConnection(apiKey, model) - POST a api.anthropic.com/v1/messages\n   - testOpenAIConnection(apiKey, model) - POST a api.openai.com/v1/chat/completions\n   - testGoogleConnection(apiKey, model) - POST a generativelanguage.googleapis.com\n   - testPerplexityConnection(apiKey, model) - POST a api.perplexity.ai\n4. Gestire timeout (10s) e error handling specifico per ogni provider\n5. Esporre via preload.ts: window.electronAPI.testLLMConnection()",
            "status": "pending",
            "testStrategy": "Test con mock HTTP responses, test timeout handling, test error codes specifici per provider.",
            "parentId": "3"
          },
          {
            "id": "5",
            "title": "Integrazione Keychain e Configurazione Ruoli Modello",
            "description": "Collegare il sistema keychain per salvataggio sicuro delle API keys e implementare la configurazione dei ruoli modello (main, fallback, research).",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "1. Creare `src/lib/services/llm-config.ts` per interazione con IPC\n2. Implementare funzioni:\n   - saveProviderCredentials(providerId, apiKey) - salva in keychain via IPC\n   - loadProviderCredentials(providerId) - recupera da keychain\n   - deleteProviderCredentials(providerId) - rimuove da keychain\n3. Creare UI per assegnazione ruoli: main (uso primario), fallback (backup), research (Perplexity)\n4. Implementare Select component per scegliere quale provider usare per ogni ruolo\n5. Salvare configurazione ruoli in electron-store (non sensibile)\n6. Aggiungere validazione: almeno un provider main configurato prima di procedere\n7. Creare Toast notifications per feedback operazioni (save success/error)",
            "status": "pending",
            "testStrategy": "Test E2E flusso completo: inserimento key -> test connessione -> salvataggio keychain -> assegnazione ruolo.",
            "parentId": "3"
          }
        ],
        "tags": [
          "frontend",
          "ai-config",
          "phase-1-config",
          "svelte"
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Creazione route settings/llm-providers con layout tab, 2) Implementazione componente LLMProviderCard.svelte con form validazione e stato connessione, 3) Creazione store llm-providers.svelte.ts con Svelte 5 runes per stato globale, 4) Implementazione IPC handlers per test connessione multi-provider (Anthropic, OpenAI, Google, Perplexity), 5) Integrazione con keychain per salvataggio sicuro API keys e configurazione ruoli modello (main, fallback, research)"
      },
      {
        "id": "4",
        "title": "Python Sidecar con FastAPI e Lifecycle Management",
        "description": "Implementare il sistema di sidecar Python con FastAPI che ospiterà il Cagent engine, includendo gestione del ciclo di vita del processo dal main Electron.",
        "details": "1. Creare struttura `python/`:\n   - `python/main.py` - FastAPI server con SSE support\n   - `python/requirements.txt` - dipendenze (fastapi, uvicorn, sse-starlette, cagent)\n   - `python/agents/` - implementazioni agenti\n   - `python/tools/` - wrapper MCP tools\n2. Implementare FastAPI server:\n```python\nfrom fastapi import FastAPI, Request\nfrom sse_starlette.sse import EventSourceResponse\nimport asyncio\n\napp = FastAPI()\n\n@app.get(\"/health\")\nasync def health():\n    return {\"status\": \"ok\"}\n\n@app.post(\"/agent/execute\")\nasync def execute_agent(request: Request):\n    data = await request.json()\n    # Esegui agente con Cagent\n    return {\"result\": \"...\"}\n\n@app.get(\"/agent/stream\")\nasync def stream_events(request: Request):\n    async def event_generator():\n        while True:\n            yield {\"data\": \"...\"}\n            await asyncio.sleep(0.1)\n    return EventSourceResponse(event_generator())\n```\n3. Creare `electron/sidecar-manager.ts`:\n   - spawn processo Python con uvicorn\n   - health check polling\n   - graceful shutdown su app quit\n   - restart automatico su crash\n4. Bundling: includere Python embedded o usare pyinstaller per distribuzione\n5. Creare `src/lib/services/cagent-client.ts` per HTTP client verso sidecar",
        "testStrategy": "Test unitari per FastAPI endpoints. Test di integrazione per verificare spawn/shutdown del sidecar. Test health check polling. Test SSE streaming.",
        "priority": "high",
        "dependencies": [
          "2"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Creazione struttura directory python/ con requirements.txt",
            "description": "Creare la struttura completa della directory python/ con tutti i file e sottocartelle necessarie per il sidecar FastAPI, incluso requirements.txt con tutte le dipendenze.",
            "dependencies": [],
            "details": "Creare la seguente struttura:\n- `python/main.py` - entry point vuoto iniziale\n- `python/requirements.txt` con dipendenze: fastapi>=0.104.0, uvicorn[standard]>=0.24.0, sse-starlette>=1.8.0, pydantic>=2.5.0, python-dotenv>=1.0.0\n- `python/agents/__init__.py` - package per implementazioni agenti\n- `python/tools/__init__.py` - package per wrapper MCP tools\n- `python/config.py` - configurazione server (host, port, log level)\n- `python/.gitignore` per __pycache__, .venv, *.pyc\n\nAggiungere commenti placeholder che indicano dove verranno implementate le funzionalità successive.",
            "status": "pending",
            "testStrategy": "Verificare che tutti i file e directory esistano. Eseguire `pip install -r requirements.txt` in un virtualenv per validare le dipendenze. Verificare che la struttura sia importabile con `python -c 'import python.agents; import python.tools'`.",
            "parentId": "4"
          },
          {
            "id": "2",
            "title": "Implementazione FastAPI server con endpoint health e execute",
            "description": "Implementare il server FastAPI base in main.py con gli endpoint /health per monitoring e /agent/execute per esecuzione sincrona degli agenti.",
            "dependencies": [
              1
            ],
            "details": "Implementare in `python/main.py`:\n```python\nfrom fastapi import FastAPI, Request, HTTPException\nfrom pydantic import BaseModel\nimport logging\n\napp = FastAPI(title='Cagent Sidecar', version='1.0.0')\nlogger = logging.getLogger(__name__)\n\nclass AgentRequest(BaseModel):\n    agent_id: str\n    input: dict\n    context: dict | None = None\n\nclass AgentResponse(BaseModel):\n    result: dict\n    execution_time: float\n    agent_id: str\n\n@app.get('/health')\nasync def health():\n    return {'status': 'ok', 'version': '1.0.0'}\n\n@app.post('/agent/execute', response_model=AgentResponse)\nasync def execute_agent(request: AgentRequest):\n    # Placeholder per integrazione Cagent\n    pass\n```\nAggiungere middleware per logging request/response e CORS per comunicazione con Electron.",
            "status": "pending",
            "testStrategy": "Test unitari con pytest e httpx.AsyncClient per entrambi gli endpoint. Verificare che /health restituisca 200 con payload corretto. Verificare validazione Pydantic su /agent/execute con input malformati. Test timeout handling.",
            "parentId": "4"
          },
          {
            "id": "3",
            "title": "Implementazione SSE streaming per eventi agenti",
            "description": "Aggiungere endpoint SSE (Server-Sent Events) per streaming real-time degli eventi durante l'esecuzione degli agenti verso il frontend Electron.",
            "dependencies": [
              2
            ],
            "details": "Implementare in `python/main.py`:\n```python\nfrom sse_starlette.sse import EventSourceResponse\nimport asyncio\nfrom typing import AsyncGenerator\n\nclass StreamEvent(BaseModel):\n    event_type: str  # 'thinking', 'tool_call', 'result', 'error'\n    data: dict\n    timestamp: float\n\nasync def agent_event_generator(agent_id: str, request_id: str) -> AsyncGenerator:\n    # Queue per eventi dall'agente\n    event_queue = asyncio.Queue()\n    try:\n        while True:\n            event = await asyncio.wait_for(event_queue.get(), timeout=30.0)\n            yield {'event': event.event_type, 'data': event.json()}\n            if event.event_type in ('result', 'error'):\n                break\n    except asyncio.TimeoutError:\n        yield {'event': 'keepalive', 'data': '{}'}\n\n@app.get('/agent/stream/{request_id}')\nasync def stream_events(request_id: str, request: Request):\n    return EventSourceResponse(agent_event_generator(request_id))\n```\nGestire disconnessione client e cleanup risorse.",
            "status": "pending",
            "testStrategy": "Test SSE connection con httpx-sse. Verificare che gli eventi vengano ricevuti nell'ordine corretto. Test disconnessione prematura del client. Test keepalive per connessioni idle. Verificare cleanup risorse post-stream.",
            "parentId": "4"
          },
          {
            "id": "4",
            "title": "Creazione sidecar-manager.ts in Electron per spawn/kill processo Python",
            "description": "Implementare il modulo TypeScript in Electron che gestisce lo spawn del processo Python uvicorn e la terminazione controllata del sidecar.",
            "dependencies": [
              1
            ],
            "details": "Creare `electron/sidecar-manager.ts`:\n```typescript\nimport { spawn, ChildProcess } from 'child_process';\nimport path from 'path';\nimport { app } from 'electron';\n\nexport class SidecarManager {\n  private process: ChildProcess | null = null;\n  private readonly port: number = 8765;\n  private readonly host: string = '127.0.0.1';\n\n  async start(): Promise<void> {\n    const pythonPath = this.getPythonPath();\n    const scriptPath = path.join(app.getAppPath(), 'python', 'main.py');\n    \n    this.process = spawn(pythonPath, [\n      '-m', 'uvicorn',\n      'main:app',\n      '--host', this.host,\n      '--port', String(this.port)\n    ], { cwd: path.dirname(scriptPath) });\n    \n    this.setupEventHandlers();\n  }\n\n  async stop(): Promise<void> {\n    // SIGTERM con timeout, poi SIGKILL\n  }\n\n  getBaseUrl(): string {\n    return `http://${this.host}:${this.port}`;\n  }\n}\n```\nGestire stdout/stderr logging e rilevamento errori startup.",
            "status": "pending",
            "testStrategy": "Test spawn processo con mock child_process. Verificare che il processo venga avviato con argomenti corretti. Test stop() con verifica SIGTERM inviato. Test gestione errori se Python non trovato. Integration test con processo Python reale.",
            "parentId": "4"
          },
          {
            "id": "5",
            "title": "Implementazione health check polling con auto-restart e backoff esponenziale",
            "description": "Aggiungere sistema di health check polling al SidecarManager con logica di auto-restart in caso di crash e backoff esponenziale per evitare restart loop.",
            "dependencies": [
              4
            ],
            "details": "Estendere `electron/sidecar-manager.ts`:\n```typescript\ninterface HealthCheckConfig {\n  interval: number;        // 5000ms default\n  timeout: number;         // 2000ms default  \n  maxRetries: number;      // 3 prima di restart\n  maxRestarts: number;     // 5 prima di circuit breaker\n  backoffMultiplier: number; // 2.0\n  maxBackoff: number;      // 60000ms\n}\n\nclass SidecarManager {\n  private healthCheckTimer: NodeJS.Timer | null = null;\n  private restartCount: number = 0;\n  private currentBackoff: number = 1000;\n\n  private async checkHealth(): Promise<boolean> {\n    try {\n      const response = await fetch(`${this.getBaseUrl()}/health`, {\n        signal: AbortSignal.timeout(this.config.timeout)\n      });\n      return response.ok;\n    } catch {\n      return false;\n    }\n  }\n\n  private async handleUnhealthy(): Promise<void> {\n    if (this.restartCount >= this.config.maxRestarts) {\n      this.emit('circuit-breaker-open');\n      return;\n    }\n    await this.restart();\n    this.currentBackoff = Math.min(\n      this.currentBackoff * this.config.backoffMultiplier,\n      this.config.maxBackoff\n    );\n  }\n}\n```\nEmettere eventi per UI feedback sullo stato del sidecar.",
            "status": "pending",
            "testStrategy": "Test health check con mock fetch. Test backoff esponenziale verificando timing tra restart. Test circuit breaker dopo maxRestarts. Test reset contatori dopo periodo stabile. Test eventi emessi per ogni stato.",
            "parentId": "4"
          },
          {
            "id": "6",
            "title": "Gestione graceful shutdown su app quit con timeout e SIGTERM/SIGKILL",
            "description": "Implementare la logica di shutdown graceful del sidecar Python quando l'app Electron viene chiusa, con escalation da SIGTERM a SIGKILL dopo timeout.",
            "dependencies": [
              5
            ],
            "details": "Estendere `electron/sidecar-manager.ts` e integrare con lifecycle Electron:\n```typescript\nimport { app } from 'electron';\n\nclass SidecarManager {\n  private readonly shutdownTimeout: number = 5000;\n\n  registerShutdownHandlers(): void {\n    app.on('before-quit', async (event) => {\n      if (this.process) {\n        event.preventDefault();\n        await this.gracefulShutdown();\n        app.quit();\n      }\n    });\n\n    process.on('SIGINT', () => this.gracefulShutdown());\n    process.on('SIGTERM', () => this.gracefulShutdown());\n  }\n\n  private async gracefulShutdown(): Promise<void> {\n    if (!this.process) return;\n    \n    this.stopHealthCheck();\n    \n    // Notifica sidecar di shutdown\n    try {\n      await fetch(`${this.getBaseUrl()}/shutdown`, { method: 'POST' });\n    } catch {}\n\n    // SIGTERM\n    this.process.kill('SIGTERM');\n    \n    // Attendi o forza SIGKILL\n    const killed = await this.waitForExit(this.shutdownTimeout);\n    if (!killed) {\n      this.process.kill('SIGKILL');\n    }\n  }\n}\n```\nAggiungere endpoint /shutdown in FastAPI per cleanup risorse Python.",
            "status": "pending",
            "testStrategy": "Test SIGTERM inviato come primo segnale. Test escalation a SIGKILL dopo timeout. Test che app.quit() venga chiamato dopo shutdown. Test cleanup risorse Python verificando log. Integration test shutdown completo con processo reale.",
            "parentId": "4"
          },
          {
            "id": "7",
            "title": "Bundling strategy con PyInstaller per distribuzione cross-platform",
            "description": "Configurare PyInstaller per creare un eseguibile standalone del sidecar Python che può essere distribuito insieme all'app Electron su Windows, macOS e Linux.",
            "dependencies": [
              6
            ],
            "details": "Creare `python/build/` con configurazione PyInstaller:\n1. `python/pyinstaller.spec`:\n```python\na = Analysis(\n    ['main.py'],\n    pathex=[],\n    binaries=[],\n    datas=[('agents', 'agents'), ('tools', 'tools')],\n    hiddenimports=['uvicorn.logging', 'uvicorn.protocols.http'],\n    hookspath=[],\n    noarchive=False,\n)\npyz = PYZ(a.pure)\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.datas,\n    name='cagent-sidecar',\n    console=False,\n    onefile=True\n)\n```\n2. Script `scripts/build-sidecar.sh`:\n```bash\n#!/bin/bash\npyinstaller --clean --noconfirm python/pyinstaller.spec\ncp dist/cagent-sidecar resources/sidecar/\n```\n3. Modificare `SidecarManager.getPythonPath()` per usare eseguibile bundled in produzione:\n```typescript\ngetSidecarPath(): string {\n  if (app.isPackaged) {\n    return path.join(process.resourcesPath, 'sidecar', 'cagent-sidecar');\n  }\n  return 'python3'; // Dev mode\n}\n```\n4. Aggiornare electron-builder config per includere sidecar negli extraResources.",
            "status": "pending",
            "testStrategy": "Build PyInstaller su CI per ogni piattaforma. Verificare che l'eseguibile si avvii correttamente standalone. Test dimensione bundle < 100MB. Test che health check funzioni con sidecar bundled. Integration test completo dell'app packaged.",
            "parentId": "4"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "phase-2-core",
          "python",
          "fastapi"
        ],
        "complexity": 8,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Espandi in subtask: 1) Creazione struttura directory python/ con requirements.txt, 2) Implementazione FastAPI server con endpoint health e execute, 3) Implementazione SSE streaming per eventi agenti, 4) Creazione sidecar-manager.ts in Electron per spawn/kill processo Python, 5) Implementazione health check polling con auto-restart e backoff esponenziale, 6) Gestione graceful shutdown su app quit con timeout e SIGTERM/SIGKILL, 7) Bundling strategy con PyInstaller per distribuzione cross-platform"
      },
      {
        "id": "5",
        "title": "Generazione Dinamica cagent.yaml e Configurazione Agenti",
        "description": "Implementare il sistema che genera dinamicamente il file cagent.yaml basandosi sulle configurazioni utente dei provider LLM e ruoli agenti.",
        "details": "1. Creare `src/lib/services/cagent-config.ts`:\n```typescript\ninterface AgentRole {\n  name: string;\n  model: string;\n  provider: string;\n  systemPrompt: string;\n  tools: string[];\n}\n\ninterface CagentConfig {\n  version: string;\n  agents: AgentRole[];\n  rag: { vectorStore: string; embeddingModel: string; };\n  mcp: { servers: string[]; };\n}\n\nexport async function generateCagentYaml(config: CagentConfig): Promise<string> {\n  // Genera YAML dalla configurazione\n}\n```\n2. Creare IPC handler per scrivere cagent.yaml nel path corretto\n3. Implementare UI in `src/routes/settings/agents/+page.svelte` per:\n   - Assegnare modelli a ruoli (Orchestrator, Extraction, Editing, Captioning, Scheduling)\n   - Configurare system prompts per agente\n   - Abilitare/disabilitare tools per agente\n4. Creare template YAML di default in `resources/cagent-template.yaml`\n5. Validazione configurazione prima di salvataggio\n6. Hot-reload: notificare sidecar Python di ricaricare config",
        "testStrategy": "Test unitari per generazione YAML corretta. Test di validazione configurazione. Test che il sidecar riceva correttamente le notifiche di reload.",
        "priority": "high",
        "dependencies": [
          "3",
          "4"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Definizione TypeScript Interfaces per CagentConfig e AgentRole",
            "description": "Creare le interfacce TypeScript complete per la configurazione del sistema cagent, includendo AgentRole, CagentConfig, RAGConfig e MCPConfig con tutti i tipi necessari per la validazione statica e l'esportazione del modulo.",
            "dependencies": [],
            "details": "Creare il file `src/lib/types/cagent.ts` con le seguenti interfacce: 1) `AgentRole` con proprietà name, model, provider, systemPrompt e tools (array di stringhe), 2) `RAGConfig` con vectorStore e embeddingModel, 3) `MCPConfig` con array servers, 4) `CagentConfig` con version, array agents di tipo AgentRole[], rag di tipo RAGConfig e mcp di tipo MCPConfig. Aggiungere type guards per validazione runtime: `isAgentRole()`, `isCagentConfig()`. Definire costanti per i ruoli predefiniti: ORCHESTRATOR, EXTRACTION, EDITING, CAPTIONING, SCHEDULING. Creare tipi utility come `PartialAgentRole` per update parziali. Esportare tutto dal barrel file `src/lib/types/index.ts`.",
            "status": "pending",
            "testStrategy": "Test unitari per type guards con casi validi e invalidi. Verificare che i tipi siano esportati correttamente e utilizzabili in altri moduli. Test di compilazione TypeScript per verificare correttezza tipi. Testare che PartialAgentRole permetta update parziali corretti.",
            "parentId": "5"
          },
          {
            "id": "2",
            "title": "Creazione cagent-config.ts con Funzione generateCagentYaml e Serializzazione",
            "description": "Implementare il servizio principale in src/lib/services/cagent-config.ts per la generazione del file YAML cagent, includendo serializzazione YAML con libreria js-yaml, template di default e gestione errori completa.",
            "dependencies": [
              1
            ],
            "details": "Installare dipendenza `js-yaml` e relativi types `@types/js-yaml`. Creare `src/lib/services/cagent-config.ts` con: 1) Funzione `generateCagentYaml(config: CagentConfig): string` che serializza la configurazione in formato YAML, 2) Funzione `parseCagentYaml(yaml: string): CagentConfig` per il parsing inverso, 3) Funzione `getDefaultConfig(): CagentConfig` che ritorna la configurazione di default con tutti e 5 i ruoli agente preconfigurati, 4) Funzione `mergeWithDefaults(partial: Partial<CagentConfig>): CagentConfig` per merge intelligente, 5) Funzione `validateConfig(config: unknown): ValidationResult` per validazione schema. Creare template YAML di default in `resources/cagent-template.yaml` come riferimento. Gestire edge cases: config vuota, valori mancanti, tipi incorretti.",
            "status": "pending",
            "testStrategy": "Test unitari per generateCagentYaml con varie configurazioni. Test round-trip YAML->Config->YAML per verificare integrità dati. Test merge con defaults. Test gestione casi limite (config vuota, valori mancanti). Test parsing YAML malformato.",
            "parentId": "5"
          },
          {
            "id": "3",
            "title": "Implementazione UI Settings/Agents per Configurazione Ruoli e System Prompts",
            "description": "Creare l'interfaccia utente Svelte in src/routes/settings/agents/+page.svelte per la configurazione degli agenti, permettendo di assegnare modelli LLM a ruoli, modificare system prompts e gestire tools abilitati per ogni agente.",
            "dependencies": [
              1,
              2
            ],
            "details": "Creare la struttura directory `src/routes/settings/agents/` con +page.svelte e +page.ts. Implementare UI con: 1) Lista dei 5 ruoli agente (Orchestrator, Extraction, Editing, Captioning, Scheduling) con card espandibili, 2) Select dropdown per assegnare provider e modello a ciascun ruolo (popolato da Task 3 - config providers), 3) Textarea per modificare system prompt di ogni agente con preview markdown, 4) Checkbox list per tools abilitati per ogni agente, 5) Pulsante 'Salva Configurazione' che chiama l'IPC handler, 6) Pulsante 'Ripristina Default' per reset. Utilizzare Svelte store per stato locale. Implementare validazione form con feedback visivo. Aggiungere skeleton loading mentre si caricano i dati. Integrare con il layout settings esistente aggiungendo link nella sidebar.",
            "status": "pending",
            "testStrategy": "Test componenti con Svelte Testing Library. Test interazioni utente (selezione modelli, modifica prompts, toggle tools). Test validazione form con casi validi e invalidi. Test integrazione con store. Screenshot testing per UI consistency.",
            "parentId": "5"
          },
          {
            "id": "4",
            "title": "IPC Handler per Scrittura File YAML e Validazione Schema",
            "description": "Implementare gli handler IPC Electron per scrivere il file cagent.yaml nel filesystem del sistema operativo, con validazione schema JSON/YAML completa e gestione errori filesystem con backup automatico.",
            "dependencies": [
              2
            ],
            "details": "Nel processo main Electron creare handler IPC in `src-electron/ipc/cagent-handlers.ts`: 1) `cagent:save-config` - riceve CagentConfig, valida con JSON Schema, genera YAML, scrive su disco in `~/.trae-extractor/cagent.yaml`, 2) `cagent:load-config` - legge file YAML esistente e ritorna CagentConfig, 3) `cagent:validate-config` - valida configurazione senza salvare, 4) `cagent:get-config-path` - ritorna path del file config. Implementare backup automatico prima di ogni scrittura (cagent.yaml.bak). Gestire errori: permessi insufficienti, disco pieno, file locked. Creare JSON Schema per validazione in `resources/cagent-schema.json`. Registrare handlers in main.ts. Creare preload bridge per esporre funzioni al renderer process.",
            "status": "pending",
            "testStrategy": "Test unitari per validazione schema con casi validi e invalidi. Test scrittura/lettura filesystem con mock fs. Test gestione errori (permessi, disco pieno, file corrotto). Test backup automatico funzionante. Test integrazione IPC end-to-end.",
            "parentId": "5"
          },
          {
            "id": "5",
            "title": "Implementazione Hot-Reload Notifica al Sidecar Python",
            "description": "Implementare il meccanismo di notifica al sidecar Python quando la configurazione cagent viene modificata dall'UI, permettendo il reload dinamico della configurazione senza necessità di riavviare il processo Python.",
            "dependencies": [
              4
            ],
            "details": "Estendere la comunicazione con il sidecar Python (da Task 4) per supportare hot-reload: 1) Nel sidecar FastAPI aggiungere endpoint `POST /config/reload` che ricarica cagent.yaml e reinizializza gli agenti, 2) Nel frontend implementare chiamata HTTP all'endpoint reload dopo salvataggio config riuscito, 3) Implementare retry logic con backoff esponenziale se il sidecar non risponde (max 3 tentativi), 4) Mostrare toast notification in UI con stato reload (successo/fallimento), 5) Aggiungere file watcher opzionale in Python per rilevare modifiche esterne al file, 6) Implementare WebSocket channel `/ws/config-events` per notifiche bidirezionali real-time tra Electron e sidecar. Gestire graceful degradation: se reload fallisce, mantenere configurazione precedente e notificare utente.",
            "status": "pending",
            "testStrategy": "Test comunicazione HTTP con mock sidecar per endpoint reload. Test timeout e retry logic con simulazione fallimenti. Test file watcher con modifiche filesystem simulate. Test E2E completo: modifica UI -> salvataggio -> notifica -> reload Python -> conferma successo.",
            "parentId": "5"
          }
        ],
        "tags": [
          "python-backend",
          "ai-config",
          "phase-1-config",
          "python",
          "cagent"
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Definizione TypeScript interfaces per CagentConfig e AgentRole, 2) Creazione cagent-config.ts con funzione generateCagentYaml e serializzazione YAML, 3) Implementazione UI Settings/Agents per configurazione ruoli e system prompts, 4) IPC handler per scrittura file YAML con validazione schema, 5) Implementazione hot-reload notifica al sidecar Python quando config cambia"
      },
      {
        "id": "6",
        "title": "Agente Estrazione con osxphotos Integration",
        "description": "Implementare l'agente di estrazione foto che utilizza osxphotos per accedere alla libreria Apple Photos locale, con preservazione EXIF e suggerimenti AI per tag.",
        "details": "1. Installare osxphotos in ambiente Python: `pip install osxphotos`\n2. Creare `python/agents/extraction_agent.py`:\n```python\nimport osxphotos\nfrom typing import List, Dict\n\nclass ExtractionAgent:\n    def __init__(self, photos_db_path: str = None):\n        self.photosdb = osxphotos.PhotosDB(dbfile=photos_db_path)\n    \n    async def list_albums(self) -> List[str]:\n        return [a.title for a in self.photosdb.album_info]\n    \n    async def extract_photos(\n        self, \n        album_name: str = None,\n        date_range: tuple = None,\n        dest_path: str = None\n    ) -> List[Dict]:\n        photos = self.photosdb.photos(albums=[album_name] if album_name else None)\n        results = []\n        for photo in photos:\n            photo.export(dest_path, exif=True)\n            results.append({\n                'uuid': photo.uuid,\n                'filename': photo.original_filename,\n                'exif': photo.exif_info,\n                'labels': photo.labels,\n                'faces': [f.name for f in photo.face_info]\n            })\n        return results\n```\n3. Creare UI in `src/routes/extract/+page.svelte`:\n   - Album browser con tree view\n   - Filtri per data, tipo media, persone\n   - Griglia preview foto con selezione multipla\n   - Progress bar durante estrazione\n4. Endpoint FastAPI `/agent/extract` per eseguire estrazione\n5. Integrazione con RAG per suggerimenti tag automatici",
        "testStrategy": "Test con mock PhotosDB per evitare dipendenza da libreria reale. Test UI per selezione album e filtri. Test E2E per flusso estrazione completo.",
        "priority": "high",
        "dependencies": [
          "4",
          "5"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Setup osxphotos in Ambiente Python e Gestione Permessi macOS Full Disk Access",
            "description": "Configurare l'ambiente Python con osxphotos e implementare la gestione dei permessi Full Disk Access richiesti da macOS per accedere alla Photos Library.",
            "dependencies": [],
            "details": "1. Creare la struttura directory `python/agents/` se non esiste\n2. Creare `python/requirements.txt` con dipendenza osxphotos: `osxphotos>=0.68.0`\n3. Installare osxphotos: `pip install osxphotos`\n4. Creare script di test `python/agents/test_photos_access.py` per verificare accesso alla libreria\n5. Implementare detection dei permessi Full Disk Access mancanti con messaggio user-friendly\n6. Creare utility `python/agents/permissions_helper.py` con funzione `check_photos_access()` che restituisce stato permessi\n7. Documentare procedura per abilitare Full Disk Access in System Preferences > Privacy & Security > Full Disk Access per l'app Electron/terminale Python\n8. Testare accesso a PhotosDB con path di default `~/Pictures/Photos Library.photoslibrary`\n9. Gestire gracefully il caso di libreria Photos non esistente o corrotta",
            "status": "pending",
            "testStrategy": "Test manuale per verificare che osxphotos si installi correttamente. Test script che verifica accesso alla Photos Library con e senza permessi Full Disk Access. Verificare che l'errore di permessi sia catturato e restituisca messaggio chiaro all'utente.",
            "parentId": "6"
          },
          {
            "id": "2",
            "title": "Implementazione ExtractionAgent Class con Metodi list_albums e extract_photos",
            "description": "Sviluppare la classe ExtractionAgent in Python con i metodi core per elencare album e estrarre foto con preservazione metadata EXIF completa.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `python/agents/extraction_agent.py` con classe ExtractionAgent\n2. Implementare `__init__(self, photos_db_path: str = None)` che inizializza PhotosDB\n3. Creare metodo async `list_albums() -> List[Dict]` che restituisce lista album con titolo, count foto, date range\n4. Implementare `async extract_photos(album_name, date_range, dest_path) -> List[Dict]`:\n   - Filtraggio per album_name se specificato\n   - Filtraggio per date_range (start_date, end_date) opzionale\n   - Export con `photo.export(dest_path, exif=True)` per preservare EXIF\n   - Restituzione dict con: uuid, original_filename, exif_info, labels (ML detection), faces\n5. Aggiungere metodo `get_photo_metadata(uuid: str) -> Dict` per metadata singola foto\n6. Implementare gestione errori per foto corrotte o inaccessibili\n7. Aggiungere typing completo con TypedDict per return types\n8. Supportare filtro per media_type (photo, video, live_photo)",
            "status": "pending",
            "testStrategy": "Test unitari con mock PhotosDB per evitare dipendenza da libreria reale. Test list_albums verifica struttura response. Test extract_photos con filtri data e album. Test che EXIF venga effettivamente preservato nei file esportati.",
            "parentId": "6"
          },
          {
            "id": "3",
            "title": "Creazione Endpoint FastAPI /agent/extract con Progress Streaming SSE",
            "description": "Implementare l'endpoint FastAPI per l'estrazione foto con supporto Server-Sent Events per progress reporting real-time al frontend.",
            "dependencies": [
              2
            ],
            "details": "1. Creare o estendere `python/api/routes/extract.py` con FastAPI router\n2. Implementare endpoint `GET /agent/extract/albums` per lista album\n3. Creare endpoint `POST /agent/extract/photos` con body: {album_name?, date_range?, dest_path}\n4. Implementare SSE streaming con `StreamingResponse` e `async def event_generator()`:\n   - Emettere evento 'progress' con {current, total, current_file} durante estrazione\n   - Emettere evento 'complete' con lista risultati alla fine\n   - Emettere evento 'error' in caso di fallimento\n5. Creare schema Pydantic per request/response: ExtractRequest, PhotoResult, ProgressEvent\n6. Aggiungere endpoint `GET /agent/extract/photo/{uuid}` per metadata singola foto\n7. Implementare cancellation support con abort signal\n8. Rate limiting per prevenire richieste multiple simultanee",
            "status": "pending",
            "testStrategy": "Test endpoint albums restituisce lista corretta. Test SSE streaming verifica formato eventi progress/complete/error. Test integrazione con ExtractionAgent. Test cancellation interrompe estrazione in corso.",
            "parentId": "6"
          },
          {
            "id": "4",
            "title": "UI Extract Page con Album Browser Tree View",
            "description": "Creare la pagina Svelte per l'estrazione con componente tree view navigabile per sfogliare la struttura album della Photos Library.",
            "dependencies": [
              3
            ],
            "details": "1. Creare `src/routes/extract/+page.svelte` con layout a due colonne: sidebar album + area principale\n2. Implementare componente `src/lib/components/custom/AlbumTree.svelte` con tree view espandibile\n3. Usare shadcn-svelte Collapsible o implementare tree custom con icone folder/chevron\n4. Fetch album list da endpoint `/agent/extract/albums` on mount\n5. Gestire stati: loading, error, empty con skeleton e messaggi appropriati\n6. Implementare selezione album con highlight visivo dell'album corrente\n7. Mostrare metadata album: numero foto, date range, icona tipo (smart album, folder, user album)\n8. Aggiungere ricerca/filtro album con input search\n9. Supportare selezione multipla album con checkbox\n10. Persistere stato espansione tree in sessionStorage",
            "status": "pending",
            "testStrategy": "Test rendering tree view con mock data album. Test espansione/collasso nodi tree. Test selezione album aggiorna stato. Test filtro ricerca album. Test accessibilità keyboard navigation nel tree.",
            "parentId": "6"
          },
          {
            "id": "5",
            "title": "Implementazione Griglia Preview con Selezione Multipla e Filtri",
            "description": "Sviluppare la griglia di preview foto con virtual scrolling per performance, selezione multipla, e pannello filtri per data, tipo media, e persone riconosciute.",
            "dependencies": [
              4
            ],
            "details": "1. Creare componente `src/lib/components/custom/PhotoGrid.svelte` con griglia responsive\n2. Implementare virtual scrolling per performance con libreria come svelte-virtual-list o custom IntersectionObserver\n3. Ogni thumbnail mostra: preview image, filename, badge tipo (photo/video/live)\n4. Selezione multipla con: click singolo toggle, Shift+click range, Ctrl/Cmd+click additive\n5. Toolbar con: Select All, Deselect All, count selezionati\n6. Creare pannello filtri `src/lib/components/custom/PhotoFilters.svelte`:\n   - DateRangePicker per filtro data (usare shadcn Calendar)\n   - Select per tipo media: All, Photos, Videos, Live Photos\n   - Autocomplete per persone (faces riconosciuti da Photos)\n7. Progress bar durante estrazione con eventi SSE\n8. Implementare lazy loading thumbnails con placeholder blur\n9. Drag selection con mouse per selezione area",
            "status": "pending",
            "testStrategy": "Test rendering griglia con 100+ items verifica virtual scrolling funziona. Test selezione multipla con Shift/Ctrl. Test filtri aggiornano lista foto. Test progress bar si aggiorna con SSE events. Test accessibilità selezione con keyboard.",
            "parentId": "6"
          },
          {
            "id": "6",
            "title": "Integrazione Preservazione EXIF e Metadata Faces/Labels per Suggerimenti AI",
            "description": "Implementare la preservazione completa dei metadata EXIF durante export e integrare i dati faces/labels di Apple Photos con il sistema RAG per suggerimenti automatici di tag.",
            "dependencies": [
              2,
              5
            ],
            "details": "1. Verificare che ExtractionAgent preservi tutti i campi EXIF durante export: GPS, DateTime, Camera, Lens, etc.\n2. Creare `python/agents/metadata_extractor.py` per parsing strutturato metadata:\n   - EXIF data completo con piexif o exifread\n   - Labels ML Apple (scene detection, objects)\n   - Face info con nomi persone riconosciute\n3. Implementare `src/lib/services/tag-suggestions.ts` per suggerimenti tag:\n   - Combinare labels ML + faces + EXIF location\n   - Interfaccia con sistema RAG (dipendenza task 5)\n4. Creare componente `src/lib/components/custom/TagSuggestions.svelte` che mostra chip suggeriti\n5. Endpoint FastAPI `GET /agent/extract/suggestions/{uuid}` per suggerimenti AI per foto\n6. Aggiungere modal dettaglio foto che mostra: preview full, EXIF completo, faces, labels, tag suggeriti\n7. Permettere accettazione/rifiuto tag suggeriti con feedback per migliorare suggerimenti futuri\n8. Batch suggestions per foto multiple selezionate",
            "status": "pending",
            "testStrategy": "Test che EXIF sia effettivamente preservato confrontando metadata originale vs esportato. Test estrazione faces/labels da foto reali. Test suggerimenti tag combinano correttamente tutte le fonti. Test UI mostra suggerimenti e permette accept/reject.",
            "parentId": "6"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "media-processing",
          "phase-2-core",
          "python",
          "osxphotos"
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Setup osxphotos in ambiente Python e test accesso Photos library con gestione permessi macOS Full Disk Access, 2) Implementazione ExtractionAgent class con metodi list_albums e extract_photos, 3) Creazione endpoint FastAPI /agent/extract con progress streaming SSE, 4) UI extract page con album browser tree view, 5) Implementazione griglia preview con selezione multipla e filtri (data, tipo, persone), 6) Integrazione preservazione EXIF e metadata faces/labels per suggerimenti AI"
      },
      {
        "id": "7",
        "title": "Integrazione Cloudinary MCP per Editing Agent",
        "description": "Implementare l'agente di editing che utilizza i server MCP ufficiali di Cloudinary per trasformazioni media avanzate come background removal, upscale e auto-crop.",
        "details": "1. Configurare Cloudinary MCP in `.mcp.json`:\n```json\n{\n  \"mcpServers\": {\n    \"cloudinary\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@cloudinary/mcp-server\"],\n      \"env\": {\n        \"CLOUDINARY_URL\": \"cloudinary://...\"\n      }\n    }\n  }\n}\n```\n2. Creare `python/agents/editing_agent.py`:\n```python\nfrom cagent import Agent, Tool\n\nclass EditingAgent(Agent):\n    tools = [\n        Tool('cloudinary_upload', 'Carica media su Cloudinary'),\n        Tool('cloudinary_transform', 'Applica trasformazioni'),\n        Tool('cloudinary_remove_bg', 'Rimuovi sfondo'),\n        Tool('cloudinary_upscale', 'Upscale immagine'),\n    ]\n    \n    async def process_media(self, media_path: str, transformations: List[str]):\n        # Esegui trasformazioni via MCP\n        pass\n```\n3. Creare UI in `src/routes/edit/+page.svelte`:\n   - Preview prima/dopo trasformazione\n   - Pannello trasformazioni con preset\n   - Slider per parametri (qualità, dimensioni)\n   - Batch processing per multiple immagini\n4. Implementare cache locale per preview\n5. Gestione quota Cloudinary e fallback",
        "testStrategy": "Test con mock MCP server per Cloudinary. Test UI per selezione trasformazioni. Test batch processing con multiple immagini.",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Configurazione Cloudinary MCP Server in .mcp.json",
            "description": "Aggiungere la configurazione del server MCP Cloudinary al file .mcp.json esistente, includendo il comando npx per il package @cloudinary/mcp-server e le variabili ambiente necessarie per l'autenticazione.",
            "dependencies": [],
            "details": "1. Aprire il file `.mcp.json` esistente che già contiene la configurazione task-master-ai\n2. Aggiungere una nuova entry `cloudinary` nell'oggetto `mcpServers`\n3. Configurare il comando: `\"command\": \"npx\"` con args `[\"-y\", \"@cloudinary/mcp-server\"]`\n4. Aggiungere le variabili ambiente: `CLOUDINARY_URL` (formato cloudinary://API_KEY:API_SECRET@CLOUD_NAME), `CLOUDINARY_CLOUD_NAME`, `CLOUDINARY_API_KEY`, `CLOUDINARY_API_SECRET`\n5. Creare file `.env.example` con placeholder per le credenziali Cloudinary\n6. Documentare nel README come ottenere le credenziali dalla dashboard Cloudinary",
            "status": "pending",
            "testStrategy": "Verificare che il server MCP Cloudinary si avvii correttamente con `npx @cloudinary/mcp-server`. Testare la connessione con credenziali valide. Verificare che non ci siano conflitti con altri server MCP configurati.",
            "parentId": "7"
          },
          {
            "id": "2",
            "title": "Implementazione EditingAgent Python con wrapper MCP tools",
            "description": "Creare l'agente Python per l'editing che incapsula le chiamate ai tool MCP di Cloudinary, gestendo upload, trasformazioni, background removal e upscale delle immagini.",
            "dependencies": [
              1
            ],
            "details": "1. Creare la directory `python/agents/` se non esiste\n2. Creare `python/agents/editing_agent.py` con classe `EditingAgent`\n3. Implementare metodi wrapper per tool MCP:\n   - `upload_media(file_path: str) -> str` - Carica su Cloudinary e ritorna public_id\n   - `apply_transform(public_id: str, transformations: dict) -> str` - Applica trasformazioni\n   - `remove_background(public_id: str) -> str` - Rimuovi sfondo con AI\n   - `upscale_image(public_id: str, scale: float) -> str` - Upscale con IA\n   - `auto_crop(public_id: str, aspect_ratio: str) -> str` - Crop intelligente\n4. Implementare gestione errori e retry logic per chiamate MCP\n5. Creare types/models per input/output delle trasformazioni\n6. Aggiungere logging per debug delle operazioni MCP",
            "status": "pending",
            "testStrategy": "Creare mock del server MCP Cloudinary per test unitari. Testare ogni metodo wrapper con mock responses. Testare error handling con simulazione di errori di rete e API.",
            "parentId": "7"
          },
          {
            "id": "3",
            "title": "UI Edit Page con preview before/after e pannello trasformazioni",
            "description": "Creare la pagina di editing in Svelte con visualizzazione side-by-side prima/dopo le trasformazioni, pannello per selezionare e configurare le trasformazioni disponibili.",
            "dependencies": [
              2
            ],
            "details": "1. Creare `src/routes/edit/+page.svelte` come pagina principale di editing\n2. Implementare componente `BeforeAfterPreview.svelte`:\n   - Layout split-view con slider trascinabile\n   - Immagine originale a sinistra, trasformata a destra\n   - Opzione toggle per view overlay\n3. Creare `TransformationsPanel.svelte` con:\n   - Lista preset trasformazioni (background removal, upscale 2x/4x, auto-crop)\n   - Slider per parametri regolabili (qualità 1-100, dimensioni)\n   - Pulsanti per applicare/annullare trasformazioni\n4. Implementare store Svelte 5 `editing-state.svelte.ts` per:\n   - Immagine corrente e cronologia trasformazioni\n   - Stato loading per ogni operazione\n   - Undo/redo stack\n5. Integrare con EditingAgent tramite IPC per operazioni reali",
            "status": "pending",
            "testStrategy": "Test E2E con Playwright per interazioni UI. Test del componente BeforeAfterPreview con immagini di test. Test dello slider trasformazioni. Test dello store per undo/redo.",
            "parentId": "7"
          },
          {
            "id": "4",
            "title": "Implementazione batch processing con progress tracking",
            "description": "Estendere l'UI e l'agent per supportare l'elaborazione batch di multiple immagini con barra di progresso, gestione code e possibilità di annullamento.",
            "dependencies": [
              3
            ],
            "details": "1. Creare componente `BatchProcessor.svelte` con:\n   - Drag-drop zone per upload multiplo\n   - Lista immagini in coda con status individuale\n   - Barra progresso globale e per-immagine\n   - Pulsanti pausa/riprendi/annulla\n2. Implementare `BatchQueue` class in EditingAgent:\n   - Coda FIFO con priorità opzionale\n   - Processamento parallelo configurabile (max concurrent)\n   - Gestione errori senza bloccare la coda\n   - Emit eventi per aggiornamento progress\n3. Creare `batch-progress.svelte.ts` store per:\n   - Tracking stato ogni immagine (pending/processing/done/error)\n   - Percentuale completamento globale\n   - Tempo stimato rimanente\n4. Implementare IPC handlers per streaming progress updates\n5. Salvare risultati batch in directory configurabile",
            "status": "pending",
            "testStrategy": "Test batch con 10+ immagini di varie dimensioni. Test annullamento a metà elaborazione. Test gestione errori per immagini corrotte. Test progress tracking accuracy.",
            "parentId": "7"
          },
          {
            "id": "5",
            "title": "Cache locale preview e gestione quota Cloudinary con fallback",
            "description": "Implementare sistema di cache locale per le preview delle trasformazioni, monitoraggio quota Cloudinary e meccanismo di fallback per quando la quota è esaurita.",
            "dependencies": [
              4
            ],
            "details": "1. Creare `src/lib/services/preview-cache.ts`:\n   - Cache LRU in memoria con limite configurabile\n   - Persistenza su disco per preview già generate\n   - Chiave cache basata su hash immagine + parametri trasformazione\n   - TTL configurabile per invalidazione\n2. Implementare `CloudinaryQuotaManager` in `quota-manager.ts`:\n   - Polling periodico API Cloudinary per usage stats\n   - Threshold warning (80%) e critical (95%)\n   - Emit eventi per notifiche UI\n3. Creare fallback chain:\n   - Primario: Cloudinary cloud\n   - Secondario: Processamento locale con Sharp (npm)\n   - Notifica utente quando in modalità fallback\n4. UI per visualizzare stato quota:\n   - Badge nell'header con % utilizzo\n   - Modal dettagli quota quando cliccato\n5. Configurazione in settings per soglie e comportamento fallback",
            "status": "pending",
            "testStrategy": "Test cache hit/miss con immagini identiche. Test invalidazione cache. Test threshold quota con mock API responses. Test fallback a Sharp quando quota esaurita. Test performance confronto cache vs non-cache.",
            "parentId": "7"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "media-processing",
          "phase-3-agents",
          "python",
          "cloudinary"
        ],
        "complexity": 5,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Configurazione Cloudinary MCP Server in .mcp.json con variabili ambiente, 2) Implementazione EditingAgent Python con wrapper MCP tools, 3) UI Edit Page con preview before/after e pannello trasformazioni, 4) Implementazione batch processing con progress tracking, 5) Cache locale preview e gestione quota Cloudinary con fallback"
      },
      {
        "id": "8",
        "title": "Native RAG con SQLite e Captioning Agent",
        "description": "Implementare il sistema RAG nativo di Cagent con storage SQLite locale per knowledge base del brand, e l'agente di captioning che genera descrizioni contestuali.",
        "details": "1. Creare struttura `resources/brand-assets/` per documenti brand\n2. Creare `resources/vector-store/` per SQLite embeddings\n3. Implementare `python/rag/indexer.py`:\n```python\nimport sqlite3\nfrom sentence_transformers import SentenceTransformer\n\nclass BrandKnowledgeBase:\n    def __init__(self, db_path: str):\n        self.db = sqlite3.connect(db_path)\n        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n        self._init_schema()\n    \n    def index_document(self, doc_path: str, doc_type: str):\n        # Estrai testo, genera embeddings, salva in SQLite\n        pass\n    \n    def search(self, query: str, top_k: int = 5) -> List[Dict]:\n        query_embedding = self.model.encode(query)\n        # Ricerca similarità coseno\n        pass\n```\n4. Creare `python/agents/captioning_agent.py`:\n   - Integrazione con RAG per contesto brand\n   - Generazione caption per piattaforma (IG, LinkedIn, Twitter)\n   - Tone of voice personalizzabile\n   - Hashtag suggestions\n5. UI in `src/routes/edit/+page.svelte` sezione captions:\n   - Editor caption con preview per piattaforma\n   - Suggerimenti AI in tempo reale\n   - Storico captions generate",
        "testStrategy": "Test unitari per indexing e search RAG. Test qualità caption generate con metriche. Test integrazione con brand guidelines.",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Setup SQLite Vector Store e Schema per Embeddings",
            "description": "Creare la struttura delle directory e lo schema del database SQLite per memorizzare gli embeddings vettoriali della knowledge base del brand.",
            "dependencies": [],
            "details": "1. Creare directory `resources/brand-assets/` per documenti brand (PDF, TXT, MD)\n2. Creare directory `resources/vector-store/` per database SQLite\n3. Implementare schema SQLite in `python/rag/schema.py`:\n   - Tabella `documents`: id, path, doc_type, content, created_at, updated_at\n   - Tabella `embeddings`: id, document_id, chunk_text, embedding (BLOB), chunk_index\n   - Tabella `metadata`: key, value per configurazione\n4. Creare script di inizializzazione database con indici per ricerca efficiente\n5. Implementare migration system per futuri aggiornamenti schema",
            "status": "pending",
            "testStrategy": "Test unitari per creazione schema, verifica integrità database, test inserimento e recupero dati base.",
            "parentId": "8"
          },
          {
            "id": "2",
            "title": "Implementazione BrandKnowledgeBase con Sentence-Transformers",
            "description": "Sviluppare la classe BrandKnowledgeBase per l'indicizzazione dei documenti brand utilizzando sentence-transformers per la generazione degli embeddings.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `python/rag/indexer.py` con classe BrandKnowledgeBase\n2. Inizializzare SentenceTransformer con modello 'all-MiniLM-L6-v2'\n3. Implementare `index_document()` per:\n   - Leggere documento da path (supporto PDF, TXT, MD)\n   - Chunking intelligente del testo (overlap windows)\n   - Generazione embeddings per ogni chunk\n   - Salvataggio in SQLite con serializzazione numpy\n4. Implementare `index_directory()` per batch indexing\n5. Gestire aggiornamento incrementale documenti esistenti\n6. Logging progressi indicizzazione",
            "status": "pending",
            "testStrategy": "Test indexing con documenti sample di vari formati, verifica embeddings dimensione corretta (384 dim), test persistence nel database.",
            "parentId": "8"
          },
          {
            "id": "3",
            "title": "Creazione Funzione Search con Cosine Similarity",
            "description": "Implementare la funzionalità di ricerca semantica con calcolo della similarità coseno per recuperare i documenti più rilevanti dalla knowledge base.",
            "dependencies": [
              2
            ],
            "details": "1. Implementare metodo `search()` in BrandKnowledgeBase:\n   - Generare embedding della query\n   - Caricare embeddings da SQLite\n   - Calcolare cosine similarity vettoriale\n   - Ordinare risultati per score decrescente\n2. Ottimizzare con numpy vectorization per performance\n3. Implementare caching query frequenti\n4. Aggiungere filtri per doc_type e date range\n5. Restituire top_k risultati con metadata (path, chunk, score)\n6. Implementare threshold minimo di similarità configurabile",
            "status": "pending",
            "testStrategy": "Test ricerca con query note, verifica ranking corretto, benchmark performance con dataset di test, test edge cases (query vuota, nessun match).",
            "parentId": "8"
          },
          {
            "id": "4",
            "title": "Implementazione CaptioningAgent con Integrazione RAG",
            "description": "Sviluppare l'agente di captioning che utilizza il sistema RAG per generare descrizioni contestuali basate sulla knowledge base del brand.",
            "dependencies": [
              3
            ],
            "details": "1. Creare `python/agents/captioning_agent.py` con classe CaptioningAgent\n2. Integrare BrandKnowledgeBase per recupero contesto brand\n3. Implementare `generate_caption()` con parametri:\n   - media_description: descrizione immagine/video\n   - platform: target social platform\n   - tone_of_voice: stile comunicazione\n   - context_query: query per RAG\n4. Costruire prompt dinamico con:\n   - Contesto brand da RAG (top 3 chunks)\n   - Guidelines piattaforma specifica\n   - Tone of voice richiesto\n5. Supportare streaming output per UI realtime\n6. Generare suggerimenti hashtag pertinenti",
            "status": "pending",
            "testStrategy": "Test generazione caption con mock LLM, verifica inclusione contesto brand, test qualità output per diverse piattaforme e tone of voice.",
            "parentId": "8"
          },
          {
            "id": "5",
            "title": "UI Caption Editor con Preview e Suggestions AI",
            "description": "Creare l'interfaccia utente per l'editing delle caption con preview per piattaforma, suggerimenti AI in tempo reale e storico delle caption generate.",
            "dependencies": [
              4
            ],
            "details": "1. Estendere `src/routes/edit/+page.svelte` con sezione captions\n2. Creare componenti:\n   - CaptionEditor: textarea con character counter per piattaforma\n   - PlatformPreview: mockup visivo post per IG/LinkedIn/Twitter\n   - HashtagSuggestions: chip selezionabili con hashtag suggeriti\n   - CaptionHistory: lista caption precedenti con riutilizzo\n3. Implementare debounced AI suggestions durante typing\n4. Aggiungere indicatori limiti caratteri per piattaforma\n5. Preview responsive che simula aspetto reale del post\n6. Salvataggio bozze automatico in localStorage",
            "status": "pending",
            "testStrategy": "Test componenti UI con testing library, test character counting, test responsive design, test interazione con mock API suggestions.",
            "parentId": "8"
          },
          {
            "id": "6",
            "title": "Supporto Multi-Piattaforma con Tone of Voice Configurabile",
            "description": "Implementare il supporto completo per Instagram, LinkedIn e Twitter con profili tone of voice personalizzabili e ottimizzazioni specifiche per ogni piattaforma.",
            "dependencies": [
              5
            ],
            "details": "1. Creare `src/lib/config/platforms.ts` con configurazioni:\n   - Instagram: 2200 char limit, 30 hashtags, emoji-friendly\n   - LinkedIn: 3000 char limit, professionale, hashtag moderati\n   - Twitter/X: 280 char limit, conciso, 2-3 hashtag\n2. Implementare `src/lib/config/tone-profiles.ts`:\n   - Profili predefiniti: professionale, casual, engaging, informativo\n   - Editor profili custom con sliders (formalità, emoji usage, etc.)\n3. Creare store Svelte per preferenze utente\n4. Adattare CaptioningAgent per rispettare constraints piattaforma\n5. UI selector piattaforma con icone e switch rapido\n6. Salvataggio preferenze tone of voice per brand",
            "status": "pending",
            "testStrategy": "Test limiti caratteri per piattaforma, test generazione con diversi tone profiles, test persistenza preferenze, test UI selectors.",
            "parentId": "8"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "media-processing",
          "phase-3-agents",
          "python",
          "rag"
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Setup SQLite vector store e schema per embeddings, 2) Implementazione BrandKnowledgeBase con sentence-transformers per indexing documenti, 3) Creazione funzione search con cosine similarity, 4) Implementazione CaptioningAgent con integrazione RAG per contesto brand, 5) UI Caption Editor con preview per piattaforma e suggestions AI, 6) Supporto multi-piattaforma (IG, LinkedIn, Twitter) con tone of voice configurabile"
      },
      {
        "id": "9",
        "title": "Integrazione Postiz API e Scheduling Agent",
        "description": "Implementare l'agente di scheduling che utilizza l'API Postiz per pubblicare contenuti su multiple piattaforme social con analytics webhook.",
        "details": "1. Creare `src/lib/services/postiz.ts`:\n```typescript\nconst POSTIZ_BASE_URL = 'https://api.postiz.com/v1';\n\nexport class PostizClient {\n  constructor(private apiKey: string) {}\n  \n  async schedulePost(post: {\n    content: string;\n    media: string[];\n    platforms: string[];\n    scheduledAt: Date;\n  }) {\n    return fetch(`${POSTIZ_BASE_URL}/posts`, {\n      method: 'POST',\n      headers: { 'Authorization': `Bearer ${this.apiKey}` },\n      body: JSON.stringify(post)\n    });\n  }\n  \n  async getAnalytics(postId: string) { /* ... */ }\n}\n```\n2. Creare `python/agents/scheduling_agent.py`:\n   - Ottimizzazione orari pubblicazione per piattaforma\n   - Suggerimenti basati su analytics storici\n   - Gestione code pubblicazione\n3. Creare UI in `src/routes/publish/+page.svelte`:\n   - Form scheduling con date picker\n   - Preview post per ogni piattaforma\n   - Lista post schedulati\n4. Implementare webhook listener in main process per analytics\n5. Salvare analytics in SQLite locale\n6. Piattaforme: Instagram, Facebook, LinkedIn, Twitter, TikTok",
        "testStrategy": "Test con mock Postiz API. Test UI per scheduling flow. Test webhook processing. Test E2E per flusso completo di pubblicazione.",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Creazione PostizClient TypeScript con metodi API completi",
            "description": "Implementare il client TypeScript per l'API Postiz con tutti i metodi necessari: schedulePost per la programmazione dei post, getAnalytics per recuperare le metriche, cancelPost per annullare pubblicazioni e getScheduledPosts per elencare i post programmati.",
            "dependencies": [],
            "details": "Creare `src/lib/services/postiz.ts` con la classe PostizClient che incapsula tutte le chiamate REST all'API Postiz. Implementare gestione errori robusta con retry logic, tipizzazione TypeScript completa per request/response, e supporto per rate limiting. Includere metodi: schedulePost(post), getAnalytics(postId), cancelPost(postId), getScheduledPosts(), updatePost(postId, updates). Utilizzare fetch con timeout configurabile e headers di autenticazione Bearer token.",
            "status": "pending",
            "testStrategy": "Test unitari con mock fetch per ogni metodo API. Test gestione errori (401, 429 rate limit, 500). Test retry logic. Test tipizzazione con dati malformati.",
            "parentId": "9"
          },
          {
            "id": "2",
            "title": "Implementazione SchedulingAgent Python con ottimizzazione orari",
            "description": "Creare l'agente Python di scheduling che analizza gli analytics storici per suggerire orari di pubblicazione ottimali per ogni piattaforma social, gestendo code di pubblicazione intelligenti.",
            "dependencies": [
              1
            ],
            "details": "Creare `python/agents/scheduling_agent.py` estendendo la classe Agent di cagent. Implementare logica di ottimizzazione orari basata su: engagement rate storico per fascia oraria, best practices per piattaforma (es. LinkedIn mattina, Instagram sera), analisi pattern utente specifici. Gestire coda pubblicazioni con priorità e conflict resolution. Esporre tool MCP: suggest_best_time(platform, content_type), optimize_schedule(posts_batch), get_platform_insights(platform).",
            "status": "pending",
            "testStrategy": "Test unitari per algoritmo ottimizzazione con dataset mock. Test suggerimenti per ogni piattaforma. Test gestione coda con conflitti temporali. Test integrazione con PostizClient tramite mock.",
            "parentId": "9"
          },
          {
            "id": "3",
            "title": "UI Publish Page con form scheduling e preview multi-piattaforma",
            "description": "Sviluppare l'interfaccia utente completa per la pubblicazione in `src/routes/publish/+page.svelte` con form di scheduling, date picker, preview per ogni piattaforma e lista post schedulati.",
            "dependencies": [
              1
            ],
            "details": "Creare pagina Svelte 5 con: form scheduling usando componenti shadcn-svelte (Input, Textarea, DatePicker, Select per piattaforme), preview real-time del post adattato a ogni piattaforma selezionata (diversi limiti caratteri, aspect ratio immagini), upload media con drag-drop, lista post schedulati con filtri per data/piattaforma/status, azioni quick (modifica, cancella, duplica). Utilizzare store Svelte 5 runes per stato reattivo. Integrare con PostizClient via IPC per operazioni CRUD.",
            "status": "pending",
            "testStrategy": "Test componenti UI con Vitest e Testing Library. Test form validation. Test preview rendering per ogni piattaforma. Test interazioni utente (scheduling, cancellazione). Test E2E del flusso completo.",
            "parentId": "9"
          },
          {
            "id": "4",
            "title": "Implementazione webhook listener in Electron main process",
            "description": "Creare un server HTTP nel main process Electron per ricevere webhook di analytics da Postiz, processando e inoltrando i dati al renderer process tramite IPC.",
            "dependencies": [
              1
            ],
            "details": "Creare `electron/webhook-server.ts` con server HTTP Express/Fastify leggero su porta configurabile. Implementare endpoint POST /webhooks/postiz/analytics per ricevere notifiche. Validare signature webhook per sicurezza. Parsare payload analytics (impressions, engagement, clicks, shares per post). Inoltrare dati al renderer via IPC per aggiornamento UI real-time. Gestire lifecycle server (start/stop con app). Implementare retry queue per webhook falliti. Configurare ngrok/localtunnel per sviluppo locale.",
            "status": "pending",
            "testStrategy": "Test server HTTP con supertest. Test validazione signature. Test parsing payload analytics. Test IPC communication con mock. Test resilienza a webhook malformati.",
            "parentId": "9"
          },
          {
            "id": "5",
            "title": "Storage analytics SQLite con query e visualizzazione grafici",
            "description": "Implementare lo storage locale degli analytics in SQLite con schema ottimizzato per query temporali e creare componenti di visualizzazione con grafici storici delle performance.",
            "dependencies": [
              4
            ],
            "details": "Estendere schema SQLite in `src/lib/db/schema.ts` con tabelle: post_analytics (post_id, platform, timestamp, impressions, engagement, clicks, shares), daily_aggregates (date, platform, totals). Creare `src/lib/services/analytics-storage.ts` con metodi: saveAnalytics(), getAnalyticsByPost(), getAnalyticsByPlatform(), getTimeRangeAggregates(). Creare componenti grafici in `src/lib/components/analytics/` usando libreria charts (Chart.js o similar): EngagementChart, PlatformComparison, TimelinePerformance. Implementare filtri data range e export CSV.",
            "status": "pending",
            "testStrategy": "Test CRUD SQLite per analytics. Test query aggregazioni temporali. Test rendering grafici con dati mock. Test filtri e export. Test performance con grandi dataset.",
            "parentId": "9"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "publishing",
          "phase-3-agents",
          "python",
          "postiz"
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Creazione PostizClient TypeScript con metodi API completi (schedulePost, getAnalytics, cancelPost), 2) Implementazione SchedulingAgent Python con ottimizzazione orari per piattaforma, 3) UI Publish Page con form scheduling, date picker e preview multi-piattaforma, 4) Implementazione webhook listener in Electron main process per analytics, 5) Storage analytics SQLite locale con query e visualizzazione grafici storici"
      },
      {
        "id": "10",
        "title": "Integrazione Timeline Twick con A2UI Widgets",
        "description": "Integrare il componente timeline Twick per visualizzazione scheduling e implementare il protocollo A2UI per generazione dinamica di widget UI dagli agenti.",
        "details": "1. Installare Twick: `npm install @twick/svelte`\n2. Creare `src/routes/timeline/+page.svelte`:\n```svelte\n<script>\n  import { Timeline, Event } from '@twick/svelte';\n  import { scheduledPosts } from '$lib/stores/scheduling.svelte';\n</script>\n<Timeline>\n  {#each $scheduledPosts as post}\n    <Event date={post.scheduledAt} title={post.platform}>\n      <AgentWidget type={post.widgetType} data={post.data} />\n    </Event>\n  {/each}\n</Timeline>\n```\n3. Implementare `src/lib/components/agent-widgets/` sistema A2UI:\n   - `WidgetRegistry.ts` - registro componenti dinamici\n   - `AgentWidget.svelte` - renderer componente dinamico\n   - Widget types: MediaPreview, CaptionEditor, ScheduleCard, AnalyticsChart\n4. Protocollo A2UI in FastAPI:\n```python\n@app.post(\"/a2ui/generate\")\nasync def generate_widget(request: Request):\n    data = await request.json()\n    widget_spec = agent.generate_ui(data['context'])\n    return {\"widget\": widget_spec}\n```\n5. SSE streaming per aggiornamenti real-time dei widget\n6. Drag-drop per riordinare eventi timeline\n7. Integrazione con scheduling agent per date/orari",
        "testStrategy": "Test rendering timeline con mock data. Test drag-drop functionality. Test SSE updates per widget. Test integrazione A2UI con agenti.",
        "priority": "medium",
        "dependencies": [
          "1",
          "4",
          "9"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Installazione e Configurazione Twick con Verifica Compatibilità Svelte 5 Runes",
            "description": "Installare il pacchetto @twick/svelte e verificare la compatibilità con Svelte 5 runes. Creare wrapper se necessario per gestire eventuali incompatibilità con il nuovo sistema reattivo di Svelte 5.",
            "dependencies": [],
            "details": "1. Eseguire `npm install @twick/svelte` per installare il pacchetto\n2. Verificare se Twick supporta nativamente Svelte 5 runes controllando la documentazione e i peer dependencies\n3. Testare l'import base di Timeline e Event components in un file .svelte di test\n4. Se Twick non supporta Svelte 5 runes, creare un wrapper component in `src/lib/components/timeline/TwickWrapper.svelte` che:\n   - Converte i runes ($state, $derived) in props legacy\n   - Gestisce le differenze nel lifecycle (onMount vs $effect)\n   - Fornisce slot forwarding per contenuto dinamico\n5. Documentare eventuali workaround necessari in un commento nel file wrapper\n6. Creare un file di test `src/lib/components/timeline/Twick.test.ts` per verificare il rendering base",
            "status": "pending",
            "testStrategy": "Test di rendering con Vitest + @testing-library/svelte per verificare che Timeline e Event si rendono correttamente. Test di compatibilità con props reactive usando Svelte 5 runes syntax. Verificare che non ci siano warning di deprecation nella console.",
            "parentId": "10"
          },
          {
            "id": "2",
            "title": "Creazione Timeline Page con Store scheduledPosts e Integrazione Base",
            "description": "Creare la pagina timeline in SvelteKit con lo store Svelte 5 per i post schedulati e l'integrazione base con il componente Twick Timeline.",
            "dependencies": [
              1
            ],
            "details": "1. Creare lo store Svelte 5 `src/lib/stores/scheduling.svelte.ts` usando runes:\n```typescript\nimport { $state } from 'svelte';\n\nexport interface ScheduledPost {\n  id: string;\n  platform: 'instagram' | 'tiktok' | 'youtube' | 'twitter';\n  scheduledAt: Date;\n  content: string;\n  media: string[];\n  widgetType: 'MediaPreview' | 'CaptionEditor' | 'ScheduleCard' | 'AnalyticsChart';\n  data: Record<string, unknown>;\n  status: 'pending' | 'published' | 'failed';\n}\n\nexport const scheduledPosts = $state<ScheduledPost[]>([]);\n```\n2. Creare la route `src/routes/timeline/+page.svelte` con layout base\n3. Implementare il rendering condizionale per stati vuoti/loading\n4. Aggiungere stili Tailwind per il layout della timeline\n5. Creare `+page.ts` per eventual server-side data loading",
            "status": "pending",
            "testStrategy": "Test unitari per lo store scheduledPosts verificando operazioni CRUD. Test di rendering della pagina timeline con mock data. Test di navigazione verso /timeline route. Verificare responsive design con viewport diversi.",
            "parentId": "10"
          },
          {
            "id": "3",
            "title": "Implementazione Sistema A2UI con WidgetRegistry e AgentWidget Dinamico",
            "description": "Creare il sistema Agent-to-UI (A2UI) che permette la registrazione e il rendering dinamico di widget UI generati dagli agenti, con supporto per tipi multipli di widget.",
            "dependencies": [
              1,
              2
            ],
            "details": "1. Creare la directory `src/lib/components/agent-widgets/`\n2. Implementare `WidgetRegistry.ts` come singleton pattern:\n```typescript\ntype WidgetComponent = typeof import('*.svelte').default;\nclass WidgetRegistry {\n  private widgets = new Map<string, WidgetComponent>();\n  register(type: string, component: WidgetComponent): void;\n  get(type: string): WidgetComponent | undefined;\n  has(type: string): boolean;\n}\nexport const widgetRegistry = new WidgetRegistry();\n```\n3. Creare i widget base:\n   - `MediaPreview.svelte` - anteprima immagini/video con thumbnail\n   - `CaptionEditor.svelte` - editor inline per caption con character count\n   - `ScheduleCard.svelte` - card con date picker e platform selector\n   - `AnalyticsChart.svelte` - mini chart per metriche engagement\n4. Implementare `AgentWidget.svelte` con dynamic component rendering:\n```svelte\n<script>\n  import { widgetRegistry } from './WidgetRegistry';\n  export let type: string;\n  export let data: Record<string, unknown>;\n  $: Component = widgetRegistry.get(type);\n</script>\n{#if Component}\n  <svelte:component this={Component} {...data} />\n{/if}\n```\n5. Registrare tutti i widget all'avvio dell'app",
            "status": "pending",
            "testStrategy": "Test unitari per WidgetRegistry verificando register/get/has. Test di rendering per ogni widget type con mock data. Test di AgentWidget con dynamic type switching. Verificare error handling per widget type sconosciuti.",
            "parentId": "10"
          },
          {
            "id": "4",
            "title": "Protocollo A2UI in FastAPI per Generazione Widget Specs",
            "description": "Implementare l'endpoint FastAPI per la generazione di specifiche widget basate sul contesto dell'agente, con schema di validazione e supporto per diversi tipi di widget.",
            "dependencies": [],
            "details": "1. Creare `python/api/a2ui.py` con l'endpoint principale:\n```python\nfrom fastapi import APIRouter, HTTPException\nfrom pydantic import BaseModel\nfrom typing import Literal, Dict, Any\n\nrouter = APIRouter(prefix='/a2ui')\n\nclass WidgetContext(BaseModel):\n    agent_id: str\n    post_id: str\n    context_type: Literal['preview', 'edit', 'schedule', 'analytics']\n    metadata: Dict[str, Any] = {}\n\nclass WidgetSpec(BaseModel):\n    type: Literal['MediaPreview', 'CaptionEditor', 'ScheduleCard', 'AnalyticsChart']\n    data: Dict[str, Any]\n    actions: list[str] = []\n\n@router.post('/generate', response_model=WidgetSpec)\nasync def generate_widget(context: WidgetContext) -> WidgetSpec:\n    # Logic per generare widget spec basata su context\n    pass\n```\n2. Implementare la logica di generazione widget per ogni tipo di contesto\n3. Aggiungere validazione input con Pydantic\n4. Registrare il router nel main.py FastAPI\n5. Creare schema JSON per widget specs esportabile al frontend\n6. Implementare caching per widget specs frequenti con Redis/memoria",
            "status": "pending",
            "testStrategy": "Test API con pytest e httpx per endpoint /a2ui/generate. Test di validazione Pydantic per input malformati. Test per ogni tipo di context (preview, edit, schedule, analytics). Verificare response schema matching con frontend types.",
            "parentId": "10"
          },
          {
            "id": "5",
            "title": "SSE Streaming Real-time per Updates Widget e Drag-Drop Reordering Eventi",
            "description": "Implementare Server-Sent Events per aggiornamenti real-time dei widget e funzionalità drag-and-drop per riordinare gli eventi nella timeline con persistenza delle modifiche.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "1. Creare endpoint SSE in FastAPI `python/api/sse.py`:\n```python\nfrom fastapi import APIRouter\nfrom fastapi.responses import StreamingResponse\nimport asyncio\n\nrouter = APIRouter()\n\nasync def event_generator():\n    while True:\n        updates = await get_widget_updates()\n        if updates:\n            yield f\"data: {json.dumps(updates)}\\n\\n\"\n        await asyncio.sleep(1)\n\n@router.get('/stream/widgets')\nasync def widget_stream():\n    return StreamingResponse(event_generator(), media_type='text/event-stream')\n```\n2. Creare `src/lib/services/sse-client.ts` per gestire connessione SSE lato frontend\n3. Implementare reconnection logic con exponential backoff\n4. Integrare gli update SSE nello store scheduledPosts\n5. Implementare drag-and-drop in Timeline usando @twick/svelte API o libreria custom:\n   - Event handlers per dragstart, dragover, drop\n   - Visual feedback durante drag\n   - Animazioni smooth per reorder\n6. Creare endpoint `PATCH /timeline/reorder` per persistere nuovo ordine\n7. Ottimistic UI update con rollback su errore\n8. Integrare con scheduling agent per validare nuove date/orari",
            "status": "pending",
            "testStrategy": "Test SSE connection con mock server. Test reconnection logic simulando disconnessioni. Test drag-drop con Playwright E2E. Test persistenza ordine con API mock. Verificare che updates SSE aggiornino correttamente lo store. Test di concorrenza per multiple sessioni che modificano la timeline.",
            "parentId": "10"
          }
        ],
        "tags": [
          "frontend",
          "ui-framework",
          "phase-4-integration",
          "svelte",
          "twick"
        ],
        "complexity": 7,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Installazione e configurazione Twick con verifica compatibilità Svelte 5 runes, 2) Creazione Timeline Page con store scheduledPosts, 3) Implementazione sistema A2UI con WidgetRegistry e AgentWidget dinamico, 4) Protocollo A2UI in FastAPI per generazione widget specs, 5) SSE streaming real-time per updates widget e drag-drop reordering eventi"
      },
      {
        "id": "11",
        "title": "Orchestrator Agent e Comunicazione A2A",
        "description": "Implementare l'agente orchestratore che coordina tutti gli altri agenti specializzati, gestendo il protocollo A2A (Agent-to-Agent) per passaggio contesto e handoff.",
        "details": "1. Creare `python/agents/orchestrator_agent.py`:\n```python\nfrom cagent import Agent, Handoff\n\nclass OrchestratorAgent(Agent):\n    name = 'orchestrator'\n    description = 'Coordina il workflow completo di gestione media'\n    \n    sub_agents = [\n        'extraction_agent',\n        'editing_agent', \n        'captioning_agent',\n        'scheduling_agent'\n    ]\n    \n    async def process_request(self, user_request: str, context: Dict):\n        # Analizza richiesta e determina workflow\n        workflow = self.plan_workflow(user_request)\n        \n        results = {}\n        for step in workflow:\n            agent = self.get_agent(step.agent_name)\n            result = await agent.execute(step.task, context={**context, **results})\n            results[step.agent_name] = result\n            \n            # Notifica UI via SSE\n            await self.emit_event('step_complete', {\n                'agent': step.agent_name,\n                'result': result\n            })\n        \n        return results\n    \n    def plan_workflow(self, request: str) -> List[WorkflowStep]:\n        # LLM determina sequenza agenti\n        pass\n```\n2. Implementare protocollo A2A:\n   - Schema contesto condiviso\n   - Handoff con preservazione stato\n   - Error handling e retry\n3. Dashboard orchestrazione in `src/routes/+page.svelte`:\n   - Visualizzazione workflow attivo\n   - Status ogni agente\n   - Interruzione/pausa workflow\n4. Logging conversazioni agenti per debug",
        "testStrategy": "Test unitari per planning workflow. Test A2A handoff tra agenti. Test error recovery. Test E2E per workflow completo extraction->edit->caption->schedule.",
        "priority": "high",
        "dependencies": [
          "6",
          "7",
          "8",
          "9"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Definizione Protocollo A2A con Schema Contesto Condiviso",
            "description": "Progettare e implementare il protocollo Agent-to-Agent (A2A) con uno schema tipizzato per il contesto condiviso tra agenti, includendo serializzazione e validazione dei dati.",
            "dependencies": [],
            "details": "Creare `python/protocols/a2a_protocol.py` con:\n1. Definizione Pydantic models per A2AContext:\n   - `SharedContext`: dati condivisi (media_paths, metadata, user_preferences)\n   - `AgentState`: stato corrente dell'agente (status, progress, errors)\n   - `HandoffPayload`: payload per trasferimento tra agenti\n2. Definire `A2AMessage` con fields: sender, receiver, action, context, timestamp, correlation_id\n3. Implementare `ContextValidator` per validazione schema prima di handoff\n4. Creare `ContextSerializer` per JSON serialization con supporto per tipi complessi (datetime, Path, bytes)\n5. Definire enum `A2AAction`: START, HANDOFF, COMPLETE, ERROR, ROLLBACK\n6. Implementare versioning dello schema per backward compatibility",
            "status": "pending",
            "testStrategy": "Test unitari per validazione schema con dati validi/invalidi. Test serializzazione/deserializzazione roundtrip. Test versioning schema con payload legacy.",
            "parentId": "11"
          },
          {
            "id": "2",
            "title": "Implementazione OrchestratorAgent Base con Registro Sub-Agents",
            "description": "Creare la classe OrchestratorAgent con sistema di registrazione dinamica degli agenti specializzati e discovery automatico.",
            "dependencies": [
              1
            ],
            "details": "Creare `python/agents/orchestrator_agent.py`:\n1. Classe `OrchestratorAgent` che estende `Agent` dal cagent framework\n2. Implementare `AgentRegistry` con:\n   - `register_agent(name, agent_class)`: registra agente\n   - `get_agent(name)`: recupera istanza agente\n   - `list_agents()`: lista agenti disponibili\n   - `agent_capabilities`: mapping nome -> capabilities\n3. Auto-discovery agenti da `python/agents/` usando importlib\n4. Implementare `AgentPool` per gestione istanze con lazy initialization\n5. Definire interfaccia `ISpecializedAgent` che tutti gli agenti devono implementare\n6. Metodo `validate_agents()` per verificare tutti i sub-agents siano disponibili\n7. Configurazione agenti via YAML/JSON per flessibilità deployment",
            "status": "pending",
            "testStrategy": "Test registrazione/deregistrazione agenti. Test discovery automatico. Test lazy initialization. Test con mock agents per isolamento.",
            "parentId": "11"
          },
          {
            "id": "3",
            "title": "Implementazione Workflow Planner con LLM",
            "description": "Sviluppare il sistema di pianificazione workflow che utilizza LLM per analizzare richieste utente e determinare la sequenza ottimale di agenti da invocare.",
            "dependencies": [
              2
            ],
            "details": "Creare `python/agents/workflow_planner.py`:\n1. Classe `WorkflowPlanner` con metodo `plan_workflow(user_request, available_agents) -> List[WorkflowStep]`\n2. `WorkflowStep` dataclass: agent_name, task_description, expected_inputs, expected_outputs, timeout\n3. Prompt engineering per LLM:\n   - System prompt con descrizione capabilities ogni agente\n   - Few-shot examples per workflow comuni\n   - Output strutturato JSON per parsing affidabile\n4. Implementare `WorkflowOptimizer` per:\n   - Parallelizzazione step indipendenti\n   - Eliminazione step ridondanti\n   - Stima durata workflow\n5. Cache LRU per workflow comuni (hash della richiesta)\n6. Fallback a regole statiche se LLM non disponibile\n7. Validazione workflow: verifica dipendenze soddisfatte, agenti esistenti",
            "status": "pending",
            "testStrategy": "Test con mock LLM responses. Test parsing output strutturato. Test ottimizzazione parallelismo. Test fallback regole statiche. Test cache hit/miss.",
            "parentId": "11"
          },
          {
            "id": "4",
            "title": "Sistema Handoff con Preservazione Stato e Checkpoint",
            "description": "Implementare il meccanismo di handoff tra agenti con salvataggio dello stato per permettere rollback e recovery in caso di errori.",
            "dependencies": [
              1,
              2
            ],
            "details": "Creare `python/protocols/handoff_manager.py`:\n1. Classe `HandoffManager` con:\n   - `initiate_handoff(from_agent, to_agent, context)`: avvia trasferimento\n   - `complete_handoff(handoff_id)`: conferma completamento\n   - `rollback_handoff(handoff_id)`: ripristina stato precedente\n2. Sistema checkpoint:\n   - `CheckpointStore` con storage SQLite per persistenza\n   - Salvataggio automatico prima di ogni handoff\n   - Metadata: timestamp, agent_state, context_snapshot\n3. Implementare `StateSnapshot` per deep copy dello stato agente\n4. `HandoffTransaction` per garantire atomicità:\n   - Prepare -> Commit/Rollback pattern\n   - Timeout automatico per handoff pendenti\n5. Event emitter per notifiche handoff (start, complete, rollback)\n6. Cleanup automatico checkpoint vecchi (configurable retention)",
            "status": "pending",
            "testStrategy": "Test handoff completo tra agenti mock. Test rollback dopo errore. Test persistenza checkpoint. Test recovery dopo crash simulato. Test cleanup automatico.",
            "parentId": "11"
          },
          {
            "id": "5",
            "title": "Error Handling Robusto con Retry Policies e Circuit Breaker",
            "description": "Implementare sistema di gestione errori avanzato con retry configurabili, circuit breaker pattern e graceful degradation.",
            "dependencies": [
              4
            ],
            "details": "Creare `python/resilience/error_handler.py`:\n1. `RetryPolicy` configurabile:\n   - max_retries, backoff_strategy (exponential, linear, fixed)\n   - retry_exceptions: lista eccezioni da ritentare\n   - on_retry callback per logging/metriche\n2. `CircuitBreaker` per ogni agente:\n   - Stati: CLOSED, OPEN, HALF_OPEN\n   - failure_threshold, recovery_timeout, success_threshold\n   - Metriche: failure_count, last_failure_time\n3. `ErrorClassifier` per categorizzare errori:\n   - Transient (retry), Permanent (fail fast), Unknown\n4. `GracefulDegradation` strategies:\n   - Skip agent non critico\n   - Use cached result\n   - Partial workflow completion\n5. `ErrorAggregator` per raccogliere errori multipli in workflow\n6. Integration con logging strutturato per troubleshooting\n7. Alerting hooks per errori critici",
            "status": "pending",
            "testStrategy": "Test retry con diverse policies. Test circuit breaker state transitions. Test graceful degradation scenarios. Test error classification accuracy. Test alerting hooks.",
            "parentId": "11"
          },
          {
            "id": "6",
            "title": "Dashboard Orchestrazione UI con Workflow Visualization Real-time",
            "description": "Sviluppare l'interfaccia utente Svelte per visualizzare lo stato del workflow in tempo reale con controlli per pausa, interruzione e dettagli agenti.",
            "dependencies": [
              3,
              4
            ],
            "details": "Creare/estendere `src/routes/+page.svelte` e componenti:\n1. `WorkflowVisualization.svelte`:\n   - Grafo workflow con nodi agenti e frecce transizioni\n   - Colori stato: pending (grigio), running (blu), complete (verde), error (rosso)\n   - Animazioni transizioni handoff\n2. `AgentStatusCard.svelte` per ogni agente:\n   - Nome, descrizione, stato corrente\n   - Progress bar se disponibile\n   - Ultimo output/errore\n3. Controlli workflow:\n   - Pulsante Pause/Resume\n   - Pulsante Stop con conferma\n   - Pulsante Retry per step falliti\n4. SSE listener per aggiornamenti real-time da backend\n5. Store Svelte `workflowStore` per stato globale workflow\n6. Timeline laterale con cronologia eventi\n7. Modal dettagli per inspect contesto ogni step",
            "status": "pending",
            "testStrategy": "Test componenti con Vitest. Test SSE updates con mock server. Test controlli UI (pause, stop, retry). Test E2E flusso completo con Playwright.",
            "parentId": "11"
          },
          {
            "id": "7",
            "title": "Logging e Tracing Conversazioni Agenti per Debug",
            "description": "Implementare sistema completo di logging strutturato e distributed tracing per tracciare conversazioni e interazioni tra agenti a fini di debug e analisi.",
            "dependencies": [
              5
            ],
            "details": "Creare `python/observability/agent_logger.py`:\n1. `StructuredLogger` con output JSON:\n   - Fields: timestamp, correlation_id, agent_name, action, payload, duration_ms\n   - Log levels: DEBUG, INFO, WARN, ERROR con filtering\n2. `ConversationTracer` per A2A:\n   - Trace ID unico per ogni workflow\n   - Span per ogni step agente\n   - Parent-child relationships per nested calls\n3. `LogStore` con SQLite per query storiche:\n   - Ricerca per correlation_id, agent, timerange\n   - Aggregazioni per analytics\n4. UI componente `DebugPanel.svelte`:\n   - Vista conversazioni per workflow\n   - Filtri per agente/livello\n   - Export logs come JSON\n5. Integration con Python logging module\n6. Log rotation e cleanup automatico\n7. Sensitive data masking (API keys, tokens)",
            "status": "pending",
            "testStrategy": "Test structured logging output format. Test correlation ID propagation. Test query storiche su LogStore. Test UI filtri e export. Test masking dati sensibili.",
            "parentId": "11"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "phase-3-agents",
          "python",
          "cagent"
        ],
        "complexity": 9,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Espandi in subtask: 1) Definizione protocollo A2A con schema contesto condiviso, 2) Implementazione OrchestratorAgent base con registro sub-agents, 3) Implementazione Workflow Planner con LLM per determinare sequenza agenti, 4) Sistema handoff con preservazione stato e checkpoint per rollback, 5) Error handling robusto con retry policies e circuit breaker, 6) Dashboard orchestrazione UI con workflow visualization real-time, 7) Logging e tracing conversazioni agenti per debug"
      },
      {
        "id": "12",
        "title": "Brand Management UI e Asset Organization",
        "description": "Creare l'interfaccia per gestione brand con organizzazione assets, upload documenti brand guidelines per RAG, e configurazione profili social.",
        "details": "1. Creare `src/routes/brands/+page.svelte`:\n   - Lista brand cards con logo e stats\n   - Modal creazione nuovo brand\n2. Creare `src/routes/brands/[brandId]/+page.svelte`:\n```svelte\n<script>\n  import { page } from '$app/stores';\n  import { Tabs, TabsContent } from '$lib/components/ui/tabs';\n</script>\n<Tabs>\n  <TabsContent value=\"assets\">\n    <!-- Griglia assets del brand -->\n  </TabsContent>\n  <TabsContent value=\"guidelines\">\n    <!-- Upload PDF/docs per RAG indexing -->\n  </TabsContent>\n  <TabsContent value=\"social\">\n    <!-- Configurazione account social -->\n  </TabsContent>\n  <TabsContent value=\"analytics\">\n    <!-- Dashboard analytics aggregati -->\n  </TabsContent>\n</Tabs>\n```\n3. Implementare upload documenti con indexing automatico RAG\n4. Creare store brand con SQLite backend\n5. Componenti:\n   - AssetGrid con filtri e ricerca\n   - BrandColorPalette estratta da guidelines\n   - SocialAccountConnector per OAuth",
        "testStrategy": "Test CRUD operazioni brand. Test upload e indexing documenti. Test UI per navigazione brand e assets.",
        "priority": "medium",
        "dependencies": [
          "1",
          "8"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Creazione Route Brands con Lista Brand Cards e Modal Creazione",
            "description": "Implementare la pagina principale `src/routes/brands/+page.svelte` con griglia di BrandCard per ogni brand registrato, includendo logo, statistiche e azioni rapide. Creare il modal per l'inserimento di nuovi brand con form validation.",
            "dependencies": [],
            "details": "1. Creare `src/routes/brands/+page.svelte` con layout griglia responsiva CSS Grid/Flexbox\n2. Implementare componente `BrandCard.svelte` che mostra: logo brand, nome, numero assets, data ultima modifica, badge stato\n3. Creare `CreateBrandModal.svelte` con form shadcn (Input, Button, Dialog):\n   - Campo nome brand (required, min 2 caratteri)\n   - Upload logo (preview immagine, max 2MB)\n   - Descrizione opzionale\n   - Selezione colore primario\n4. Aggiungere bottone 'Nuovo Brand' che apre il modal\n5. Implementare stati empty state quando non ci sono brand\n6. Collegare al brandStore per fetch lista brands all'onMount\n7. Gestire loading states e error handling con toast notifications",
            "status": "pending",
            "testStrategy": "Test unitari per rendering BrandCard con vari stati (con/senza logo, diverse statistiche). Test form validation per modal creazione (campi required, limiti caratteri, dimensione file). Test E2E per flusso creazione nuovo brand completo. Verificare layout responsivo su viewport mobile/tablet/desktop.",
            "parentId": "12"
          },
          {
            "id": "2",
            "title": "Implementazione Route brands/[brandId] con Sistema Tabs",
            "description": "Creare la pagina dettaglio brand dinamica `src/routes/brands/[brandId]/+page.svelte` con navigazione a tabs per assets, guidelines, social accounts e analytics dashboard.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `src/routes/brands/[brandId]/+page.svelte` con estrazione brandId da $page.params\n2. Implementare header brand con logo grande, nome, descrizione, edit button\n3. Configurare shadcn Tabs con 4 TabsContent:\n   - 'assets': placeholder per AssetGrid\n   - 'guidelines': placeholder per upload documenti\n   - 'social': placeholder per SocialAccountConnector\n   - 'analytics': placeholder per dashboard metriche\n4. Implementare URL persistence del tab attivo via query params (?tab=assets)\n5. Aggiungere page.ts per load function che fetcha dati brand\n6. Gestire 404 per brandId inesistente con redirect o error page\n7. Implementare breadcrumb navigation (Home > Brands > [Brand Name])\n8. Loading skeleton states per ogni tab durante fetch dati",
            "status": "pending",
            "testStrategy": "Test navigazione tra tabs e verifica contenuto corretto per ogni tab. Test URL persistence del tab selezionato dopo refresh pagina. Test 404 handling per brandId inesistenti. Test loading states durante fetch. Verificare che $page.params.brandId venga correttamente estratto e utilizzato.",
            "parentId": "12"
          },
          {
            "id": "3",
            "title": "Sistema Upload Documenti con RAG Indexing Automatico",
            "description": "Implementare l'interfaccia upload documenti brand guidelines (PDF, DOCX, MD) nel tab guidelines con pipeline di indexing automatico nel sistema RAG per ricerca semantica.",
            "dependencies": [
              2
            ],
            "details": "1. Creare `GuidelinesUploader.svelte` nel tab guidelines con:\n   - Drag & drop zone per file upload\n   - Supporto formati: PDF, DOCX, MD, TXT\n   - Preview lista documenti caricati con metadata\n   - Progress bar durante upload e indexing\n2. Implementare IPC handler 'documents:upload' in main process:\n   - Salvataggio file in cartella brand-specific\n   - Estrazione testo con librerie appropriate (pdf-parse, mammoth)\n3. Creare pipeline RAG indexing:\n   - Chunking documenti (500-1000 token per chunk con overlap)\n   - Generazione embeddings via provider LLM configurato\n   - Storage in vector database locale (sqlite-vec o chromadb)\n4. UI per visualizzare stato indexing per ogni documento\n5. Bottone per ri-indicizzare documento modificato\n6. Delete documento con rimozione da vector store",
            "status": "pending",
            "testStrategy": "Test upload file di vari formati (PDF, DOCX, MD) verificando salvataggio corretto. Test estrazione testo da PDF multi-pagina e DOCX con formattazione. Test chunking con verifica overlap e dimensioni. Test generazione embeddings con mock provider. Test query RAG con documenti di test e risultati attesi. Test UI stati upload (progress, success, error) e indexing status.",
            "parentId": "12"
          },
          {
            "id": "4",
            "title": "Store Brand con SQLite Backend via IPC",
            "description": "Creare lo store Svelte reattivo per gestione stato brands con persistenza SQLite tramite comunicazione IPC con main process Electron, includendo schema database e operazioni CRUD complete.",
            "dependencies": [],
            "details": "1. Definire schema SQLite in `electron/database/schema.sql`:\n   - Tabella `brands` (id, name, logo_path, description, primary_color, created_at, updated_at)\n   - Tabella `brand_assets` (id, brand_id FK, file_path, type, metadata_json, created_at)\n   - Tabella `brand_documents` (id, brand_id FK, file_path, indexed_at, chunks_count)\n2. Creare `electron/ipc/brandHandlers.ts` con handlers:\n   - 'brands:list' -> SELECT con paginazione\n   - 'brands:get' -> SELECT by id con relazioni\n   - 'brands:create' -> INSERT con validazione\n   - 'brands:update' -> UPDATE con timestamp\n   - 'brands:delete' -> DELETE con cascade assets/documents\n3. Creare `src/lib/stores/brandStore.ts` con Svelte writable:\n   - State: { brands: Brand[], loading: boolean, error: string | null, selectedBrand: Brand | null }\n   - Actions: fetchBrands(), getBrand(id), createBrand(data), updateBrand(id, data), deleteBrand(id)\n4. Implementare caching locale e invalidation strategy\n5. Gestire optimistic updates per UX migliore",
            "status": "pending",
            "testStrategy": "Test CRUD operations su SQLite con database in-memory. Test IPC handlers con mock database verificando query corrette. Test store Svelte con operazioni async e verifica state updates. Test rollback su errori database con verifica stato consistente. Verificare cascade delete per assets e documents quando brand viene eliminato.",
            "parentId": "12"
          },
          {
            "id": "5",
            "title": "Componenti AssetGrid, BrandColorPalette e SocialAccountConnector",
            "description": "Implementare i tre componenti UI principali: griglia assets con filtri e virtual scrolling, estrattore palette colori da guidelines, e connettore OAuth per account social.",
            "dependencies": [
              2,
              4
            ],
            "details": "1. Creare `AssetGrid.svelte`:\n   - Griglia responsiva con virtual scrolling (svelte-virtual-list o tanstack-virtual)\n   - Filtri per tipo asset (immagine, video, documento)\n   - Ricerca full-text per nome/tag\n   - Selezione multipla con bulk actions (delete, export, tag)\n   - Preview lightbox per immagini\n   - Ordinamento per data, nome, dimensione\n2. Creare `BrandColorPalette.svelte`:\n   - Estrazione automatica colori dominanti da logo/guidelines (color-thief o vibrant.js)\n   - Display palette con hex/rgb values\n   - Copy to clipboard per ogni colore\n   - Salvataggio palette custom nel brand\n3. Creare `SocialAccountConnector.svelte`:\n   - Card per ogni piattaforma (Instagram, TikTok, YouTube, Facebook)\n   - Stato connesso/disconnesso con icone\n   - Bottone Connect che avvia OAuth flow\n   - Display account name e avatar quando connesso\n   - Bottone Disconnect con conferma\n   - Placeholder per piattaforme non ancora implementate",
            "status": "pending",
            "testStrategy": "Test AssetGrid con vari numeri di assets (0, 10, 100, 1000+) verificando performance virtual scrolling. Test filtri con combinazioni multiple attive. Test estrazione colori da immagini di test con palette note. Test OAuth flow con mock providers verificando state management. Test UI stati connesso/disconnesso per ogni social account. Test copy to clipboard per colori palette.",
            "parentId": "12"
          }
        ],
        "tags": [
          "frontend",
          "ui-framework",
          "phase-4-integration",
          "svelte"
        ],
        "complexity": 5,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Creazione route brands con lista brand cards e modal creazione, 2) Implementazione route brands/[brandId] con sistema tabs (assets, guidelines, social, analytics), 3) Sistema upload documenti con RAG indexing automatico, 4) Store brand con SQLite backend via IPC, 5) Componenti AssetGrid, BrandColorPalette e SocialAccountConnector"
      },
      {
        "id": "13",
        "title": "Testing Suite Completa e CI/CD Setup",
        "description": "Implementare suite di test completa con unit, integration, e E2E tests, insieme a pipeline CI/CD per build automatiche.",
        "details": "1. Configurare test pyramid:\n   - 70% Unit tests (Vitest per frontend, pytest per Python)\n   - 20% Integration tests (IPC, agent communication)\n   - 10% E2E tests (Playwright)\n2. Creare `tests/` struttura:\n```\ntests/\n├── unit/\n│   ├── components/\n│   ├── services/\n│   └── stores/\n├── integration/\n│   ├── ipc/\n│   ├── agents/\n│   └── rag/\n└── e2e/\n    ├── workflows/\n    └── fixtures/\n```\n3. Test critici da implementare:\n   - Provider configuration validation\n   - Agent handoff context preservation\n   - A2UI component generation safety\n   - Timeline drag-drop scheduling\n   - Twick timeline rendering\n   - Electron context isolation\n4. CI/CD in `.github/workflows/`:\n   - Lint + Type check\n   - Unit tests\n   - Integration tests\n   - E2E tests\n   - Build artefatti per macOS/Windows/Linux\n5. Pre-commit hooks con husky",
        "testStrategy": "Meta-testing: verificare copertura test >80%. Test che CI pipeline completi senza errori. Test build artefatti su tutte le piattaforme.",
        "priority": "medium",
        "dependencies": [
          "11"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Configurazione Test Pyramid e Struttura Directory tests/",
            "description": "Creare la struttura organizzativa delle directory per test unitari, di integrazione ed E2E, configurando la test pyramid con rapporto 70/20/10",
            "dependencies": [],
            "details": "1. Creare la gerarchia di directory tests/ con subdirectory unit/, integration/, e2e/\n2. Configurare sottocartelle specifiche:\n   - tests/unit/components/, tests/unit/services/, tests/unit/stores/\n   - tests/integration/ipc/, tests/integration/agents/, tests/integration/rag/\n   - tests/e2e/workflows/, tests/e2e/fixtures/\n3. Estendere vite.config.ts per includere i nuovi percorsi di test\n4. Configurare vitest workspace per separare test client e server con ambienti appropriati (jsdom per componenti, node per servizi)\n5. Aggiungere script package.json per eseguire test per categoria (test:unit, test:integration, test:e2e)\n6. Creare file di setup vitest-setup-client.ts e vitest-setup-server.ts con mock globali\n7. Documentare la strategia test pyramid nel README con metriche di coverage target (70% unit, 20% integration, 10% E2E)",
            "status": "pending",
            "testStrategy": "Verificare che la struttura directory sia corretta con glob patterns. Test che tutti gli script npm run test:* funzionino correttamente. Validare che le configurazioni Vitest riconoscano i file di test nelle nuove posizioni.",
            "parentId": "13"
          },
          {
            "id": "2",
            "title": "Unit Tests per Componenti Svelte e Servizi TypeScript con Vitest",
            "description": "Implementare suite completa di test unitari per componenti Svelte 5 e servizi TypeScript utilizzando Vitest e Testing Library",
            "dependencies": [
              1
            ],
            "details": "1. Configurare @testing-library/svelte con supporto Svelte 5 runes e componenti\n2. Creare test per componenti UI critici:\n   - Timeline component (rendering, drag-drop handlers)\n   - Provider configuration forms (validazione input)\n   - A2UI generated components (safety checks)\n   - Twick timeline rendering\n3. Test per servizi TypeScript:\n   - IPC service mocking con vi.mock\n   - Store tests (Svelte stores e state management)\n   - API client tests con mock fetch\n4. Configurare coverage reporter (istanbul/v8) con soglia minima 70%\n5. Aggiungere snapshot testing per componenti UI stabili\n6. Creare helper utilities per render testing di componenti con contesto Svelte\n7. Mock per Electron APIs (contextBridge, ipcRenderer) nei test client\n8. Test per provider configuration validation con casi edge",
            "status": "pending",
            "testStrategy": "Eseguire npm run test:unit con --coverage. Verificare che coverage sia >= 70% per src/. Test matrix per browser environments diversi. Controllare che tutti i componenti critici abbiano test dedicati.",
            "parentId": "13"
          },
          {
            "id": "3",
            "title": "Unit Tests Python per Agenti e Sistema RAG con pytest",
            "description": "Creare suite di test unitari Python con pytest per il sistema di agenti Cagent e il modulo RAG con embeddings",
            "dependencies": [
              1
            ],
            "details": "1. Configurare pytest in python/ directory con pytest.ini e conftest.py\n2. Creare fixtures condivise per:\n   - Mock FastAPI TestClient\n   - Database SQLite in-memory per RAG tests\n   - Fake embeddings model per test veloci\n3. Test per agent communication:\n   - Handoff context preservation tra agenti\n   - Agent state machine transitions\n   - Tool invocation mocking\n4. Test per sistema RAG:\n   - Document indexing con embeddings mock\n   - Similarity search accuracy\n   - Brand knowledge base queries\n5. Test per captioning agent:\n   - Caption generation con mock LLM\n   - Brand guidelines adherence\n6. Configurare pytest-cov per coverage Python >= 80%\n7. Aggiungere pytest-asyncio per test async FastAPI endpoints\n8. Creare test parametrizzati per diverse configurazioni agente",
            "status": "pending",
            "testStrategy": "Eseguire pytest python/tests/ --cov=python/ --cov-report=html. Verificare coverage >= 80%. Test isolation con database in-memory. Validare che tutti gli agenti e RAG components abbiano coverage adeguata.",
            "parentId": "13"
          },
          {
            "id": "4",
            "title": "Integration Tests per IPC e Agent Communication",
            "description": "Implementare test di integrazione per il bridge IPC tra Electron main/renderer e la comunicazione con il Python sidecar",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "1. Creare test framework per IPC integration:\n   - Mock Electron main process per test isolati\n   - Test contextBridge exposed APIs\n   - Verifica context isolation attivo\n2. Test IPC handlers:\n   - Keychain save/get/delete operations\n   - Provider API invocations\n   - Error propagation tra processi\n3. Test agent communication end-to-end:\n   - HTTP/SSE streaming dal Python sidecar\n   - Agent handoff con context preservation\n   - Timeout e retry logic\n4. Test RAG integration:\n   - Document upload attraverso IPC\n   - Query e retrieval pipeline\n5. Configurare test database SQLite per integration tests\n6. Mock external APIs (Postiz, provider APIs) con msw o simili\n7. Test health check polling del sidecar\n8. Verifica gestione errori di rete e reconnection",
            "status": "pending",
            "testStrategy": "Eseguire integration tests in ambiente isolato con mock server. Verificare che IPC messages siano correttamente serializzati/deserializzati. Test di stress per connessioni SSE. Coverage target 20% del totale test.",
            "parentId": "13"
          },
          {
            "id": "5",
            "title": "E2E Tests per Workflow Critici con Playwright",
            "description": "Implementare test end-to-end con Playwright per validare i flussi utente critici dell'applicazione Electron",
            "dependencies": [
              1,
              4
            ],
            "details": "1. Estendere playwright.config.ts per Electron testing:\n   - Configurare electronPath per app packaging\n   - Setup fixture per app instance\n   - Screenshot e video recording su failure\n2. Test workflow critici:\n   - Provider configuration flow completo (add, validate, save)\n   - Timeline drag-drop scheduling operations\n   - Content generation e preview\n   - Posting workflow con scheduling\n3. Creare fixtures directory con:\n   - Test media assets (images, videos)\n   - Mock API responses\n   - Pre-configured app states\n4. Test A2UI component generation:\n   - Safety checks per generated code\n   - Rendering validation\n5. Test multi-window scenarios se applicabile\n6. Configurare retries e timeout appropriati per CI\n7. Parallel test execution con sharding\n8. Accessibility testing con axe-playwright",
            "status": "pending",
            "testStrategy": "Eseguire npx playwright test con --trace on-failure. Verificare che tutti i workflow critici passino. Test su multiple browser (chromium minimo per Electron). Visual regression testing per UI consistency.",
            "parentId": "13"
          },
          {
            "id": "6",
            "title": "CI/CD Pipeline GitHub Actions con Build Multi-Piattaforma",
            "description": "Configurare pipeline CI/CD completa in GitHub Actions per test automatici, build multi-piattaforma e code signing",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "1. Creare .github/workflows/ci.yml con jobs:\n   - lint: ESLint + TypeScript type check\n   - test-unit: Vitest unit tests con coverage\n   - test-python: pytest per Python sidecar\n   - test-integration: Integration tests\n   - test-e2e: Playwright E2E (dopo build)\n2. Creare .github/workflows/build.yml:\n   - Build matrix: macOS-latest, windows-latest, ubuntu-latest\n   - electron-forge make per artefatti nativi\n   - Upload artifacts per ogni piattaforma\n3. Configurare code signing:\n   - macOS: Apple Developer ID con notarization\n   - Windows: Code signing certificate\n   - Secrets per certificati in GitHub Secrets\n4. Setup pre-commit hooks con husky:\n   - lint-staged per ESLint/Prettier\n   - Commit message validation\n   - Type check pre-push\n5. Configurare Dependabot per security updates\n6. Badge di status nel README\n7. Cache per node_modules e Python venv\n8. Conditional builds su tag per release",
            "status": "pending",
            "testStrategy": "Verificare che CI pipeline completi senza errori su ogni push. Test manuale dei build artefatti su tutte le piattaforme. Validare che code signing funzioni correttamente su macOS e Windows. Controllare che husky hooks si attivino correttamente.",
            "parentId": "13"
          }
        ],
        "tags": [
          "infrastructure",
          "testing",
          "phase-5-polish"
        ],
        "complexity": 6,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Configurazione test pyramid e struttura directory tests/ (unit, integration, e2e), 2) Unit tests per componenti Svelte e servizi TypeScript con Vitest, 3) Unit tests Python per agenti e sistema RAG con pytest, 4) Integration tests per IPC e agent communication, 5) E2E tests per workflow critici con Playwright, 6) CI/CD pipeline GitHub Actions con build multi-piattaforma e code signing"
      },
      {
        "id": "14",
        "title": "Electron Packaging e Distribuzione",
        "description": "Configurare il packaging finale dell'applicazione Electron con bundling Python sidecar, code signing, e setup per distribuzione.",
        "details": "1. Configurare Electron Forge in `forge.config.ts`:\n   - Maker DMG per macOS con notarization\n   - Maker Squirrel per Windows\n   - Maker DEB/RPM per Linux\n2. Bundling Python sidecar:\n   - Opzione A: PyInstaller per creare eseguibile standalone\n   - Opzione B: Embedded Python con venv\n```typescript\n// forge.config.ts\nconst config = {\n  packagerConfig: {\n    extraResource: ['./python-dist'],\n    osxSign: { identity: '...' },\n    osxNotarize: { appleId: '...', appleIdPassword: '...' }\n  },\n  makers: [\n    { name: '@electron-forge/maker-dmg', config: {} },\n    { name: '@electron-forge/maker-squirrel', config: {} },\n  ]\n};\n```\n3. Gestione aggiornamenti automatici con electron-updater\n4. Configurare code signing per macOS e Windows\n5. Setup GitHub Releases per distribuzione\n6. Documentazione installazione per utenti finali\n7. Verificare bundle size target: ~2.5MB (escludendo Python)",
        "testStrategy": "Test build su macOS, Windows, Linux. Test installazione pulita su sistema vergine. Test auto-update flow. Verificare code signing valido.",
        "priority": "low",
        "dependencies": [
          "11",
          "13"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": "1",
            "title": "Configurazione Electron Forge Maker DMG con Notarization macOS",
            "description": "Configurare il maker DMG in forge.config.ts con supporto completo per code signing e notarization Apple, necessario per distribuzione su macOS Sequoia e versioni successive.",
            "dependencies": [],
            "details": "1. Aggiungere MakerDMG alla configurazione in forge.config.ts sostituendo MakerZIP per darwin\n2. Configurare packagerConfig con osxSign:\n   - identity: Developer ID Application certificate\n   - optionsForFile: funzione per configurare entitlements\n3. Configurare osxNotarize con:\n   - appleId: email sviluppatore Apple\n   - appleIdPassword: app-specific password (da Keychain @keychain:AC_PASSWORD)\n   - teamId: Apple Team ID\n4. Creare file entitlements.plist con capabilities necessarie (hardened-runtime, allow-unsigned-executable-memory per Python sidecar)\n5. Configurare environment variables in .env per credenziali Apple (APPLE_ID, APPLE_ID_PASSWORD, APPLE_TEAM_ID)\n6. Testare build locale con `npm run make` e verificare firma con `codesign -dv --verbose=4`\n7. Verificare notarization con `spctl -a -v` e `stapler validate`",
            "status": "pending",
            "testStrategy": "Eseguire build DMG su macOS e verificare: 1) codesign -dv mostra firma valida, 2) spctl -a -v approva l'app, 3) Gatekeeper non blocca l'apertura su sistema pulito, 4) Console.app non mostra errori di notarization.",
            "parentId": "14"
          },
          {
            "id": "2",
            "title": "Configurazione Maker Squirrel Windows con Code Signing Authenticode",
            "description": "Configurare MakerSquirrel per Windows con supporto Authenticode code signing, creazione installer NSIS/Squirrel, e gestione icone e metadata applicazione.",
            "dependencies": [],
            "details": "1. Configurare MakerSquirrel in forge.config.ts con opzioni:\n   - name: nome applicazione senza spazi\n   - authors: nome autore per metadata\n   - exe: nome eseguibile finale\n   - setupIcon: percorso icona .ico\n   - loadingGif: splash screen opzionale\n   - certificateFile: path al certificato .pfx\n   - certificatePassword: password certificato (da env var WINDOWS_CERTIFICATE_PASSWORD)\n2. Creare script PowerShell per signing: `sign-windows.ps1` con signtool.exe\n3. Configurare packagerConfig per Windows:\n   - icon: percorso icona .ico\n   - win32metadata: CompanyName, FileDescription, ProductName\n4. Aggiungere hook afterSign per verifica firma\n5. Creare assets: icon.ico (256x256, 128x128, 64x64, 48x48, 32x32, 16x16)\n6. Configurare environment variables: WINDOWS_CERTIFICATE_FILE, WINDOWS_CERTIFICATE_PASSWORD\n7. Documentare acquisizione certificato Authenticode (DigiCert, Sectigo, etc.)",
            "status": "pending",
            "testStrategy": "Test su Windows: 1) Eseguire build con `npm run make`, 2) Verificare firma con signtool verify /pa, 3) Installare su Windows vergine e verificare UAC non mostri 'publisher sconosciuto', 4) Testare uninstall completo.",
            "parentId": "14"
          },
          {
            "id": "3",
            "title": "Bundling Python Sidecar con PyInstaller Cross-Platform",
            "description": "Creare sistema di bundling per il Python sidecar usando PyInstaller, con build separati per macOS (universal2), Windows (x64), e Linux (x64/arm64), inclusi tutti i moduli Cagent.",
            "dependencies": [],
            "details": "1. Creare python/pyinstaller.spec con configurazione:\n   - Analysis: main.py come entry, hidden imports per FastAPI, uvicorn, sse-starlette, cagent\n   - Exclude: tkinter, matplotlib, test modules per ridurre size\n   - Datas: includere assets e config necessari\n   - hiddenimports: tutti i moduli dinamici di cagent e MCP tools\n2. Creare script build-python.sh / build-python.ps1:\n   - Attivare venv\n   - pip install -r requirements.txt\n   - pyinstaller --onefile --windowed (macOS) / --onefile (Windows/Linux)\n   - Copiare output in ./python-dist/\n3. Configurare forge.config.ts extraResource: ['./python-dist']\n4. Modificare main.ts per trovare sidecar in resources path:\n   - process.resourcesPath per production\n   - __dirname per development\n5. Creare Makefile/package.json scripts per build cross-platform\n6. Target size: ~50MB per sidecar (Python + dipendenze)\n7. Verificare che sidecar parta correttamente da extraResources",
            "status": "pending",
            "testStrategy": "Per ogni piattaforma: 1) Build sidecar con PyInstaller, 2) Eseguire standalone e verificare endpoint /health, 3) Package app Electron e verificare sidecar in Resources, 4) Test avvio app e comunicazione IPC con sidecar, 5) Verificare size finale < 100MB totale.",
            "parentId": "14"
          },
          {
            "id": "4",
            "title": "Implementazione Auto-Update con electron-updater e GitHub Releases",
            "description": "Implementare sistema di aggiornamenti automatici usando electron-updater con backend GitHub Releases, includendo UI per notifiche e progress bar download.",
            "dependencies": [
              1,
              2
            ],
            "details": "1. Installare electron-updater: npm install electron-updater\n2. Configurare forge.config.ts per generare file update:\n   - publishers: GitHubPublisher con repo e owner\n   - packagerConfig.protocols: deep link per update\n3. Implementare in main.ts:\n   - autoUpdater.setFeedURL() con GitHub repo\n   - autoUpdater.checkForUpdatesAndNotify() all'avvio\n   - Eventi: checking-for-update, update-available, update-downloaded, error\n4. Creare IPC handlers per comunicare stato update al renderer:\n   - 'update:check', 'update:download', 'update:install'\n5. Implementare componente Svelte UpdateNotification.svelte:\n   - Banner 'Nuovo aggiornamento disponibile'\n   - Progress bar durante download\n   - Pulsante 'Riavvia e Installa'\n6. Configurare electron-builder.yml / forge publishers per:\n   - Generare latest.yml/latest-mac.yml/latest-linux.yml\n   - Upload automatico assets a GitHub Release\n7. Gestire canali: stable, beta (opzionale)\n8. Implementare rollback in caso di update fallito",
            "status": "pending",
            "testStrategy": "1) Creare release v0.0.2 di test su GitHub, 2) Installare v0.0.1, verificare che rilevi update, 3) Testare download progress in UI, 4) Verificare installazione automatica al riavvio, 5) Testare rollback se update corrotto, 6) Verificare firma codice post-update su macOS/Windows.",
            "parentId": "14"
          },
          {
            "id": "5",
            "title": "Setup GitHub Actions CI/CD Pipeline per Build e Publish Automatico",
            "description": "Creare workflow GitHub Actions per build automatico multi-piattaforma, code signing in CI, upload a GitHub Releases, e gestione versioning semantico.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "1. Creare .github/workflows/build.yml per build su ogni push:\n   - Matrix: macos-latest, windows-latest, ubuntu-latest\n   - Cache node_modules e Python venv\n   - npm ci && npm run make\n   - Upload artifacts per testing\n2. Creare .github/workflows/release.yml trigger su tag v*:\n   - Build per tutte le piattaforme in parallelo\n   - macOS: import certificati da secrets, notarize\n   - Windows: import certificato .pfx da secrets, sign\n   - Linux: build DEB e RPM\n   - Upload tutti gli assets a GitHub Release\n3. Configurare GitHub Secrets:\n   - APPLE_ID, APPLE_ID_PASSWORD, APPLE_TEAM_ID, APPLE_CERTIFICATE_P12, APPLE_CERTIFICATE_PASSWORD\n   - WINDOWS_CERTIFICATE_PFX (base64), WINDOWS_CERTIFICATE_PASSWORD\n4. Creare script release.sh per bump version e tag\n5. Configurare electron-forge publish per GitHub:\n   - GITHUB_TOKEN per upload assets\n6. Aggiungere workflow per PR checks (lint, test, build)\n7. Implementare caching aggressivo per ridurre build time",
            "status": "pending",
            "testStrategy": "1) Push branch feature e verificare build passa su tutte le piattaforme, 2) Creare tag v0.1.0-test e verificare release workflow, 3) Verificare assets uploadati correttamente a GitHub Release, 4) Download e installare su ogni OS per verifica E2E, 5) Verificare code signing valido negli artifacts.",
            "parentId": "14"
          },
          {
            "id": "6",
            "title": "Documentazione Installazione e Troubleshooting per Utenti Finali",
            "description": "Creare documentazione completa per installazione su macOS, Windows e Linux, incluse FAQ, troubleshooting per errori comuni, e guida per sviluppatori che vogliono contribuire.",
            "dependencies": [
              4,
              5
            ],
            "details": "1. Creare docs/installation/README.md con sezioni:\n   - Requisiti di sistema (OS version, RAM, disk space)\n   - Download links per ogni piattaforma\n   - Istruzioni passo-passo con screenshot\n2. Creare docs/installation/macos.md:\n   - Gestione Gatekeeper ('app da sviluppatore non identificato')\n   - Permessi Privacy: Accessibilità, Full Disk Access se necessari\n   - Troubleshooting notarization issues\n3. Creare docs/installation/windows.md:\n   - SmartScreen warning per prime esecuzioni\n   - Windows Defender exceptions se necessario\n   - Installazione silente con parametri CLI\n4. Creare docs/installation/linux.md:\n   - Istruzioni per DEB (apt), RPM (yum/dnf), AppImage\n   - Permessi e dipendenze (libsecret per keychain)\n5. Creare docs/troubleshooting.md:\n   - Errori comuni e soluzioni\n   - Come raccogliere logs (Console.app, Event Viewer, journalctl)\n   - Come segnalare bug con template issue\n6. Creare CHANGELOG.md template per release notes\n7. Aggiornare README.md principale con quick start",
            "status": "pending",
            "testStrategy": "1) Far seguire la guida a utente non tecnico su ogni OS, 2) Verificare che tutti i link di download funzionino, 3) Testare ogni scenario di troubleshooting documentato, 4) Review da parte di QA per completezza, 5) Verificare rendering corretto su GitHub.",
            "parentId": "14"
          }
        ],
        "tags": [
          "infrastructure",
          "deployment",
          "phase-5-polish",
          "electron"
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Configurazione Electron Forge Maker DMG con notarization macOS, 2) Configurazione Maker Squirrel Windows con code signing Authenticode, 3) Bundling Python sidecar con PyInstaller cross-platform, 4) Implementazione auto-update con electron-updater e GitHub Releases, 5) Setup GitHub Releases e CI/CD pipeline per publish automatico, 6) Documentazione installazione e troubleshooting per utenti finali"
      },
      {
        "id": "15",
        "title": "Sandboxed osxphotos Process Manager con Isolamento di Sicurezza",
        "description": "Implementare un processo Python completamente isolato in python/sandboxed/ per l'accesso sicuro alla Photos Library di macOS, comunicante esclusivamente via Unix socket con protocollo JSON-RPC 2.0 e supervisione auto-restart con circuit breaker.",
        "details": "## Struttura Directory\n\n```\npython/\n├── sandboxed/\n│   ├── __init__.py\n│   ├── main.py                    # Entry point processo sandboxed\n│   ├── socket_server.py           # Server Unix socket\n│   ├── jsonrpc_handler.py         # Handler JSON-RPC 2.0\n│   ├── photos_service.py          # Wrapper osxphotos\n│   ├── path_validator.py          # Validazione whitelist directory\n│   └── requirements.txt           # Dipendenze isolate\n```\n\n## 1. Unix Socket Server (`socket_server.py`)\n\n```python\nimport socket\nimport os\nimport asyncio\nfrom typing import Callable\n\nSOCKET_PATH = '/tmp/trae-osxphotos.sock'\n\nclass UnixSocketServer:\n    def __init__(self, handler: Callable):\n        self.handler = handler\n        self.socket_path = SOCKET_PATH\n        \n    async def start(self):\n        # Rimuovi socket esistente\n        if os.path.exists(self.socket_path):\n            os.unlink(self.socket_path)\n        \n        server = await asyncio.start_unix_server(\n            self._handle_client,\n            path=self.socket_path\n        )\n        # Permessi restrittivi: solo owner\n        os.chmod(self.socket_path, 0o600)\n        \n        async with server:\n            await server.serve_forever()\n    \n    async def _handle_client(self, reader, writer):\n        try:\n            data = await reader.read(1024 * 1024)  # Max 1MB\n            response = await self.handler(data.decode())\n            writer.write(response.encode())\n            await writer.drain()\n        finally:\n            writer.close()\n            await writer.wait_closed()\n```\n\n## 2. JSON-RPC 2.0 Handler (`jsonrpc_handler.py`)\n\n```python\nimport json\nfrom typing import Dict, Any, Optional\n\nclass JsonRpcHandler:\n    def __init__(self, photos_service):\n        self.photos_service = photos_service\n        self.methods = {\n            'list_albums': self.photos_service.list_albums,\n            'get_photos': self.photos_service.get_photos,\n            'export_photo': self.photos_service.export_photo,\n            'get_photo_metadata': self.photos_service.get_photo_metadata,\n            'search_photos': self.photos_service.search_photos,\n        }\n    \n    async def handle(self, request_str: str) -> str:\n        try:\n            request = json.loads(request_str)\n            \n            # Validazione JSON-RPC 2.0\n            if request.get('jsonrpc') != '2.0':\n                return self._error_response(None, -32600, 'Invalid Request')\n            \n            method = request.get('method')\n            params = request.get('params', {})\n            req_id = request.get('id')\n            \n            if method not in self.methods:\n                return self._error_response(req_id, -32601, 'Method not found')\n            \n            result = await self.methods[method](**params)\n            return self._success_response(req_id, result)\n            \n        except json.JSONDecodeError:\n            return self._error_response(None, -32700, 'Parse error')\n        except Exception as e:\n            return self._error_response(req_id, -32000, str(e))\n    \n    def _success_response(self, id: Any, result: Any) -> str:\n        return json.dumps({\n            'jsonrpc': '2.0',\n            'result': result,\n            'id': id\n        })\n    \n    def _error_response(self, id: Any, code: int, message: str) -> str:\n        return json.dumps({\n            'jsonrpc': '2.0',\n            'error': {'code': code, 'message': message},\n            'id': id\n        })\n```\n\n## 3. Path Validator con Whitelist (`path_validator.py`)\n\n```python\nimport os\nfrom pathlib import Path\nfrom typing import List\n\nclass PathValidator:\n    WHITELIST_DIRECTORIES = [\n        os.path.expanduser('~/Exports/'),\n        os.path.expanduser('~/Documents/TraeExports/'),\n    ]\n    \n    @classmethod\n    def validate_export_path(cls, target_path: str) -> bool:\n        \"\"\"Valida che il path sia nella whitelist e non contenga path traversal.\"\"\"\n        real_path = os.path.realpath(target_path)\n        \n        # Check path traversal\n        if '..' in target_path:\n            raise SecurityError(f'Path traversal detected: {target_path}')\n        \n        # Check whitelist\n        for allowed in cls.WHITELIST_DIRECTORIES:\n            allowed_real = os.path.realpath(allowed)\n            if os.path.commonpath([real_path, allowed_real]) == allowed_real:\n                return True\n        \n        raise SecurityError(f'Path not in whitelist: {target_path}')\n    \n    @classmethod\n    def ensure_directories_exist(cls):\n        \"\"\"Crea le directory whitelist se non esistono.\"\"\"\n        for dir_path in cls.WHITELIST_DIRECTORIES:\n            Path(dir_path).mkdir(parents=True, exist_ok=True)\n\nclass SecurityError(Exception):\n    pass\n```\n\n## 4. Photos Service con osxphotos (`photos_service.py`)\n\n```python\nimport osxphotos\nfrom typing import List, Dict, Optional\nfrom path_validator import PathValidator, SecurityError\n\nclass PhotosService:\n    def __init__(self, photos_db_path: Optional[str] = None):\n        self.photosdb = osxphotos.PhotosDB(dbfile=photos_db_path)\n        PathValidator.ensure_directories_exist()\n    \n    async def list_albums(self) -> List[Dict]:\n        return [\n            {'title': a.title, 'uuid': a.uuid, 'photo_count': len(a.photos)}\n            for a in self.photosdb.album_info\n        ]\n    \n    async def get_photos(\n        self, \n        album_uuid: Optional[str] = None,\n        from_date: Optional[str] = None,\n        to_date: Optional[str] = None,\n        limit: int = 100\n    ) -> List[Dict]:\n        photos = self.photosdb.photos()\n        \n        if album_uuid:\n            album = next((a for a in self.photosdb.album_info if a.uuid == album_uuid), None)\n            if album:\n                photos = album.photos\n        \n        return [\n            {\n                'uuid': p.uuid,\n                'filename': p.original_filename,\n                'date': p.date.isoformat() if p.date else None,\n                'width': p.width,\n                'height': p.height,\n                'has_exif': bool(p.exif_info),\n            }\n            for p in list(photos)[:limit]\n        ]\n    \n    async def export_photo(\n        self, \n        photo_uuid: str, \n        target_directory: str,\n        preserve_exif: bool = True\n    ) -> Dict:\n        # CRITICAL: Validazione whitelist\n        PathValidator.validate_export_path(target_directory)\n        \n        photo = next((p for p in self.photosdb.photos() if p.uuid == photo_uuid), None)\n        if not photo:\n            raise ValueError(f'Photo not found: {photo_uuid}')\n        \n        exported = photo.export(\n            target_directory,\n            use_photos_export=True,\n            exiftool=preserve_exif\n        )\n        \n        return {'exported_path': exported[0] if exported else None}\n    \n    async def get_photo_metadata(self, photo_uuid: str) -> Dict:\n        photo = next((p for p in self.photosdb.photos() if p.uuid == photo_uuid), None)\n        if not photo:\n            raise ValueError(f'Photo not found: {photo_uuid}')\n        \n        return {\n            'uuid': photo.uuid,\n            'filename': photo.original_filename,\n            'date': photo.date.isoformat() if photo.date else None,\n            'exif': photo.exif_info.__dict__ if photo.exif_info else None,\n            'location': {'lat': photo.latitude, 'lon': photo.longitude},\n            'keywords': photo.keywords,\n            'persons': [p.name for p in photo.person_info],\n        }\n```\n\n## 5. Main Entry Point (`main.py`)\n\n```python\nimport asyncio\nimport signal\nimport sys\nimport os\n\n# SECURITY: Blocca accesso network\ndef block_network():\n    \"\"\"Impedisce qualsiasi connessione network.\"\"\"\n    import socket\n    _original_socket = socket.socket\n    \n    def restricted_socket(*args, **kwargs):\n        # Permetti SOLO Unix socket (AF_UNIX)\n        if args and args[0] == socket.AF_UNIX:\n            return _original_socket(*args, **kwargs)\n        raise PermissionError('Network access is disabled in sandboxed process')\n    \n    socket.socket = restricted_socket\n\nblock_network()\n\nfrom socket_server import UnixSocketServer\nfrom jsonrpc_handler import JsonRpcHandler\nfrom photos_service import PhotosService\n\nasync def main():\n    photos_service = PhotosService()\n    handler = JsonRpcHandler(photos_service)\n    server = UnixSocketServer(handler.handle)\n    \n    print(f'[osxphotos-sandbox] Starting on {server.socket_path}', file=sys.stderr)\n    \n    def shutdown_handler(sig, frame):\n        print('[osxphotos-sandbox] Shutting down...', file=sys.stderr)\n        sys.exit(0)\n    \n    signal.signal(signal.SIGTERM, shutdown_handler)\n    signal.signal(signal.SIGINT, shutdown_handler)\n    \n    await server.start()\n\nif __name__ == '__main__':\n    asyncio.run(main())\n```\n\n## 6. Electron Main Process Supervisor (`electron/osxphotos-supervisor.ts`)\n\n```typescript\nimport { spawn, ChildProcess } from 'child_process';\nimport * as path from 'path';\nimport * as net from 'net';\n\ninterface CircuitBreakerState {\n  failures: number;\n  lastFailure: number;\n  isOpen: boolean;\n}\n\nexport class OsxphotosSupervisor {\n  private process: ChildProcess | null = null;\n  private circuitBreaker: CircuitBreakerState = {\n    failures: 0,\n    lastFailure: 0,\n    isOpen: false,\n  };\n  \n  private readonly MAX_FAILURES = 3;\n  private readonly RESET_TIMEOUT_MS = 5 * 60 * 1000; // 5 minuti\n  private readonly SOCKET_PATH = '/tmp/trae-osxphotos.sock';\n  \n  async start(): Promise<void> {\n    if (this.circuitBreaker.isOpen) {\n      const elapsed = Date.now() - this.circuitBreaker.lastFailure;\n      if (elapsed < this.RESET_TIMEOUT_MS) {\n        throw new Error(`Circuit breaker open. Retry in ${Math.ceil((this.RESET_TIMEOUT_MS - elapsed) / 1000)}s`);\n      }\n      // Reset circuit breaker\n      this.circuitBreaker = { failures: 0, lastFailure: 0, isOpen: false };\n    }\n    \n    const pythonPath = this.getPythonPath();\n    const scriptPath = path.join(__dirname, '../python/sandboxed/main.py');\n    \n    this.process = spawn(pythonPath, [scriptPath], {\n      stdio: ['ignore', 'pipe', 'pipe'],\n      env: { ...process.env, PYTHONUNBUFFERED: '1' },\n    });\n    \n    this.process.stderr?.on('data', (data) => {\n      console.log(`[osxphotos-sandbox] ${data.toString().trim()}`);\n    });\n    \n    this.process.on('exit', (code, signal) => {\n      console.log(`[osxphotos-sandbox] Exited with code ${code}, signal ${signal}`);\n      this.handleProcessExit(code);\n    });\n    \n    // Wait for socket to be ready\n    await this.waitForSocket();\n  }\n  \n  private handleProcessExit(code: number | null): void {\n    if (code !== 0) {\n      this.circuitBreaker.failures++;\n      this.circuitBreaker.lastFailure = Date.now();\n      \n      if (this.circuitBreaker.failures >= this.MAX_FAILURES) {\n        this.circuitBreaker.isOpen = true;\n        console.error('[osxphotos-sandbox] Circuit breaker OPEN - max failures reached');\n        return;\n      }\n      \n      // Auto-restart\n      console.log(`[osxphotos-sandbox] Restarting (attempt ${this.circuitBreaker.failures}/${this.MAX_FAILURES})`);\n      setTimeout(() => this.start(), 1000);\n    }\n  }\n  \n  private waitForSocket(timeout = 5000): Promise<void> {\n    return new Promise((resolve, reject) => {\n      const start = Date.now();\n      const check = () => {\n        const socket = net.createConnection(this.SOCKET_PATH);\n        socket.on('connect', () => {\n          socket.destroy();\n          resolve();\n        });\n        socket.on('error', () => {\n          if (Date.now() - start > timeout) {\n            reject(new Error('Socket connection timeout'));\n          } else {\n            setTimeout(check, 100);\n          }\n        });\n      };\n      check();\n    });\n  }\n  \n  async call<T>(method: string, params: Record<string, any> = {}): Promise<T> {\n    return new Promise((resolve, reject) => {\n      const socket = net.createConnection(this.SOCKET_PATH);\n      const request = JSON.stringify({\n        jsonrpc: '2.0',\n        method,\n        params,\n        id: Date.now(),\n      });\n      \n      socket.on('connect', () => {\n        socket.write(request);\n      });\n      \n      socket.on('data', (data) => {\n        const response = JSON.parse(data.toString());\n        socket.destroy();\n        \n        if (response.error) {\n          reject(new Error(response.error.message));\n        } else {\n          resolve(response.result);\n        }\n      });\n      \n      socket.on('error', reject);\n    });\n  }\n  \n  stop(): void {\n    if (this.process) {\n      this.process.kill('SIGTERM');\n      this.process = null;\n    }\n  }\n  \n  private getPythonPath(): string {\n    // In development usa python3, in production usa bundled Python\n    return process.env.NODE_ENV === 'development' \n      ? 'python3' \n      : path.join(__dirname, '../python-dist/bin/python3');\n  }\n}\n```\n\n## 7. Registrazione IPC Handlers (`electron/ipc-handlers.ts` - estensione)\n\n```typescript\nimport { ipcMain } from 'electron';\nimport { OsxphotosSupervisor } from './osxphotos-supervisor';\n\nconst supervisor = new OsxphotosSupervisor();\n\nexport function registerPhotosHandlers(): void {\n  ipcMain.handle('photos:start-service', async () => {\n    await supervisor.start();\n    return { success: true };\n  });\n  \n  ipcMain.handle('photos:list-albums', async () => {\n    return supervisor.call('list_albums');\n  });\n  \n  ipcMain.handle('photos:get-photos', async (_, params) => {\n    return supervisor.call('get_photos', params);\n  });\n  \n  ipcMain.handle('photos:export', async (_, params) => {\n    return supervisor.call('export_photo', params);\n  });\n  \n  ipcMain.handle('photos:get-metadata', async (_, { uuid }) => {\n    return supervisor.call('get_photo_metadata', { photo_uuid: uuid });\n  });\n}\n```\n\n## Requisiti Python (`python/sandboxed/requirements.txt`)\n\n```\nosxphotos>=0.67.0\n```\n\n## Note di Sicurezza Critiche\n\n1. **Network Blocking**: Il monkey-patching di `socket.socket` blocca qualsiasi tentativo di connessione network eccetto Unix socket\n2. **Path Validation**: Ogni operazione di export passa attraverso whitelist validation con controllo path traversal\n3. **Socket Permissions**: Il socket Unix ha permessi 0600 (solo owner)\n4. **Circuit Breaker**: Previene restart loops infiniti in caso di errori persistenti\n5. **Processo Separato**: Isolamento completo dal FastAPI sidecar principale",
        "testStrategy": "## Unit Tests Python\n\n1. **test_path_validator.py**\n   - Test che path nella whitelist siano accettati\n   - Test che path fuori dalla whitelist siano rifiutati con SecurityError\n   - Test che path traversal (`..`) siano rilevati e bloccati\n   - Test che symlink non risolti siano gestiti correttamente\n   - Test creazione automatica directory whitelist\n\n2. **test_jsonrpc_handler.py**\n   - Test risposta corretta per metodi validi\n   - Test errore -32601 per metodi non esistenti\n   - Test errore -32700 per JSON malformato\n   - Test errore -32600 per richieste senza jsonrpc: '2.0'\n   - Test che id venga preservato nella risposta\n\n3. **test_photos_service.py** (con mock osxphotos)\n   - Test list_albums ritorna struttura corretta\n   - Test get_photos con filtri album_uuid\n   - Test export_photo chiama PathValidator\n   - Test get_photo_metadata ritorna tutti i campi EXIF\n\n## Integration Tests Python\n\n4. **test_unix_socket.py**\n   - Test che il socket venga creato su /tmp/trae-osxphotos.sock\n   - Test che permessi socket siano 0600\n   - Test comunicazione bidirezionale client-server\n   - Test cleanup socket su shutdown\n\n5. **test_network_blocking.py**\n   - Test che `socket.socket(AF_INET, ...)` sollevi PermissionError\n   - Test che `socket.socket(AF_UNIX, ...)` funzioni normalmente\n   - Test che import di librerie network (requests, urllib) falliscano\n\n## Unit Tests TypeScript (Electron)\n\n6. **osxphotos-supervisor.spec.ts**\n   - Test start() spawna processo Python\n   - Test circuit breaker si apre dopo 3 fallimenti\n   - Test circuit breaker si resetta dopo 5 minuti\n   - Test auto-restart funziona fino a MAX_FAILURES\n   - Test waitForSocket timeout dopo 5 secondi\n   - Test call() invia JSON-RPC corretto e parsa risposta\n\n## E2E Tests\n\n7. **test_full_workflow.py**\n   - Test completo: avvio servizio → list albums → export foto → verifica file\n   - Test che export su directory non whitelist fallisca\n   - Test recovery dopo crash del processo sandboxed\n   - Test che circuit breaker blocchi restart eccessivi\n\n## Manual Testing Checklist\n\n- [ ] Verificare che `Full Disk Access` sia richiesto solo per il processo sandboxed\n- [ ] Confermare che il FastAPI sidecar NON abbia accesso a Photos Library\n- [ ] Testare export su ~/Exports/ e ~/Documents/TraeExports/ - deve funzionare\n- [ ] Testare export su ~/Desktop/ - deve fallire con SecurityError\n- [ ] Verificare che kill del processo sandboxed triggeri auto-restart\n- [ ] Testare 3+ crash consecutivi - circuit breaker deve bloccare\n- [ ] Attendere 5 minuti e verificare reset circuit breaker",
        "status": "pending",
        "dependencies": [
          "2",
          "4",
          "6"
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": "1",
            "title": "Setup Unix Socket Server Python con JSON-RPC 2.0",
            "description": "Implementare il server Unix socket asincrono con handler JSON-RPC 2.0 completo per la comunicazione inter-processo sicura.",
            "dependencies": [],
            "details": "Creare `python/sandboxed/socket_server.py` con classe UnixSocketServer che utilizza asyncio.start_unix_server per gestire connessioni su `/tmp/trae-osxphotos.sock`. Implementare permessi restrittivi (0o600) sul socket. Creare `python/sandboxed/jsonrpc_handler.py` con validazione completa dello standard JSON-RPC 2.0 (versione, method, params, id). Gestire tutti i codici errore standard: -32700 (Parse error), -32600 (Invalid Request), -32601 (Method not found), -32000 (Server error). Configurare limite lettura 1MB per prevenire DoS. Creare `python/sandboxed/__init__.py` e `python/sandboxed/requirements.txt` con osxphotos>=0.67.0.",
            "status": "pending",
            "testStrategy": "Test unitari per validazione JSON-RPC 2.0: richieste valide, metodi inesistenti, parse error, invalid request. Test integrazione socket con client mock che invia richieste e verifica risposte. Test permessi socket file (0o600). Test limite dimensione messaggio.",
            "parentId": "15"
          },
          {
            "id": "2",
            "title": "Implementazione Path Validator con Whitelist Directory per Export Sicuro",
            "description": "Creare il sistema di validazione path con whitelist directory per garantire che le operazioni di export avvengano solo in directory autorizzate.",
            "dependencies": [
              1
            ],
            "details": "Creare `python/sandboxed/path_validator.py` con classe PathValidator contenente: WHITELIST_DIRECTORIES configurata per `~/Exports/` e `~/Documents/TraeExports/`. Metodo `validate_export_path()` che utilizza os.path.realpath() per risolvere symlink e path canonici, verifica assenza di path traversal (`..`), controlla che il path risolto sia sotto una directory whitelist usando os.path.commonpath(). Creare eccezione custom SecurityError per violazioni. Metodo `ensure_directories_exist()` per creare directory whitelist al bootstrap. Tutti i path devono essere normalizzati prima della validazione.",
            "status": "pending",
            "testStrategy": "Test path nella whitelist accettati correttamente. Test path fuori whitelist rifiutati con SecurityError. Test path traversal (`../../../etc/passwd`) bloccati. Test symlink che puntano fuori whitelist rifiutati. Test creazione automatica directory whitelist.",
            "parentId": "15"
          },
          {
            "id": "3",
            "title": "Wrapper PhotosService per osxphotos con Metadata Extraction",
            "description": "Implementare il servizio wrapper attorno a osxphotos per accesso alla Photos Library con estrazione completa dei metadati EXIF e info persone/luoghi.",
            "dependencies": [
              1,
              2
            ],
            "details": "Creare `python/sandboxed/photos_service.py` con classe PhotosService. Metodo `list_albums()` che ritorna lista album con title, uuid, photo_count. Metodo `get_photos()` con filtri opzionali (album_uuid, from_date, to_date, limit) che ritorna uuid, filename, date, width, height, has_exif. Metodo `export_photo()` che OBBLIGATORIAMENTE chiama PathValidator.validate_export_path() prima di qualsiasi operazione, supporta preserve_exif flag. Metodo `get_photo_metadata()` che estrae uuid, filename, date, exif completo, location (lat/lon), keywords, persons. Metodo `search_photos()` per ricerca testuale. Inizializzazione con PhotosDB opzionale per testing.",
            "status": "pending",
            "testStrategy": "Test con mock PhotosDB per evitare dipendenza da libreria reale. Test list_albums ritorna struttura corretta. Test get_photos con vari filtri. Test export_photo chiama sempre PathValidator prima di export. Test get_photo_metadata estrae tutti i campi. Test search_photos filtra correttamente.",
            "parentId": "15"
          },
          {
            "id": "4",
            "title": "Network Blocking via Monkey-Patching Socket per Isolamento",
            "description": "Implementare il blocco completo dell'accesso network nel processo sandboxed tramite monkey-patching del modulo socket Python.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "In `python/sandboxed/main.py` implementare funzione `block_network()` chiamata IMMEDIATAMENTE all'avvio, PRIMA di qualsiasi import. La funzione deve salvare riferimento originale a socket.socket, sostituirlo con wrapper `restricted_socket()` che permette SOLO socket.AF_UNIX e solleva PermissionError per qualsiasi altro tipo (AF_INET, AF_INET6). Creare entry point asincrono `main()` che inizializza PhotosService, JsonRpcHandler, UnixSocketServer. Registrare signal handlers per SIGTERM e SIGINT per shutdown graceful. Log startup e shutdown su stderr con prefisso `[osxphotos-sandbox]`.",
            "status": "pending",
            "testStrategy": "Test che import di requests/urllib dopo block_network() fallisce con PermissionError. Test che socket.socket(AF_INET) solleva PermissionError. Test che socket.socket(AF_UNIX) funziona normalmente. Test signal handlers chiudono correttamente il processo. Test log messaggi su stderr.",
            "parentId": "15"
          },
          {
            "id": "5",
            "title": "Supervisor TypeScript con Circuit Breaker e Auto-Restart",
            "description": "Implementare il supervisor Electron/Node.js che gestisce il ciclo di vita del processo Python sandboxed con circuit breaker pattern per prevenire restart loop.",
            "dependencies": [
              4
            ],
            "details": "Creare `electron/osxphotos-supervisor.ts` con classe OsxphotosSupervisor. Implementare circuit breaker con: MAX_FAILURES=3, RESET_TIMEOUT_MS=5 minuti, stato (failures, lastFailure, isOpen). Metodo `start()` che verifica circuit breaker, spawna processo Python con stdio configurato, attende socket pronto. Metodo `handleProcessExit()` che incrementa failures, apre circuit breaker se necessario, altrimenti auto-restart con delay 1s. Metodo `waitForSocket()` con polling ogni 100ms e timeout 5s. Metodo `call<T>()` per invio richieste JSON-RPC via net.createConnection. Metodo `stop()` per SIGTERM. `getPythonPath()` che distingue development (python3) da production (bundled).",
            "status": "pending",
            "testStrategy": "Test circuit breaker si apre dopo 3 failures consecutive. Test circuit breaker si resetta dopo 5 minuti. Test auto-restart avviene con delay corretto. Test waitForSocket timeout dopo 5s se socket non disponibile. Test call() invia JSON-RPC corretto e parsa risposta. Test stop() invia SIGTERM al processo.",
            "parentId": "15"
          },
          {
            "id": "6",
            "title": "IPC Handlers per Comunicazione Electron con Processo Sandboxed",
            "description": "Registrare gli IPC handlers nel main process Electron per esporre le funzionalità del processo sandboxed al renderer tramite contextBridge.",
            "dependencies": [
              5
            ],
            "details": "Estendere `electron/ipc-handlers.ts` con funzione `registerPhotosHandlers()`. Creare istanza singleton di OsxphotosSupervisor. Registrare handlers: `photos:start-service` -> supervisor.start(), `photos:list-albums` -> supervisor.call('list_albums'), `photos:get-photos` -> supervisor.call('get_photos', params), `photos:export` -> supervisor.call('export_photo', params), `photos:get-metadata` -> supervisor.call('get_photo_metadata', {photo_uuid}). Gestire errori con try/catch e ritornare oggetti errore strutturati. Chiamare registerPhotosHandlers() all'avvio dell'app in main.ts. Aggiornare preload.ts per esporre i nuovi canali IPC.",
            "status": "pending",
            "testStrategy": "Test IPC handlers registrati correttamente con ipcMain.handle. Test photos:start-service avvia il supervisor. Test photos:list-albums chiama supervisor.call con metodo corretto. Test gestione errori ritorna struttura errore consistente. Test integrazione end-to-end da renderer a processo sandboxed.",
            "parentId": "15"
          }
        ],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Setup Unix socket server Python con JSON-RPC 2.0, 2) Implementazione path validator con whitelist directory per export sicuro, 3) Wrapper PhotosService per osxphotos con metadata extraction, 4) Network blocking via monkey-patching socket per isolamento, 5) Supervisor TypeScript con circuit breaker e auto-restart, 6) IPC handlers per comunicazione con processo sandboxed"
      },
      {
        "id": "16",
        "title": "Integrazione Docker MCP Gateway per Gestione Centralizzata Tool MCP",
        "description": "Implementare l'integrazione con Docker MCP Gateway per la gestione centralizzata dei tool MCP, includendo detection di Docker Engine, auto-installazione del plugin CLI Gateway, UI Settings per toggle Cloud/Local per-tool, e generazione dinamica cagent.yaml con fallback chain intelligente.",
        "details": "## Struttura File\n\n```\nelectron/\n├── docker-detector.ts          # Detection Docker Engine\n├── mcp-gateway-installer.ts    # Auto-install CLI plugin\n└── ipc-handlers.ts             # Estensione con handler Docker/Gateway\n\nsrc/lib/\n├── services/\n│   ├── docker-gateway.ts       # Client per Docker MCP Gateway\n│   └── mcp-mode-manager.ts     # Gestione modalità Cloud/Local\n├── stores/\n│   └── mcp-settings.svelte.ts  # Store Svelte 5 per settings MCP\n└── components/custom/\n    └── MCPToolToggle.svelte    # Toggle per-tool Cloud/Local\n\npython/\n└── tools/\n    └── mcp_resolver.py         # Risoluzione dinamica ref MCP\n```\n\n## 1. Docker Engine Detection (`electron/docker-detector.ts`)\n\n```typescript\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\nexport interface DockerStatus {\n  isInstalled: boolean;\n  isRunning: boolean;\n  version: string | null;\n  isDesktop: boolean;  // true = Desktop, false = Engine only\n  gatewayInstalled: boolean;\n  gatewayVersion: string | null;\n}\n\nexport async function detectDocker(): Promise<DockerStatus> {\n  const status: DockerStatus = {\n    isInstalled: false,\n    isRunning: false,\n    version: null,\n    isDesktop: false,\n    gatewayInstalled: false,\n    gatewayVersion: null\n  };\n\n  try {\n    // Check docker info (verifica sia installazione che running)\n    const { stdout } = await execAsync('docker info --format \"{{.ServerVersion}}\"', {\n      timeout: 5000\n    });\n    status.isInstalled = true;\n    status.isRunning = true;\n    status.version = stdout.trim();\n\n    // Detect if Docker Desktop (check for Desktop-specific indicators)\n    const { stdout: infoFull } = await execAsync('docker info', { timeout: 5000 });\n    status.isDesktop = infoFull.includes('Docker Desktop') || \n                       infoFull.includes('desktop-linux');\n\n    // Check MCP Gateway plugin\n    await checkGatewayPlugin(status);\n  } catch (error) {\n    // docker command exists ma daemon non running\n    try {\n      await execAsync('docker --version');\n      status.isInstalled = true;\n    } catch {\n      status.isInstalled = false;\n    }\n  }\n\n  return status;\n}\n\nasync function checkGatewayPlugin(status: DockerStatus): Promise<void> {\n  try {\n    const { stdout } = await execAsync('docker mcp --version', { timeout: 3000 });\n    status.gatewayInstalled = true;\n    status.gatewayVersion = stdout.trim();\n  } catch {\n    status.gatewayInstalled = false;\n  }\n}\n```\n\n## 2. MCP Gateway Auto-Installer (`electron/mcp-gateway-installer.ts`)\n\n```typescript\nimport { app } from 'electron';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport * as https from 'https';\nimport { createWriteStream } from 'fs';\n\nconst GATEWAY_RELEASES_URL = 'https://api.github.com/repos/docker/mcp-gateway/releases/latest';\n\ninterface ReleaseAsset {\n  name: string;\n  browser_download_url: string;\n}\n\nexport async function installMCPGateway(): Promise<{ success: boolean; error?: string }> {\n  try {\n    // 1. Fetch latest release info\n    const releaseInfo = await fetchLatestRelease();\n    \n    // 2. Determine platform-specific binary\n    const platform = process.platform;\n    const arch = process.arch === 'arm64' ? 'arm64' : 'amd64';\n    const binaryName = `docker-mcp-${platform === 'darwin' ? 'darwin' : 'linux'}-${arch}`;\n    \n    const asset = releaseInfo.assets.find((a: ReleaseAsset) => a.name === binaryName);\n    if (!asset) {\n      return { success: false, error: `Binary non trovato per ${platform}-${arch}` };\n    }\n\n    // 3. Download binary\n    const cliPluginsDir = path.join(process.env.HOME || '', '.docker', 'cli-plugins');\n    await fs.mkdir(cliPluginsDir, { recursive: true });\n    \n    const destPath = path.join(cliPluginsDir, 'docker-mcp');\n    await downloadFile(asset.browser_download_url, destPath);\n    \n    // 4. Make executable\n    await fs.chmod(destPath, 0o755);\n\n    return { success: true };\n  } catch (error) {\n    return { success: false, error: String(error) };\n  }\n}\n\nasync function fetchLatestRelease(): Promise<{ assets: ReleaseAsset[] }> {\n  return new Promise((resolve, reject) => {\n    https.get(GATEWAY_RELEASES_URL, { \n      headers: { 'User-Agent': 'Trae-Extractor-App' } \n    }, (res) => {\n      let data = '';\n      res.on('data', chunk => data += chunk);\n      res.on('end', () => resolve(JSON.parse(data)));\n    }).on('error', reject);\n  });\n}\n\nasync function downloadFile(url: string, dest: string): Promise<void> {\n  return new Promise((resolve, reject) => {\n    const file = createWriteStream(dest);\n    https.get(url, { headers: { 'User-Agent': 'Trae-Extractor-App' } }, (res) => {\n      // Handle redirects\n      if (res.statusCode === 302 && res.headers.location) {\n        https.get(res.headers.location, (redirectRes) => {\n          redirectRes.pipe(file);\n          file.on('finish', () => { file.close(); resolve(); });\n        }).on('error', reject);\n      } else {\n        res.pipe(file);\n        file.on('finish', () => { file.close(); resolve(); });\n      }\n    }).on('error', reject);\n  });\n}\n\nexport async function enableGatewayServer(serverName: string): Promise<boolean> {\n  const { exec } = require('child_process');\n  return new Promise((resolve) => {\n    exec(`docker mcp server enable ${serverName}`, (error: Error | null) => {\n      resolve(!error);\n    });\n  });\n}\n```\n\n## 3. UI Settings Toggle (`src/lib/components/custom/MCPToolToggle.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { Switch } from '$lib/components/ui/switch';\n  import { Label } from '$lib/components/ui/label';\n  import { Badge } from '$lib/components/ui/badge';\n  import { mcpSettings } from '$lib/stores/mcp-settings.svelte';\n  \n  interface Props {\n    toolId: string;\n    toolName: string;\n    description: string;\n    supportsGateway: boolean;\n  }\n  \n  let { toolId, toolName, description, supportsGateway }: Props = $props();\n  \n  const dockerStatus = $derived(mcpSettings.dockerStatus);\n  const toolMode = $derived(mcpSettings.getToolMode(toolId));\n  const canUseGateway = $derived(\n    supportsGateway && \n    dockerStatus.isRunning && \n    dockerStatus.gatewayInstalled\n  );\n  \n  function toggleMode() {\n    if (!canUseGateway) return;\n    mcpSettings.setToolMode(toolId, toolMode === 'gateway' ? 'local' : 'gateway');\n  }\n</script>\n\n<div class=\"flex items-center justify-between p-4 border rounded-lg\">\n  <div class=\"space-y-1\">\n    <div class=\"flex items-center gap-2\">\n      <Label class=\"text-base font-medium\">{toolName}</Label>\n      {#if toolMode === 'gateway'}\n        <Badge variant=\"secondary\">Cloud</Badge>\n      {:else}\n        <Badge variant=\"outline\">Local</Badge>\n      {/if}\n    </div>\n    <p class=\"text-sm text-muted-foreground\">{description}</p>\n    {#if !canUseGateway && supportsGateway}\n      <p class=\"text-xs text-yellow-600\">\n        {#if !dockerStatus.isRunning}\n          Docker non attivo - usando modalità locale\n        {:else if !dockerStatus.gatewayInstalled}\n          MCP Gateway non installato\n        {/if}\n      </p>\n    {/if}\n  </div>\n  \n  <Switch \n    checked={toolMode === 'gateway'}\n    disabled={!canUseGateway}\n    onCheckedChange={toggleMode}\n  />\n</div>\n```\n\n## 4. MCP Settings Store (`src/lib/stores/mcp-settings.svelte.ts`)\n\n```typescript\nimport { writable } from 'svelte/store';\n\ninterface DockerStatus {\n  isInstalled: boolean;\n  isRunning: boolean;\n  gatewayInstalled: boolean;\n  gatewayVersion: string | null;\n}\n\ntype ToolMode = 'gateway' | 'local';\n\ninterface MCPToolConfig {\n  mode: ToolMode;\n  gatewayRef: string;    // es: 'mcp/cloudinary'\n  localRef: string;      // es: 'npx @cloudinary/mcp-server'\n  envVars: string[];     // es: ['CLOUDINARY_URL']\n}\n\nconst SUPPORTED_TOOLS: Record<string, MCPToolConfig> = {\n  cloudinary: {\n    mode: 'gateway',\n    gatewayRef: 'mcp/cloudinary',\n    localRef: 'npx @cloudinary/mcp-server',\n    envVars: ['CLOUDINARY_URL']\n  },\n  duckduckgo: {\n    mode: 'gateway',\n    gatewayRef: 'mcp/duckduckgo',\n    localRef: 'npx @anthropics/duckduckgo-mcp-server',\n    envVars: []\n  }\n};\n\nfunction createMCPSettingsStore() {\n  let dockerStatus = $state<DockerStatus>({\n    isInstalled: false,\n    isRunning: false,\n    gatewayInstalled: false,\n    gatewayVersion: null\n  });\n  \n  let toolModes = $state<Record<string, ToolMode>>({\n    cloudinary: 'gateway',\n    duckduckgo: 'gateway'\n  });\n\n  return {\n    get dockerStatus() { return dockerStatus; },\n    get toolModes() { return toolModes; },\n    \n    setDockerStatus(status: DockerStatus) {\n      dockerStatus = status;\n    },\n    \n    getToolMode(toolId: string): ToolMode {\n      return toolModes[toolId] ?? 'local';\n    },\n    \n    setToolMode(toolId: string, mode: ToolMode) {\n      toolModes[toolId] = mode;\n      // Trigger cagent.yaml regeneration\n      window.electronAPI?.regenerateCagentConfig();\n    },\n    \n    getToolRef(toolId: string): string {\n      const config = SUPPORTED_TOOLS[toolId];\n      if (!config) return '';\n      \n      const mode = this.getToolMode(toolId);\n      if (mode === 'gateway' && dockerStatus.isRunning && dockerStatus.gatewayInstalled) {\n        return config.gatewayRef;\n      }\n      return config.localRef;\n    },\n    \n    async refreshDockerStatus() {\n      const status = await window.electronAPI?.detectDocker();\n      if (status) this.setDockerStatus(status);\n    }\n  };\n}\n\nexport const mcpSettings = createMCPSettingsStore();\n```\n\n## 5. Generazione Dinamica cagent.yaml (Estensione `src/lib/services/cagent-config.ts`)\n\n```typescript\n// Aggiungere alla funzione generateCagentYaml esistente (Task 5)\n\ninterface MCPToolsetConfig {\n  type: 'mcp';\n  ref: string;\n  env?: Record<string, string>;\n}\n\nexport function generateMCPToolsets(\n  toolModes: Record<string, ToolMode>,\n  dockerStatus: DockerStatus\n): MCPToolsetConfig[] {\n  const toolsets: MCPToolsetConfig[] = [];\n  \n  for (const [toolId, mode] of Object.entries(toolModes)) {\n    const config = SUPPORTED_TOOLS[toolId];\n    if (!config) continue;\n    \n    const useGateway = mode === 'gateway' && \n                       dockerStatus.isRunning && \n                       dockerStatus.gatewayInstalled;\n    \n    toolsets.push({\n      type: 'mcp',\n      ref: useGateway ? config.gatewayRef : config.localRef,\n      env: config.envVars.reduce((acc, envVar) => {\n        acc[envVar] = `\\${${envVar}}`;  // Placeholder per env vars\n        return acc;\n      }, {} as Record<string, string>)\n    });\n  }\n  \n  return toolsets;\n}\n```\n\n## 6. Fallback Chain Implementation (`python/tools/mcp_resolver.py`)\n\n```python\nimport subprocess\nimport asyncio\nfrom typing import Optional, Tuple\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass MCPMode(Enum):\n    GATEWAY = \"gateway\"\n    LOCAL = \"local\"\n    ERROR = \"error\"\n\n@dataclass\nclass MCPResolution:\n    mode: MCPMode\n    ref: str\n    error_message: Optional[str] = None\n\nclass MCPResolver:\n    \"\"\"Risolve il modo MCP con fallback chain: Gateway → Local → Error\"\"\"\n    \n    def __init__(self, tool_id: str, gateway_ref: str, local_ref: str):\n        self.tool_id = tool_id\n        self.gateway_ref = gateway_ref\n        self.local_ref = local_ref\n    \n    async def resolve(self, preferred_mode: str = \"gateway\") -> MCPResolution:\n        \"\"\"\n        Fallback chain:\n        1. Se preferred_mode == gateway: prova Gateway, fallback a Local\n        2. Se preferred_mode == local: usa direttamente Local\n        3. Se tutto fallisce: Error con istruzioni\n        \"\"\"\n        if preferred_mode == \"gateway\":\n            # Try Gateway first\n            gateway_ok = await self._check_gateway()\n            if gateway_ok:\n                return MCPResolution(MCPMode.GATEWAY, self.gateway_ref)\n            \n            # Fallback to Local\n            local_ok = await self._check_local()\n            if local_ok:\n                return MCPResolution(MCPMode.LOCAL, self.local_ref)\n        else:\n            # Direct Local mode\n            local_ok = await self._check_local()\n            if local_ok:\n                return MCPResolution(MCPMode.LOCAL, self.local_ref)\n        \n        # Error state\n        return MCPResolution(\n            MCPMode.ERROR,\n            \"\",\n            error_message=self._generate_error_instructions()\n        )\n    \n    async def _check_gateway(self) -> bool:\n        \"\"\"Verifica se Docker MCP Gateway è disponibile\"\"\"\n        try:\n            proc = await asyncio.create_subprocess_exec(\n                'docker', 'mcp', 'server', 'list',\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE\n            )\n            await proc.wait()\n            return proc.returncode == 0\n        except Exception:\n            return False\n    \n    async def _check_local(self) -> bool:\n        \"\"\"Verifica se il tool locale è disponibile\"\"\"\n        try:\n            # Check if npx command would work\n            proc = await asyncio.create_subprocess_exec(\n                'which', 'npx',\n                stdout=asyncio.subprocess.PIPE\n            )\n            await proc.wait()\n            return proc.returncode == 0\n        except Exception:\n            return False\n    \n    def _generate_error_instructions(self) -> str:\n        return f\"\"\"\nTool MCP '{self.tool_id}' non disponibile.\n\nPer risolvere:\n\nOPZIONE 1 - Docker MCP Gateway (consigliato):\n  1. Installa Docker Engine: https://docs.docker.com/engine/install/\n  2. Avvia Docker: `sudo systemctl start docker` o avvia Docker Desktop\n  3. Installa MCP Gateway: Settings > Tools > Installa Gateway\n\nOPZIONE 2 - Modalità Locale:\n  1. Assicurati che Node.js sia installato\n  2. Configura le API keys in Settings > Providers\n  3. Il tool verrà eseguito via npx: {self.local_ref}\n\"\"\"\n```\n\n## 7. IPC Handlers Estensione (`electron/ipc-handlers.ts`)\n\n```typescript\n// Aggiungere ai handler esistenti\n\nimport { detectDocker } from './docker-detector';\nimport { installMCPGateway, enableGatewayServer } from './mcp-gateway-installer';\n\nexport function registerDockerHandlers(ipcMain: Electron.IpcMain) {\n  ipcMain.handle('docker:detect', async () => {\n    return await detectDocker();\n  });\n  \n  ipcMain.handle('docker:install-gateway', async () => {\n    return await installMCPGateway();\n  });\n  \n  ipcMain.handle('docker:enable-server', async (_, serverName: string) => {\n    return await enableGatewayServer(serverName);\n  });\n  \n  ipcMain.handle('docker:start-gateway', async () => {\n    const { exec } = require('child_process');\n    return new Promise((resolve) => {\n      exec('docker mcp gateway run --detach', (error: Error | null) => {\n        resolve(!error);\n      });\n    });\n  });\n}\n```\n\n## 8. Settings Page Integration (`src/routes/settings/tools/+page.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { onMount } from 'svelte';\n  import { Button } from '$lib/components/ui/button';\n  import { Card, CardContent, CardHeader, CardTitle } from '$lib/components/ui/card';\n  import { Alert, AlertDescription } from '$lib/components/ui/alert';\n  import MCPToolToggle from '$lib/components/custom/MCPToolToggle.svelte';\n  import { mcpSettings } from '$lib/stores/mcp-settings.svelte';\n  \n  let installing = $state(false);\n  let installError = $state<string | null>(null);\n  \n  const dockerStatus = $derived(mcpSettings.dockerStatus);\n  \n  onMount(() => {\n    mcpSettings.refreshDockerStatus();\n  });\n  \n  async function installGateway() {\n    installing = true;\n    installError = null;\n    \n    const result = await window.electronAPI.installMCPGateway();\n    if (result.success) {\n      await mcpSettings.refreshDockerStatus();\n    } else {\n      installError = result.error ?? 'Installazione fallita';\n    }\n    \n    installing = false;\n  }\n</script>\n\n<div class=\"space-y-6\">\n  <Card>\n    <CardHeader>\n      <CardTitle>Docker MCP Gateway</CardTitle>\n    </CardHeader>\n    <CardContent class=\"space-y-4\">\n      <div class=\"flex items-center justify-between\">\n        <div>\n          <p class=\"font-medium\">Stato Docker Engine</p>\n          <p class=\"text-sm text-muted-foreground\">\n            {#if dockerStatus.isRunning}\n              ✅ Docker attivo (v{dockerStatus.version})\n            {:else if dockerStatus.isInstalled}\n              ⚠️ Docker installato ma non attivo\n            {:else}\n              ❌ Docker non installato\n            {/if}\n          </p>\n        </div>\n      </div>\n      \n      <div class=\"flex items-center justify-between\">\n        <div>\n          <p class=\"font-medium\">MCP Gateway Plugin</p>\n          <p class=\"text-sm text-muted-foreground\">\n            {#if dockerStatus.gatewayInstalled}\n              ✅ Installato (v{dockerStatus.gatewayVersion})\n            {:else}\n              ❌ Non installato\n            {/if}\n          </p>\n        </div>\n        {#if !dockerStatus.gatewayInstalled && dockerStatus.isRunning}\n          <Button onclick={installGateway} disabled={installing}>\n            {installing ? 'Installazione...' : 'Installa Gateway'}\n          </Button>\n        {/if}\n      </div>\n      \n      {#if installError}\n        <Alert variant=\"destructive\">\n          <AlertDescription>{installError}</AlertDescription>\n        </Alert>\n      {/if}\n    </CardContent>\n  </Card>\n  \n  <Card>\n    <CardHeader>\n      <CardTitle>Configurazione Tool MCP</CardTitle>\n    </CardHeader>\n    <CardContent class=\"space-y-4\">\n      <MCPToolToggle\n        toolId=\"cloudinary\"\n        toolName=\"Cloudinary\"\n        description=\"Background removal, upscale, auto-crop\"\n        supportsGateway={true}\n      />\n      <MCPToolToggle\n        toolId=\"duckduckgo\"\n        toolName=\"DuckDuckGo Search\"\n        description=\"Web search senza API key\"\n        supportsGateway={true}\n      />\n    </CardContent>\n  </Card>\n</div>\n```\n\n## Note Implementative\n\n1. **Docker Engine vs Desktop**: Il codice usa `docker info` che funziona sia con Engine che Desktop. Il flag `isDesktop` è informativo ma non bloccante.\n\n2. **Sicurezza download**: Il download del binary Gateway usa HTTPS e verifica il redirect di GitHub releases.\n\n3. **Fallback automatico**: La chain Gateway → Local → Error è implementata sia lato UI (disabilita toggle) che lato Python (runtime resolution).\n\n4. **Regenerazione cagent.yaml**: Ogni cambio di modalità triggera la rigenerazione del file config tramite IPC.\n\n5. **Tool supportati iniziali**: Cloudinary e DuckDuckGo come da specifiche, facilmente estendibile aggiungendo entry a `SUPPORTED_TOOLS`.",
        "testStrategy": "## Test Unitari TypeScript\n\n1. **test/docker-detector.test.ts**\n   - Test detectDocker() con mock exec che simula Docker running\n   - Test detectDocker() con mock exec che simula Docker non installato\n   - Test detectDocker() con mock exec che simula daemon non running\n   - Test checkGatewayPlugin() con Gateway installato/non installato\n   - Test timeout handling per comandi docker lenti\n\n2. **test/mcp-gateway-installer.test.ts**\n   - Test fetchLatestRelease() con mock GitHub API response\n   - Test downloadFile() con mock HTTPS e redirect handling\n   - Test installMCPGateway() su diverse piattaforme (darwin-arm64, darwin-amd64, linux-amd64)\n   - Test gestione errori per download falliti o permessi file\n\n3. **test/mcp-settings.svelte.test.ts**\n   - Test getToolRef() ritorna gateway ref quando Docker è attivo\n   - Test getToolRef() fallback a local ref quando Docker non disponibile\n   - Test setToolMode() persiste correttamente le preferenze\n   - Test refreshDockerStatus() aggiorna lo stato correttamente\n\n## Test Unitari Python\n\n4. **tests/test_mcp_resolver.py**\n   - Test resolve() con Gateway disponibile → ritorna GATEWAY mode\n   - Test resolve() con Gateway fallito → fallback a LOCAL mode\n   - Test resolve() con tutto fallito → ritorna ERROR con istruzioni\n   - Test _check_gateway() con subprocess mock\n   - Test _check_local() verifica presenza npx\n   - Test _generate_error_instructions() formato corretto\n\n## Test Integrazione\n\n5. **test/integration/docker-gateway.test.ts**\n   - Test E2E flusso completo: detect → install → enable server\n   - Test IPC handlers docker:detect, docker:install-gateway\n   - Test regenerateCagentConfig triggera correttamente la rigenerazione\n\n6. **test/integration/settings-ui.test.ts**\n   - Test rendering pagina settings/tools con Playwright\n   - Test toggle Cloud/Local aggiorna store\n   - Test bottone \"Installa Gateway\" appare quando Docker attivo ma Gateway mancante\n   - Test alert errore appare su installazione fallita\n\n## Test E2E\n\n7. **e2e/mcp-gateway-workflow.test.ts**\n   - Test workflow completo: apertura Settings → Tools → toggle tool → verifica cagent.yaml aggiornato\n   - Test fallback visuale: disabilita toggle quando Docker non disponibile\n   - Test messaggio errore user-friendly quando nessun backend disponibile\n\n## Verifiche Manuali\n\n8. **Checklist manuale**\n   - [ ] Su macOS con Docker Engine: `docker info` funziona\n   - [ ] Su macOS senza Docker: app mostra stato \"non installato\"\n   - [ ] Download Gateway da GitHub releases completa correttamente\n   - [ ] Binary ha permessi esecuzione (755) dopo installazione\n   - [ ] `docker mcp --version` funziona dopo installazione\n   - [ ] Toggle Cloud/Local persiste dopo restart app\n   - [ ] cagent.yaml contiene ref corretti ('mcp/cloudinary' vs 'npx @cloudinary/mcp-server')\n   - [ ] Fallback chain funziona runtime (Gateway down → usa Local)",
        "status": "pending",
        "dependencies": [
          "2",
          "4",
          "5",
          "7"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Docker Engine detection e status check, 2) Auto-installer MCP Gateway CLI plugin, 3) UI Settings toggle Cloud/Local per-tool con stato Docker, 4) Store MCP settings con Svelte 5 runes, 5) Generazione dinamica cagent.yaml con ref gateway vs local, 6) Fallback chain Python Gateway → Local → Error con istruzioni"
      },
      {
        "id": "17",
        "title": "Alternativa Locale per Media Processing Privacy-First",
        "description": "Implementare un sistema di elaborazione media locale come alternativa privacy-first a Cloudinary, includendo background removal con rembg, upscaling con Real-ESRGAN, e smart crop con OpenCV, con UI toggle nelle settings e fallback chain intelligente.",
        "details": "## Struttura Directory\n\n```\npython/\n├── local_media/\n│   ├── __init__.py\n│   ├── background_remover.py      # Wrapper rembg (U2-Net)\n│   ├── upscaler.py                # Wrapper Real-ESRGAN\n│   ├── smart_cropper.py           # OpenCV + face detection\n│   ├── model_manager.py           # Download on-demand modelli\n│   └── processor.py               # Orchestrator locale\nsrc/lib/\n├── services/\n│   └── local-media-processor.ts   # Client TypeScript per sidecar\n├── stores/\n│   └── media-processing-settings.svelte.ts  # Store Svelte 5 runes\n└── components/custom/\n    └── MediaProcessingToggle.svelte  # UI toggle settings\nelectron/\n└── model-downloader.ts            # Download manager con progress\n```\n\n## 1. Background Removal (`background_remover.py`)\n\n```python\nfrom rembg import remove\nfrom PIL import Image\nimport io\nfrom typing import Optional\n\nclass BackgroundRemover:\n    \"\"\"Background removal usando rembg con U2-Net model (~90% accuratezza Cloudinary)\"\"\"\n    \n    def __init__(self):\n        # rembg scarica automaticamente u2net.onnx (~168MB) al primo uso\n        self._model_name = \"u2net\"\n    \n    async def remove_background(\n        self, \n        image_bytes: bytes,\n        alpha_matting: bool = False,\n        alpha_matting_foreground_threshold: int = 240,\n        alpha_matting_background_threshold: int = 10\n    ) -> bytes:\n        \"\"\"\n        Rimuove lo sfondo dall'immagine.\n        \n        Args:\n            image_bytes: Bytes dell'immagine input\n            alpha_matting: Abilita alpha matting per bordi più smooth\n            \n        Returns:\n            Bytes dell'immagine PNG con sfondo trasparente\n        \"\"\"\n        try:\n            input_image = Image.open(io.BytesIO(image_bytes))\n            output_image = remove(\n                input_image,\n                alpha_matting=alpha_matting,\n                alpha_matting_foreground_threshold=alpha_matting_foreground_threshold,\n                alpha_matting_background_threshold=alpha_matting_background_threshold\n            )\n            \n            output_buffer = io.BytesIO()\n            output_image.save(output_buffer, format=\"PNG\")\n            return output_buffer.getvalue()\n            \n        except Exception as e:\n            raise LocalProcessingError(f\"Background removal failed: {e}\")\n```\n\n## 2. Upscaling (`upscaler.py`)\n\n```python\nfrom pathlib import Path\nimport numpy as np\nfrom PIL import Image\nimport io\nfrom typing import Literal\nfrom .model_manager import ModelManager\n\nclass Upscaler:\n    \"\"\"Super-resolution con Real-ESRGAN (x2, x4 scale)\"\"\"\n    \n    MODELS = {\n        \"x2\": {\n            \"name\": \"RealESRGAN_x2plus.pth\",\n            \"url\": \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth\",\n            \"size_mb\": 64\n        },\n        \"x4\": {\n            \"name\": \"RealESRGAN_x4plus.pth\",\n            \"url\": \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\",\n            \"size_mb\": 64\n        }\n    }\n    \n    def __init__(self, model_manager: ModelManager):\n        self._model_manager = model_manager\n        self._loaded_models = {}\n    \n    async def ensure_model(self, scale: Literal[\"x2\", \"x4\"]) -> Path:\n        \"\"\"Scarica modello se non presente (download on-demand)\"\"\"\n        model_info = self.MODELS[scale]\n        return await self._model_manager.ensure_model(\n            model_info[\"name\"],\n            model_info[\"url\"],\n            model_info[\"size_mb\"]\n        )\n    \n    async def upscale(\n        self, \n        image_bytes: bytes, \n        scale: Literal[\"x2\", \"x4\"] = \"x2\"\n    ) -> bytes:\n        \"\"\"\n        Upscale immagine con Real-ESRGAN.\n        \n        Args:\n            image_bytes: Bytes dell'immagine input\n            scale: Fattore di upscaling (\"x2\" o \"x4\")\n            \n        Returns:\n            Bytes dell'immagine upscalata\n        \"\"\"\n        from basicsr.archs.rrdbnet_arch import RRDBNet\n        from realesrgan import RealESRGANer\n        \n        model_path = await self.ensure_model(scale)\n        \n        # Configurazione modello\n        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, \n                       num_block=23, num_grow_ch=32, scale=int(scale[1]))\n        \n        upsampler = RealESRGANer(\n            scale=int(scale[1]),\n            model_path=str(model_path),\n            model=model,\n            tile=0,  # 0 = no tiling, usa più memoria ma più veloce\n            tile_pad=10,\n            pre_pad=0,\n            half=False  # True per GPU con supporto FP16\n        )\n        \n        # Process\n        img = Image.open(io.BytesIO(image_bytes))\n        img_array = np.array(img)\n        output, _ = upsampler.enhance(img_array, outscale=int(scale[1]))\n        \n        output_buffer = io.BytesIO()\n        Image.fromarray(output).save(output_buffer, format=\"PNG\", quality=95)\n        return output_buffer.getvalue()\n```\n\n## 3. Smart Crop (`smart_cropper.py`)\n\n```python\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport io\nfrom typing import Tuple, Optional\n\nclass SmartCropper:\n    \"\"\"Smart crop con face detection (fallback: center crop)\"\"\"\n    \n    def __init__(self):\n        # Carica Haar cascade per face detection\n        self._face_cascade = cv2.CascadeClassifier(\n            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n        )\n    \n    def _detect_faces(self, img_array: np.ndarray) -> list:\n        \"\"\"Rileva volti nell'immagine\"\"\"\n        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n        faces = self._face_cascade.detectMultiScale(\n            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)\n        )\n        return faces\n    \n    def _calculate_focus_point(\n        self, \n        img_shape: Tuple[int, int], \n        faces: list\n    ) -> Tuple[int, int]:\n        \"\"\"Calcola punto focale basato su volti rilevati\"\"\"\n        if len(faces) == 0:\n            # Fallback: center\n            return img_shape[1] // 2, img_shape[0] // 2\n        \n        # Centro pesato dei volti\n        total_weight = 0\n        cx, cy = 0, 0\n        for (x, y, w, h) in faces:\n            weight = w * h  # Peso = area del volto\n            cx += (x + w/2) * weight\n            cy += (y + h/2) * weight\n            total_weight += weight\n        \n        return int(cx / total_weight), int(cy / total_weight)\n    \n    async def smart_crop(\n        self, \n        image_bytes: bytes,\n        target_width: int,\n        target_height: int,\n        gravity: Optional[str] = None  # \"face\", \"center\", \"auto\"\n    ) -> bytes:\n        \"\"\"\n        Smart crop con rilevamento automatico punto focale.\n        \n        Args:\n            image_bytes: Bytes dell'immagine input\n            target_width: Larghezza target\n            target_height: Altezza target\n            gravity: \"face\" (usa face detection), \"center\", \"auto\" (face con fallback center)\n            \n        Returns:\n            Bytes dell'immagine croppata\n        \"\"\"\n        img = Image.open(io.BytesIO(image_bytes))\n        img_array = np.array(img)\n        \n        orig_h, orig_w = img_array.shape[:2]\n        \n        # Determina punto focale\n        if gravity == \"center\":\n            focus_x, focus_y = orig_w // 2, orig_h // 2\n        else:  # \"face\" o \"auto\"\n            faces = self._detect_faces(img_array)\n            focus_x, focus_y = self._calculate_focus_point(img_array.shape, faces)\n        \n        # Calcola crop box mantenendo aspect ratio\n        target_ratio = target_width / target_height\n        orig_ratio = orig_w / orig_h\n        \n        if orig_ratio > target_ratio:\n            # Immagine più larga: crop orizzontale\n            new_w = int(orig_h * target_ratio)\n            new_h = orig_h\n        else:\n            # Immagine più alta: crop verticale\n            new_w = orig_w\n            new_h = int(orig_w / target_ratio)\n        \n        # Centro crop sul punto focale\n        left = max(0, min(focus_x - new_w // 2, orig_w - new_w))\n        top = max(0, min(focus_y - new_h // 2, orig_h - new_h))\n        \n        cropped = img.crop((left, top, left + new_w, top + new_h))\n        resized = cropped.resize((target_width, target_height), Image.LANCZOS)\n        \n        output_buffer = io.BytesIO()\n        resized.save(output_buffer, format=\"PNG\")\n        return output_buffer.getvalue()\n```\n\n## 4. Model Manager (`model_manager.py`)\n\n```python\nfrom pathlib import Path\nimport aiohttp\nimport asyncio\nfrom typing import Callable, Optional\n\nclass ModelManager:\n    \"\"\"Gestisce download on-demand dei modelli ML (~100MB per modello)\"\"\"\n    \n    def __init__(self, models_dir: Path):\n        self.models_dir = models_dir\n        self.models_dir.mkdir(parents=True, exist_ok=True)\n        self._download_callbacks: list[Callable] = []\n    \n    def on_download_progress(self, callback: Callable[[str, float], None]):\n        \"\"\"Registra callback per progress download\"\"\"\n        self._download_callbacks.append(callback)\n    \n    async def ensure_model(\n        self, \n        name: str, \n        url: str, \n        expected_size_mb: int\n    ) -> Path:\n        \"\"\"Scarica modello se non presente, ritorna path\"\"\"\n        model_path = self.models_dir / name\n        \n        if model_path.exists():\n            return model_path\n        \n        # Download con progress\n        async with aiohttp.ClientSession() as session:\n            async with session.get(url) as response:\n                total = int(response.headers.get('content-length', 0))\n                downloaded = 0\n                \n                with open(model_path, 'wb') as f:\n                    async for chunk in response.content.iter_chunked(8192):\n                        f.write(chunk)\n                        downloaded += len(chunk)\n                        progress = downloaded / total if total else 0\n                        for cb in self._download_callbacks:\n                            cb(name, progress)\n        \n        return model_path\n```\n\n## 5. Local Processor Orchestrator (`processor.py`)\n\n```python\nfrom typing import Literal, Optional\nfrom .background_remover import BackgroundRemover\nfrom .upscaler import Upscaler\nfrom .smart_cropper import SmartCropper\nfrom .model_manager import ModelManager\n\nclass LocalMediaProcessor:\n    \"\"\"Orchestrator per processing media locale\"\"\"\n    \n    def __init__(self, models_dir: Path):\n        self.model_manager = ModelManager(models_dir)\n        self.bg_remover = BackgroundRemover()\n        self.upscaler = Upscaler(self.model_manager)\n        self.cropper = SmartCropper()\n    \n    async def process(\n        self,\n        image_bytes: bytes,\n        operations: list[dict]\n    ) -> bytes:\n        \"\"\"\n        Applica sequenza di operazioni.\n        \n        Args:\n            image_bytes: Bytes immagine input\n            operations: Lista di operazioni es. [\n                {\"type\": \"remove_bg\"},\n                {\"type\": \"upscale\", \"scale\": \"x2\"},\n                {\"type\": \"crop\", \"width\": 1080, \"height\": 1080, \"gravity\": \"face\"}\n            ]\n            \n        Returns:\n            Bytes immagine processata\n        \"\"\"\n        result = image_bytes\n        \n        for op in operations:\n            op_type = op[\"type\"]\n            \n            if op_type == \"remove_bg\":\n                result = await self.bg_remover.remove_background(result)\n            elif op_type == \"upscale\":\n                result = await self.upscaler.upscale(result, op.get(\"scale\", \"x2\"))\n            elif op_type == \"crop\":\n                result = await self.cropper.smart_crop(\n                    result,\n                    op[\"width\"],\n                    op[\"height\"],\n                    op.get(\"gravity\", \"auto\")\n                )\n        \n        return result\n```\n\n## 6. FastAPI Endpoints (`python/main.py` estensione)\n\n```python\nfrom fastapi import APIRouter, File, UploadFile, HTTPException\nfrom pydantic import BaseModel\nfrom typing import List, Literal, Optional\nfrom local_media.processor import LocalMediaProcessor\n\nrouter = APIRouter(prefix=\"/local-media\", tags=[\"local-media\"])\nprocessor = LocalMediaProcessor(Path(\"./models\"))\n\nclass Operation(BaseModel):\n    type: Literal[\"remove_bg\", \"upscale\", \"crop\"]\n    scale: Optional[Literal[\"x2\", \"x4\"]] = None\n    width: Optional[int] = None\n    height: Optional[int] = None\n    gravity: Optional[Literal[\"face\", \"center\", \"auto\"]] = None\n\nclass ProcessRequest(BaseModel):\n    operations: List[Operation]\n\n@router.post(\"/process\")\nasync def process_image(\n    file: UploadFile = File(...),\n    operations: str = None  # JSON encoded operations\n):\n    \"\"\"Processa immagine con operazioni locali\"\"\"\n    try:\n        image_bytes = await file.read()\n        ops = json.loads(operations) if operations else []\n        result = await processor.process(image_bytes, ops)\n        return Response(content=result, media_type=\"image/png\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@router.get(\"/models/status\")\nasync def models_status():\n    \"\"\"Ritorna stato download modelli\"\"\"\n    return {\n        \"upscale_x2\": processor.model_manager.is_downloaded(\"RealESRGAN_x2plus.pth\"),\n        \"upscale_x4\": processor.model_manager.is_downloaded(\"RealESRGAN_x4plus.pth\"),\n        \"rembg\": True  # Auto-downloaded by rembg\n    }\n\n@router.post(\"/models/download/{model_name}\")\nasync def download_model(model_name: str):\n    \"\"\"Trigger download manuale modello\"\"\"\n    await processor.model_manager.ensure_model(...)\n    return {\"status\": \"downloaded\"}\n```\n\n## 7. TypeScript Client (`src/lib/services/local-media-processor.ts`)\n\n```typescript\ninterface ProcessingOperation {\n  type: 'remove_bg' | 'upscale' | 'crop';\n  scale?: 'x2' | 'x4';\n  width?: number;\n  height?: number;\n  gravity?: 'face' | 'center' | 'auto';\n}\n\ninterface ModelStatus {\n  upscale_x2: boolean;\n  upscale_x4: boolean;\n  rembg: boolean;\n}\n\nexport class LocalMediaProcessor {\n  private baseUrl = 'http://localhost:8765';\n  \n  async process(file: File, operations: ProcessingOperation[]): Promise<Blob> {\n    const formData = new FormData();\n    formData.append('file', file);\n    formData.append('operations', JSON.stringify(operations));\n    \n    const response = await fetch(`${this.baseUrl}/local-media/process`, {\n      method: 'POST',\n      body: formData\n    });\n    \n    if (!response.ok) {\n      throw new Error(`Local processing failed: ${response.statusText}`);\n    }\n    \n    return response.blob();\n  }\n  \n  async getModelsStatus(): Promise<ModelStatus> {\n    const response = await fetch(`${this.baseUrl}/local-media/models/status`);\n    return response.json();\n  }\n  \n  async downloadModel(modelName: string): Promise<void> {\n    await fetch(`${this.baseUrl}/local-media/models/download/${modelName}`, {\n      method: 'POST'\n    });\n  }\n}\n```\n\n## 8. Svelte Store (`src/lib/stores/media-processing-settings.svelte.ts`)\n\n```typescript\nimport { writable } from 'svelte/store';\n\ninterface MediaProcessingSettings {\n  preferLocalProcessing: boolean;\n  fallbackToCloud: boolean;\n  downloadModelsAutomatically: boolean;\n}\n\nconst defaultSettings: MediaProcessingSettings = {\n  preferLocalProcessing: false,\n  fallbackToCloud: true,\n  downloadModelsAutomatically: false\n};\n\nfunction createMediaProcessingStore() {\n  const { subscribe, set, update } = writable<MediaProcessingSettings>(defaultSettings);\n  \n  return {\n    subscribe,\n    setPreferLocal: (value: boolean) => update(s => ({ ...s, preferLocalProcessing: value })),\n    setFallbackToCloud: (value: boolean) => update(s => ({ ...s, fallbackToCloud: value })),\n    load: async () => {\n      const saved = await window.electronAPI?.getStore('mediaProcessing');\n      if (saved) set(saved);\n    },\n    save: async (settings: MediaProcessingSettings) => {\n      await window.electronAPI?.setStore('mediaProcessing', settings);\n      set(settings);\n    }\n  };\n}\n\nexport const mediaProcessingSettings = createMediaProcessingStore();\n```\n\n## 9. UI Toggle Component (`src/lib/components/custom/MediaProcessingToggle.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { Switch } from '$lib/components/ui/switch';\n  import { Label } from '$lib/components/ui/label';\n  import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '$lib/components/ui/card';\n  import { Badge } from '$lib/components/ui/badge';\n  import { mediaProcessingSettings } from '$lib/stores/media-processing-settings.svelte';\n  import { LocalMediaProcessor } from '$lib/services/local-media-processor';\n  \n  let processor = new LocalMediaProcessor();\n  let modelsStatus = $state({ upscale_x2: false, upscale_x4: false, rembg: false });\n  \n  $effect(() => {\n    processor.getModelsStatus().then(status => modelsStatus = status);\n  });\n</script>\n\n<Card>\n  <CardHeader>\n    <CardTitle>Elaborazione Media Locale</CardTitle>\n    <CardDescription>\n      Alternativa privacy-first a Cloudinary. Nessun upload su server esterni.\n    </CardDescription>\n  </CardHeader>\n  <CardContent class=\"space-y-4\">\n    <div class=\"flex items-center justify-between\">\n      <div class=\"space-y-0.5\">\n        <Label>Preferisci elaborazione locale</Label>\n        <p class=\"text-sm text-muted-foreground\">\n          Background removal, upscaling e smart crop eseguiti sul tuo Mac\n        </p>\n      </div>\n      <Switch \n        checked={$mediaProcessingSettings.preferLocalProcessing}\n        onCheckedChange={(v) => mediaProcessingSettings.setPreferLocal(v)}\n      />\n    </div>\n    \n    <div class=\"flex items-center justify-between\">\n      <div class=\"space-y-0.5\">\n        <Label>Fallback a Cloudinary</Label>\n        <p class=\"text-sm text-muted-foreground\">\n          Usa Cloudinary se l'elaborazione locale fallisce\n        </p>\n      </div>\n      <Switch \n        checked={$mediaProcessingSettings.fallbackToCloud}\n        onCheckedChange={(v) => mediaProcessingSettings.setFallbackToCloud(v)}\n      />\n    </div>\n    \n    <div class=\"pt-4 border-t\">\n      <h4 class=\"text-sm font-medium mb-2\">Stato Modelli ML</h4>\n      <div class=\"flex gap-2 flex-wrap\">\n        <Badge variant={modelsStatus.rembg ? 'default' : 'secondary'}>\n          rembg {modelsStatus.rembg ? '✓' : '~168MB'}\n        </Badge>\n        <Badge variant={modelsStatus.upscale_x2 ? 'default' : 'secondary'}>\n          ESRGAN x2 {modelsStatus.upscale_x2 ? '✓' : '~64MB'}\n        </Badge>\n        <Badge variant={modelsStatus.upscale_x4 ? 'default' : 'secondary'}>\n          ESRGAN x4 {modelsStatus.upscale_x4 ? '✓' : '~64MB'}\n        </Badge>\n      </div>\n    </div>\n  </CardContent>\n</Card>\n```\n\n## 10. Editing Agent Integrazione (`python/agents/editing_agent.py` update)\n\n```python\nclass EditingAgent(Agent):\n    \"\"\"Editing agent con supporto locale e cloud\"\"\"\n    \n    async def process_media(self, request: EditRequest) -> EditResult:\n        settings = await self.get_user_settings()\n        \n        if settings.prefer_local_processing:\n            try:\n                return await self._process_local(request)\n            except LocalProcessingError as e:\n                if settings.fallback_to_cloud:\n                    logger.warning(f\"Local processing failed, fallback to Cloudinary: {e}\")\n                    return await self._process_cloudinary(request)\n                raise\n        else:\n            return await self._process_cloudinary(request)\n    \n    async def _process_local(self, request: EditRequest) -> EditResult:\n        \"\"\"Processing locale con rembg, Real-ESRGAN, OpenCV\"\"\"\n        from local_media.processor import LocalMediaProcessor\n        processor = LocalMediaProcessor(self.models_dir)\n        \n        operations = self._map_request_to_operations(request)\n        result_bytes = await processor.process(request.image_bytes, operations)\n        \n        return EditResult(\n            success=True,\n            output_bytes=result_bytes,\n            processing_mode=\"local\"\n        )\n    \n    async def _process_cloudinary(self, request: EditRequest) -> EditResult:\n        \"\"\"Processing via Cloudinary MCP\"\"\"\n        # Existing Cloudinary implementation\n        ...\n```\n\n## Dipendenze Python (`python/requirements.txt` aggiunte)\n\n```txt\n# Local Media Processing\nrembg>=2.0.50\nrealesrgan>=0.3.0\nbasicsr>=1.4.2\nopencv-python-headless>=4.8.0\npillow>=10.0.0\naiohttp>=3.9.0\nnumpy>=1.24.0\n```\n\n## Trade-offs Documentati\n\n| Aspetto | Locale | Cloudinary |\n|---------|--------|------------|\n| Privacy | ✅ 100% locale | ⚠️ Upload su server |\n| Costo | ✅ Zero API costs | ⚠️ Pay-per-transform |\n| Velocità | ⚠️ Dipende da hardware | ✅ Server ottimizzati |\n| Qualità BG Removal | ~90% | 100% (baseline) |\n| Modelli | ~300MB download | Zero download |\n| Edge cases | ⚠️ Può fallire | ✅ Più robusto |",
        "testStrategy": "## Test Unitari Python\n\n### 1. `tests/unit/test_background_remover.py`\n- Test che immagine con sfondo semplice venga processata correttamente\n- Test che immagine con sfondo complesso ritorni PNG con alpha channel\n- Test che alpha_matting migliori bordi per immagini specifiche\n- Test gestione errori per immagini corrotte\n\n### 2. `tests/unit/test_upscaler.py`\n- Test che upscale x2 raddoppi effettivamente le dimensioni\n- Test che upscale x4 quadruplichi le dimensioni\n- Test che modello venga scaricato on-demand se mancante\n- Test progress callback durante download modello\n- Test gestione memoria per immagini molto grandi (>4K)\n\n### 3. `tests/unit/test_smart_cropper.py`\n- Test face detection con immagine contenente 1 volto\n- Test face detection con immagine contenente 3+ volti (centro pesato)\n- Test fallback a center crop quando nessun volto rilevato\n- Test crop mantenga aspect ratio target correttamente\n- Test gravity=\"center\" ignori face detection\n\n### 4. `tests/unit/test_model_manager.py`\n- Test download modello da URL valido\n- Test skip download se modello già presente\n- Test progress callback riceva valori 0.0 → 1.0\n- Test gestione errori per URL non raggiungibile\n- Test cleanup file parziali su download fallito\n\n## Test Integrazione Python\n\n### 5. `tests/integration/test_local_processor.py`\n- Test pipeline completa: remove_bg → upscale → crop\n- Test ordine operazioni rispettato\n- Test ogni operazione possa funzionare singolarmente\n- Test che risultato sia sempre PNG valido\n- Test performance: pipeline completa < 30s per immagine 1080p su M1\n\n### 6. `tests/integration/test_fastapi_endpoints.py`\n- Test POST `/local-media/process` con file valido\n- Test GET `/local-media/models/status` ritorna stato corretto\n- Test POST `/local-media/models/download/{name}` trigger download\n- Test error handling per file non-immagine\n- Test concurrent requests (max 3 simultanee)\n\n## Test TypeScript\n\n### 7. `tests/unit/local-media-processor.test.ts`\n- Test `process()` invia FormData corretta al sidecar\n- Test `getModelsStatus()` parsa risposta JSON\n- Test `downloadModel()` chiama endpoint corretto\n- Test error handling per network failures\n\n### 8. `tests/unit/media-processing-settings.test.ts`\n- Test store inizializza con valori default\n- Test `setPreferLocal()` aggiorna stato\n- Test `load()` recupera settings salvati\n- Test `save()` persiste via electronAPI\n\n## Test UI (Playwright)\n\n### 9. `e2e/media-processing-toggle.spec.ts`\n- Test toggle \"Preferisci elaborazione locale\" si attiva/disattiva\n- Test toggle \"Fallback a Cloudinary\" disabilitato quando local=false\n- Test badge modelli mostrano stato corretto (✓ vs dimensione)\n- Test settings persistono dopo refresh pagina\n\n## Test Fallback Chain\n\n### 10. `tests/integration/test_editing_agent_fallback.py`\n- Test con `prefer_local=true, fallback=true`: local fail → cloudinary success\n- Test con `prefer_local=true, fallback=false`: local fail → raise error\n- Test con `prefer_local=false`: skip locale, usa sempre cloudinary\n- Test log warning quando fallback attivato\n- Test `processing_mode` nel risultato indica quale metodo usato\n\n## Test Performance e Limiti\n\n### 11. `tests/performance/test_local_processing_limits.py`\n- Benchmark background removal: < 5s per 1080p\n- Benchmark upscale x2: < 10s per 1080p  \n- Benchmark upscale x4: < 30s per 1080p\n- Benchmark smart crop: < 1s per qualsiasi dimensione\n- Test memory usage non superi 4GB durante processing\n\n## Validazione Qualità\n\n### 12. Confronto manuale Cloudinary vs Local\n- Preparare 10 immagini test (volti, prodotti, landscape)\n- Confronto visivo background removal: acceptable se < 10% differenza percepita\n- Confronto upscaling: SSIM > 0.9 rispetto originale scalato\n- Confronto smart crop: volti sempre nel frame finale",
        "status": "pending",
        "dependencies": [
          "4",
          "5",
          "7"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": "1",
            "title": "Setup Background Remover con rembg e U2-Net",
            "description": "Implementare il modulo background_remover.py con wrapper rembg che utilizza il modello U2-Net per la rimozione automatica dello sfondo dalle immagini.",
            "dependencies": [],
            "details": "Creare la classe BackgroundRemover in python/local_media/background_remover.py. Implementare il metodo remove_background() che accetta bytes immagine e parametri opzionali per alpha_matting. Il modello U2-Net (~168MB) viene scaricato automaticamente da rembg al primo utilizzo. Gestire la conversione PIL Image <-> bytes, output in formato PNG con canale alpha trasparente. Includere gestione errori con LocalProcessingError custom. Aggiungere dipendenze rembg>=2.0.50 e pillow>=10.0.0 a requirements.txt.",
            "status": "pending",
            "testStrategy": "Test unitari: verifica che immagine con sfondo semplice produca PNG con alpha channel; test che alpha_matting migliori bordi; test gestione errori per immagini corrotte o formati non supportati.",
            "parentId": "17"
          },
          {
            "id": "2",
            "title": "Implementazione Upscaler con Real-ESRGAN",
            "description": "Creare il modulo upscaler.py che implementa super-resolution usando Real-ESRGAN con supporto per scale x2 e x4.",
            "dependencies": [
              4
            ],
            "details": "Implementare la classe Upscaler in python/local_media/upscaler.py. Definire dizionario MODELS con URL download per RealESRGAN_x2plus.pth e RealESRGAN_x4plus.pth (~64MB ciascuno). Metodo ensure_model() per download on-demand via ModelManager. Metodo upscale() che configura RRDBNet e RealESRGANer, processa l'immagine e ritorna bytes PNG. Aggiungere dipendenze realesrgan>=0.3.0, basicsr>=1.4.2, numpy>=1.24.0 a requirements.txt. Gestire conversione PIL <-> numpy array.",
            "status": "pending",
            "testStrategy": "Test che upscale x2 raddoppi le dimensioni immagine; test che upscale x4 quadruplichi; test download modello on-demand; benchmark performance su immagini di diverse dimensioni.",
            "parentId": "17"
          },
          {
            "id": "3",
            "title": "Smart Cropper con OpenCV e Face Detection",
            "description": "Implementare il modulo smart_cropper.py con rilevamento volti tramite Haar Cascade e crop intelligente basato su punto focale.",
            "dependencies": [],
            "details": "Creare la classe SmartCropper in python/local_media/smart_cropper.py. Caricare haarcascade_frontalface_default.xml da cv2.data.haarcascades. Implementare _detect_faces() con detectMultiScale. Implementare _calculate_focus_point() che calcola centro pesato dei volti rilevati o fallback al centro immagine. Metodo smart_crop() che: rileva volti, calcola punto focale, calcola crop box mantenendo aspect ratio target, centra sul punto focale, esegue resize con LANCZOS. Supportare gravity: 'face', 'center', 'auto'. Aggiungere opencv-python-headless>=4.8.0.",
            "status": "pending",
            "testStrategy": "Test con immagine contenente volto singolo verifica crop centrato sul volto; test con volti multipli verifica centro pesato; test senza volti verifica fallback center; test aspect ratio mantenuto correttamente.",
            "parentId": "17"
          },
          {
            "id": "4",
            "title": "Model Manager per Download On-Demand Modelli ML",
            "description": "Creare il sistema di gestione modelli che scarica i modelli ML (~300MB totali) on-demand con progress tracking e caching locale.",
            "dependencies": [],
            "details": "Implementare ModelManager in python/local_media/model_manager.py. Costruttore accetta models_dir (Path) e crea directory se non esiste. Metodo on_download_progress() per registrare callback progress. Metodo ensure_model(name, url, expected_size_mb) che: verifica se modello già presente in models_dir, altrimenti scarica con aiohttp in chunks da 8KB, notifica progress via callbacks registrati. Metodo is_downloaded(name) per verificare presenza. Aggiungere aiohttp>=3.9.0 a requirements.txt. Creare endpoint FastAPI GET /local-media/models/status e POST /local-media/models/download/{model_name}.",
            "status": "pending",
            "testStrategy": "Test download modello simulato con mock server; test progress callback riceve valori 0-1; test modello già presente non viene riscaricato; test gestione errori network.",
            "parentId": "17"
          },
          {
            "id": "5",
            "title": "UI Toggle Settings e Svelte Store per Preferenze Processing",
            "description": "Creare componente MediaProcessingToggle.svelte e store Svelte 5 runes per gestire preferenze utente su elaborazione locale vs cloud.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Creare store in src/lib/stores/media-processing-settings.svelte.ts con stato: preferLocalProcessing (boolean), fallbackToCloud (boolean), downloadModelsAutomatically (boolean). Metodi setPreferLocal(), setFallbackToCloud(), load() da electron store, save() verso electron store. Creare componente MediaProcessingToggle.svelte in src/lib/components/custom/ con Card shadcn contenente: Switch per preferire elaborazione locale, Switch per fallback Cloudinary, sezione stato modelli ML con Badge per rembg/ESRGAN x2/x4 che mostra checkmark se scaricato o dimensione se mancante. Usare $effect per caricare stato modelli da LocalMediaProcessor.getModelsStatus().",
            "status": "pending",
            "testStrategy": "Test store mantiene stato correttamente; test persistenza su electron store; test componente mostra stati corretti modelli; test toggle aggiorna store; test integrazione con settings page esistente.",
            "parentId": "17"
          },
          {
            "id": "6",
            "title": "Fallback Chain Local-Cloudinary e Integrazione Editing Agent",
            "description": "Implementare orchestrator LocalMediaProcessor, client TypeScript, endpoint FastAPI e logica fallback intelligente nell'editing agent.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Creare processor.py in python/local_media/ con classe LocalMediaProcessor che orchestra bg_remover, upscaler, cropper. Metodo process(image_bytes, operations) che applica sequenza operazioni. Creare endpoint FastAPI POST /local-media/process in python/main.py. Creare client TypeScript LocalMediaProcessor in src/lib/services/local-media-processor.ts con metodi process(), getModelsStatus(), downloadModel(). Modificare EditingAgent in python/agents/editing_agent.py: leggere settings utente, se prefer_local_processing provare _process_local(), su LocalProcessingError e fallback_to_cloud abilitato chiamare _process_cloudinary(), altrimenti rilanciare errore. Loggare mode usato in EditResult.",
            "status": "pending",
            "testStrategy": "Test E2E flusso completo locale; test fallback attivato su errore locale; test rispetto impostazioni utente; test EditResult contiene processing_mode corretto; test concorrenza multiple richieste.",
            "parentId": "17"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Setup rembg per background removal con U2-Net, 2) Implementazione upscaler con Real-ESRGAN (x2, x4), 3) Smart cropper con OpenCV e face detection, 4) Model manager per download on-demand modelli ML (~300MB totali), 5) UI toggle nelle settings e integration con editing agent, 6) Fallback chain local → Cloudinary con gestione errori"
      },
      {
        "id": "18",
        "title": "OPTIONAL UPGRADE: MCP Deep Search con Jina AI e Firecrawl",
        "description": "Implementare l'integrazione opzionale di Jina AI MCP e Firecrawl MCP per ricerca web approfondita, con rate limiting configurabile, quota tracking in UI, e fallback automatico a DuckDuckGo quando i servizi non sono disponibili.",
        "details": "## Struttura Directory\n\n```\npython/\n├── mcp/\n│   ├── __init__.py\n│   ├── jina_client.py              # Wrapper Jina AI MCP\n│   ├── firecrawl_client.py         # Wrapper Firecrawl MCP\n│   ├── rate_limiter.py             # Token bucket rate limiter\n│   └── search_orchestrator.py      # Orchestrator con fallback chain\nsrc/lib/\n├── services/\n│   └── deep-search.ts              # Client TypeScript per sidecar\n├── stores/\n│   └── search-quota.svelte.ts      # Store Svelte 5 per quota tracking\n└── components/custom/\n    └── SearchQuotaWidget.svelte    # Widget UI per visualizzazione quota\nelectron/\n└── ipc-handlers.ts                 # Estensione con handler deep search\n```\n\n## 1. Configurazione MCP Servers in `.mcp.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"jina-ai\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@anthropic/mcp-jina\"],\n      \"env\": {\n        \"JINA_API_KEY\": \"${JINA_API_KEY}\"\n      }\n    },\n    \"firecrawl\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@anthropic/mcp-firecrawl\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"${FIRECRAWL_API_KEY}\"\n      }\n    }\n  }\n}\n```\n\n## 2. Rate Limiter (`python/mcp/rate_limiter.py`)\n\n```python\nimport time\nfrom dataclasses import dataclass\nfrom typing import Dict\nimport asyncio\n\n@dataclass\nclass RateLimitConfig:\n    requests_per_minute: int = 10\n    burst_limit: int = 3\n\nclass TokenBucketRateLimiter:\n    def __init__(self, config: RateLimitConfig):\n        self.config = config\n        self.tokens = config.burst_limit\n        self.last_refill = time.time()\n        self._lock = asyncio.Lock()\n    \n    async def acquire(self) -> bool:\n        async with self._lock:\n            self._refill()\n            if self.tokens > 0:\n                self.tokens -= 1\n                return True\n            return False\n    \n    def _refill(self):\n        now = time.time()\n        elapsed = now - self.last_refill\n        refill_amount = elapsed * (self.config.requests_per_minute / 60)\n        self.tokens = min(self.config.burst_limit, self.tokens + refill_amount)\n        self.last_refill = now\n\n    def get_wait_time(self) -> float:\n        if self.tokens > 0:\n            return 0\n        return (1 - self.tokens) * (60 / self.config.requests_per_minute)\n```\n\n## 3. Jina AI Client (`python/mcp/jina_client.py`)\n\n```python\nfrom typing import List, Dict, Optional\nfrom cagent import Tool\nfrom .rate_limiter import TokenBucketRateLimiter, RateLimitConfig\n\nclass JinaSearchClient:\n    def __init__(self, rate_limiter: TokenBucketRateLimiter):\n        self.rate_limiter = rate_limiter\n        self.tools = [\n            Tool('jina_search', 'Deep web search via Jina AI'),\n            Tool('jina_reader', 'Extract structured content from URL'),\n        ]\n    \n    async def deep_search(self, query: str, max_results: int = 10) -> List[Dict]:\n        \"\"\"Ricerca web approfondita con estrazione contenuto strutturato\"\"\"\n        if not await self.rate_limiter.acquire():\n            wait_time = self.rate_limiter.get_wait_time()\n            raise RateLimitExceeded(f\"Rate limit exceeded. Retry in {wait_time:.1f}s\")\n        \n        # Chiama Jina MCP tool via cagent\n        results = await self._call_mcp_tool('jina_search', {'query': query, 'limit': max_results})\n        return results\n    \n    async def read_url(self, url: str) -> Dict:\n        \"\"\"Estrae contenuto strutturato da una URL\"\"\"\n        if not await self.rate_limiter.acquire():\n            raise RateLimitExceeded(\"Rate limit exceeded\")\n        \n        return await self._call_mcp_tool('jina_reader', {'url': url})\n    \n    async def _call_mcp_tool(self, tool_name: str, params: dict) -> Dict:\n        # Implementazione chiamata MCP\n        pass\n```\n\n## 4. Firecrawl Client (`python/mcp/firecrawl_client.py`)\n\n```python\nfrom typing import List, Dict\nfrom .rate_limiter import TokenBucketRateLimiter\n\nclass FirecrawlClient:\n    def __init__(self, rate_limiter: TokenBucketRateLimiter):\n        self.rate_limiter = rate_limiter\n    \n    async def scrape_url(self, url: str, options: Dict = None) -> Dict:\n        \"\"\"Web scraping avanzato con rendering JavaScript\"\"\"\n        if not await self.rate_limiter.acquire():\n            raise RateLimitExceeded(\"Rate limit exceeded\")\n        \n        return await self._call_mcp_tool('firecrawl_scrape', {\n            'url': url,\n            'options': options or {'waitFor': 2000, 'formats': ['markdown', 'html']}\n        })\n    \n    async def crawl_site(self, start_url: str, max_pages: int = 10) -> List[Dict]:\n        \"\"\"Crawling multi-pagina con limite configurabile\"\"\"\n        if not await self.rate_limiter.acquire():\n            raise RateLimitExceeded(\"Rate limit exceeded\")\n        \n        return await self._call_mcp_tool('firecrawl_crawl', {\n            'url': start_url,\n            'limit': max_pages,\n            'scrapeOptions': {'formats': ['markdown']}\n        })\n```\n\n## 5. Search Orchestrator con Fallback Chain (`python/mcp/search_orchestrator.py`)\n\n```python\nfrom typing import List, Dict, Optional\nfrom enum import Enum\nimport logging\n\nclass SearchProvider(Enum):\n    JINA = \"jina\"\n    FIRECRAWL = \"firecrawl\"\n    DUCKDUCKGO = \"duckduckgo\"\n\nclass DeepSearchOrchestrator:\n    def __init__(self, jina: JinaSearchClient, firecrawl: FirecrawlClient, duckduckgo_tool):\n        self.jina = jina\n        self.firecrawl = firecrawl\n        self.duckduckgo = duckduckgo_tool\n        self.logger = logging.getLogger(__name__)\n        \n        # Quota tracking\n        self.quota_used = {p.value: 0 for p in SearchProvider}\n    \n    async def search(self, query: str, preferred_provider: SearchProvider = SearchProvider.JINA) -> Dict:\n        \"\"\"Ricerca con fallback chain automatico\"\"\"\n        providers = self._get_fallback_chain(preferred_provider)\n        \n        for provider in providers:\n            try:\n                result = await self._search_with_provider(provider, query)\n                self.quota_used[provider.value] += 1\n                return {'provider': provider.value, 'results': result, 'fallback_used': provider != preferred_provider}\n            except RateLimitExceeded as e:\n                self.logger.warning(f\"{provider.value} rate limited: {e}\")\n                continue\n            except ServiceUnavailable as e:\n                self.logger.warning(f\"{provider.value} unavailable: {e}\")\n                continue\n        \n        raise AllProvidersUnavailable(\"All search providers failed\")\n    \n    async def trend_research(self, topic: str, platforms: List[str]) -> Dict:\n        \"\"\"Ricerca trend per CaptioningAgent\"\"\"\n        results = {}\n        for platform in platforms:\n            query = f\"{topic} {platform} trends 2025 social media\"\n            try:\n                search_result = await self.search(query)\n                results[platform] = search_result\n            except AllProvidersUnavailable:\n                results[platform] = {'error': 'No providers available'}\n        return results\n    \n    def get_quota_status(self) -> Dict:\n        return {\n            'used': self.quota_used.copy(),\n            'limits': {\n                'jina': 10,  # per minute\n                'firecrawl': 10,\n                'duckduckgo': 'unlimited'\n            }\n        }\n    \n    def _get_fallback_chain(self, preferred: SearchProvider) -> List[SearchProvider]:\n        chain = [preferred]\n        if preferred != SearchProvider.JINA:\n            chain.append(SearchProvider.JINA)\n        if preferred != SearchProvider.FIRECRAWL:\n            chain.append(SearchProvider.FIRECRAWL)\n        chain.append(SearchProvider.DUCKDUCKGO)  # Always last fallback\n        return chain\n```\n\n## 6. Integrazione CaptioningAgent (`python/agents/captioning_agent.py` - estensione)\n\n```python\nclass CaptioningAgent:\n    def __init__(self, knowledge_base, llm_provider, search_orchestrator: DeepSearchOrchestrator = None):\n        self.knowledge_base = knowledge_base\n        self.llm_provider = llm_provider\n        self.search = search_orchestrator  # Optional deep search\n    \n    async def generate_caption_with_trends(self, content_desc: str, platform: str, tone: str) -> Dict:\n        \"\"\"Genera caption arricchita con trend research\"\"\"\n        # 1. Contesto brand da RAG\n        brand_context = self._get_brand_context(content_desc)\n        \n        # 2. Trend research (se disponibile)\n        trend_context = \"\"\n        if self.search:\n            try:\n                trends = await self.search.trend_research(content_desc, [platform])\n                trend_context = self._format_trends(trends.get(platform, {}))\n            except Exception as e:\n                logging.warning(f\"Trend research failed: {e}\")\n        \n        # 3. Genera caption con contesto arricchito\n        prompt = self._build_prompt(content_desc, platform, tone, brand_context, trend_context)\n        return await self.llm_provider.generate(prompt)\n```\n\n## 7. TypeScript Client (`src/lib/services/deep-search.ts`)\n\n```typescript\ninterface SearchQuota {\n  used: Record<string, number>;\n  limits: Record<string, number | 'unlimited'>;\n}\n\ninterface SearchResult {\n  provider: string;\n  results: any[];\n  fallback_used: boolean;\n}\n\nexport class DeepSearchClient {\n  async search(query: string, preferredProvider: 'jina' | 'firecrawl' = 'jina'): Promise<SearchResult> {\n    const response = await window.electronAPI.invoke('deep-search:query', { query, preferredProvider });\n    if (!response.success) throw new Error(response.error);\n    return response.data;\n  }\n  \n  async trendResearch(topic: string, platforms: string[]): Promise<Record<string, SearchResult>> {\n    const response = await window.electronAPI.invoke('deep-search:trends', { topic, platforms });\n    if (!response.success) throw new Error(response.error);\n    return response.data;\n  }\n  \n  async getQuotaStatus(): Promise<SearchQuota> {\n    const response = await window.electronAPI.invoke('deep-search:quota');\n    return response.data;\n  }\n}\n```\n\n## 8. Svelte 5 Store per Quota (`src/lib/stores/search-quota.svelte.ts`)\n\n```typescript\nimport { DeepSearchClient } from '$lib/services/deep-search';\n\nconst client = new DeepSearchClient();\n\nlet quota = $state<SearchQuota>({ used: {}, limits: {} });\nlet lastUpdated = $state<Date | null>(null);\n\nexport const searchQuotaStore = {\n  get quota() { return quota; },\n  get lastUpdated() { return lastUpdated; },\n  \n  async refresh() {\n    quota = await client.getQuotaStatus();\n    lastUpdated = new Date();\n  },\n  \n  getUsagePercentage(provider: string): number {\n    const used = quota.used[provider] || 0;\n    const limit = quota.limits[provider];\n    if (limit === 'unlimited') return 0;\n    return Math.min(100, (used / (limit as number)) * 100);\n  }\n};\n\n// Auto-refresh ogni 30 secondi\nsetInterval(() => searchQuotaStore.refresh(), 30000);\n```\n\n## 9. Widget UI Quota (`src/lib/components/custom/SearchQuotaWidget.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { searchQuotaStore } from '$lib/stores/search-quota.svelte';\n  import { Progress } from '$lib/components/ui/progress';\n  import { Card, CardContent, CardHeader, CardTitle } from '$lib/components/ui/card';\n  import { Badge } from '$lib/components/ui/badge';\n  \n  const providers = ['jina', 'firecrawl', 'duckduckgo'];\n</script>\n\n<Card class=\"w-64\">\n  <CardHeader class=\"pb-2\">\n    <CardTitle class=\"text-sm\">Search Quota</CardTitle>\n  </CardHeader>\n  <CardContent class=\"space-y-3\">\n    {#each providers as provider}\n      {@const percentage = searchQuotaStore.getUsagePercentage(provider)}\n      {@const used = searchQuotaStore.quota.used[provider] || 0}\n      {@const limit = searchQuotaStore.quota.limits[provider]}\n      <div class=\"space-y-1\">\n        <div class=\"flex justify-between text-xs\">\n          <span class=\"capitalize\">{provider}</span>\n          <span>{used}/{limit === 'unlimited' ? '∞' : limit}</span>\n        </div>\n        {#if limit !== 'unlimited'}\n          <Progress value={percentage} class=\"h-1\" />\n        {:else}\n          <Badge variant=\"outline\" class=\"text-xs\">Unlimited</Badge>\n        {/if}\n      </div>\n    {/each}\n    {#if searchQuotaStore.lastUpdated}\n      <p class=\"text-xs text-muted-foreground\">\n        Updated: {searchQuotaStore.lastUpdated.toLocaleTimeString()}\n      </p>\n    {/if}\n  </CardContent>\n</Card>\n```\n\n## 10. IPC Handlers (`electron/ipc-handlers.ts` - estensione)\n\n```typescript\n// Aggiungere a registerIpcHandlers()\nipcMain.handle('deep-search:query', async (_, { query, preferredProvider }) => {\n  try {\n    const result = await sidecarClient.post('/search/query', { query, preferredProvider });\n    return { success: true, data: result };\n  } catch (error) {\n    return { success: false, error: error.message };\n  }\n});\n\nipcMain.handle('deep-search:trends', async (_, { topic, platforms }) => {\n  try {\n    const result = await sidecarClient.post('/search/trends', { topic, platforms });\n    return { success: true, data: result };\n  } catch (error) {\n    return { success: false, error: error.message };\n  }\n});\n\nipcMain.handle('deep-search:quota', async () => {\n  try {\n    const result = await sidecarClient.get('/search/quota');\n    return { success: true, data: result };\n  } catch (error) {\n    return { success: false, error: error.message };\n  }\n});\n```\n\n## 11. FastAPI Endpoints (`python/main.py` - estensione)\n\n```python\nfrom fastapi import APIRouter\nfrom python.mcp.search_orchestrator import DeepSearchOrchestrator, SearchProvider\n\nsearch_router = APIRouter(prefix=\"/search\", tags=[\"search\"])\n\n@search_router.post(\"/query\")\nasync def search_query(query: str, preferredProvider: str = \"jina\"):\n    provider = SearchProvider(preferredProvider)\n    return await search_orchestrator.search(query, provider)\n\n@search_router.post(\"/trends\")\nasync def search_trends(topic: str, platforms: list[str]):\n    return await search_orchestrator.trend_research(topic, platforms)\n\n@search_router.get(\"/quota\")\nasync def get_quota():\n    return search_orchestrator.get_quota_status()\n```\n\n## Configurazione Rate Limiting\n\nIl rate limiting default è 10 req/min per Jina e Firecrawl, configurabile in:\n- `python/mcp/rate_limiter.py` - RateLimitConfig\n- UI Settings (futuro) per override utente",
        "testStrategy": "## Test Unitari Python\n\n### 1. `tests/unit/test_rate_limiter.py`\n- Test che TokenBucketRateLimiter blocchi dopo burst_limit richieste consecutive\n- Test che i token vengano ricaricati correttamente nel tempo (simulare 60s per refill completo)\n- Test che `get_wait_time()` ritorni valore corretto quando rate limited\n- Test concorrenza con asyncio.gather per verificare thread safety del lock\n\n### 2. `tests/unit/test_jina_client.py`\n- Test `deep_search()` con mock MCP tool che ritorna risultati validi\n- Test che `RateLimitExceeded` venga sollevata quando rate limiter blocca\n- Test `read_url()` con URL valida e mock response\n- Test gestione errori per URL malformata\n\n### 3. `tests/unit/test_firecrawl_client.py`\n- Test `scrape_url()` con opzioni default\n- Test `scrape_url()` con opzioni custom (waitFor, formats)\n- Test `crawl_site()` rispetti max_pages limit\n- Test rate limiting integrato\n\n### 4. `tests/unit/test_search_orchestrator.py`\n- Test fallback chain: Jina → Firecrawl → DuckDuckGo\n- Test che quota tracking incrementi correttamente per ogni provider\n- Test `trend_research()` con multiple piattaforme\n- Test che `AllProvidersUnavailable` venga sollevata quando tutti falliscono\n- Test `get_quota_status()` ritorna struttura corretta\n\n## Test Integrazione\n\n### 5. `tests/integration/test_captioning_with_trends.py`\n- Test CaptioningAgent con mock DeepSearchOrchestrator\n- Test che trend context venga incluso nel prompt quando disponibile\n- Test graceful degradation quando search fallisce (caption generata comunque)\n- Test che quota venga aggiornata dopo trend research\n\n### 6. `tests/integration/test_ipc_deep_search.py`\n- Test IPC handler `deep-search:query` con mock sidecar\n- Test IPC handler `deep-search:trends` ritorna risultati per ogni piattaforma\n- Test IPC handler `deep-search:quota` con quota parzialmente esaurita\n- Test error handling per sidecar non disponibile\n\n## Test Componenti Svelte\n\n### 7. `tests/components/SearchQuotaWidget.test.ts`\n- Test rendering con quota vuota\n- Test rendering con quota parziale (50% jina, 80% firecrawl)\n- Test che \"unlimited\" mostri badge invece di progress bar\n- Test aggiornamento timestamp \"lastUpdated\"\n- Test responsive su diverse dimensioni schermo\n\n### 8. `tests/stores/search-quota.test.ts`\n- Test `refresh()` aggiorna stato correttamente\n- Test `getUsagePercentage()` calcola percentuale corretta\n- Test `getUsagePercentage()` ritorna 0 per 'unlimited'\n- Test auto-refresh interval (mock timers)\n\n## Test E2E\n\n### 9. `tests/e2e/deep-search-flow.test.ts`\n- Test flusso completo: Settings → Abilita Jina API key → Caption generation con trends\n- Test fallback visibile in UI quando Jina rate limited\n- Test quota widget si aggiorna dopo ricerche\n- Test che DuckDuckGo funzioni come fallback finale senza API key\n\n## Test Fallback\n\n### 10. `tests/fallback/test_duckduckgo_fallback.py`\n- Test che ricerca funzioni con solo DuckDuckGo disponibile\n- Test che risultati DuckDuckGo siano formattati consistentemente con Jina/Firecrawl\n- Test performance: DuckDuckGo risponda entro 5s\n\n## Metriche di Qualità\n\n- Copertura test: minimo 80% per moduli search\n- Latenza media ricerca: < 3s per Jina, < 5s per Firecrawl, < 2s per DuckDuckGo\n- Rate limit accuracy: 10 ± 1 req/min\n- Fallback success rate: > 99% quando almeno un provider disponibile",
        "status": "pending",
        "dependencies": [
          "4",
          "5",
          "8"
        ],
        "priority": "low",
        "subtasks": [
          {
            "id": "1",
            "title": "Configurazione MCP Servers per Jina AI e Firecrawl",
            "description": "Configurare i server MCP per Jina AI e Firecrawl nel file .mcp.json, implementare il wrapper client base per entrambi i servizi e gestire le API keys tramite variabili d'ambiente.",
            "dependencies": [],
            "details": "Creare la configurazione MCP in .mcp.json con i server jina-ai e firecrawl utilizzando npx per l'esecuzione. Implementare python/mcp/__init__.py e le classi base JinaSearchClient e FirecrawlClient con integrazione cagent Tool. Gestire le API keys JINA_API_KEY e FIRECRAWL_API_KEY tramite variabili d'ambiente. Implementare i metodi _call_mcp_tool per invocare i tool MCP tramite cagent. Includere gestione errori per API keys mancanti e servizi non disponibili con eccezioni ServiceUnavailable.",
            "status": "pending",
            "testStrategy": "Test unitari per verificare parsing corretto della configurazione MCP. Test mock per chiamate MCP tool con cagent. Test che ServiceUnavailable venga sollevata quando le API keys sono mancanti o i servizi non rispondono.",
            "parentId": "18"
          },
          {
            "id": "2",
            "title": "Implementazione Token Bucket Rate Limiter",
            "description": "Implementare il sistema di rate limiting con algoritmo token bucket per controllare il numero di richieste API verso Jina AI e Firecrawl, con configurazione personalizzabile e calcolo del tempo di attesa.",
            "dependencies": [],
            "details": "Creare python/mcp/rate_limiter.py con la classe TokenBucketRateLimiter che implementa l'algoritmo token bucket. Definire RateLimitConfig con requests_per_minute=10 e burst_limit=3 come default. Implementare il metodo acquire() con lock asincrono per thread-safety, il metodo _refill() per ricaricare i token in base al tempo trascorso, e get_wait_time() per calcolare quanto tempo attendere prima della prossima richiesta disponibile. Sollevare eccezione RateLimitExceeded quando i token sono esauriti.",
            "status": "pending",
            "testStrategy": "Test unitari in tests/unit/test_rate_limiter.py: verificare che acquire() blocchi dopo burst_limit richieste consecutive, testare ricarica token simulando il passaggio del tempo (60s per refill completo), verificare che get_wait_time() ritorni valori corretti quando i token sono esauriti.",
            "parentId": "18"
          },
          {
            "id": "3",
            "title": "Search Orchestrator con Fallback Chain Automatico",
            "description": "Implementare l'orchestratore di ricerca che coordina Jina AI, Firecrawl e DuckDuckGo con fallback automatico, quota tracking e gestione intelligente dei provider non disponibili.",
            "dependencies": [
              1,
              2
            ],
            "details": "Creare python/mcp/search_orchestrator.py con DeepSearchOrchestrator che gestisce JinaSearchClient, FirecrawlClient e DuckDuckGo tool. Implementare il metodo search() che tenta i provider in ordine di preferenza (Jina → Firecrawl → DuckDuckGo) con gestione eccezioni RateLimitExceeded e ServiceUnavailable. Implementare _get_fallback_chain() per costruire la catena di fallback dinamica. Aggiungere quota_used tracking per ogni provider e metodo get_quota_status() per esporre le statistiche. Implementare _search_with_provider() per normalizzare le risposte dei diversi provider. Sollevare AllProvidersUnavailable solo quando tutti i provider falliscono.",
            "status": "pending",
            "testStrategy": "Test unitari per verificare che il fallback passi al provider successivo quando uno fallisce. Test che DuckDuckGo venga sempre usato come ultimo fallback. Test che quota_used venga incrementata correttamente. Test che AllProvidersUnavailable venga sollevata solo quando tutti i provider falliscono. Test con mock per simulare rate limiting e service unavailable su provider specifici.",
            "parentId": "18"
          },
          {
            "id": "4",
            "title": "Integrazione Trend Research in CaptioningAgent",
            "description": "Estendere il CaptioningAgent per utilizzare il DeepSearchOrchestrator per ricerche di trend social media, arricchendo la generazione di caption con insight contestuali aggiornati.",
            "dependencies": [
              3
            ],
            "details": "Modificare python/agents/captioning_agent.py per accettare un parametro opzionale search_orchestrator: DeepSearchOrchestrator. Implementare il metodo trend_research() in DeepSearchOrchestrator che esegue ricerche multi-piattaforma usando query ottimizzate '{topic} {platform} trends 2025 social media'. Estendere generate_caption_with_trends() per combinare brand_context da RAG con trend_context da deep search. Implementare _format_trends() per normalizzare i risultati di ricerca in formato utilizzabile dal prompt LLM. Gestire gracefully i fallimenti di ricerca trend con logging warning e fallback a generazione senza trend context.",
            "status": "pending",
            "testStrategy": "Test unitari per verificare che CaptioningAgent funzioni correttamente sia con che senza search_orchestrator. Test che trend_research() generi query corrette per diverse piattaforme. Test mock per simulare ricerche trend riuscite e fallite. Test che _format_trends() normalizzi correttamente risultati da diversi provider. Test di integrazione per generazione caption con e senza trend context.",
            "parentId": "18"
          },
          {
            "id": "5",
            "title": "UI Quota Widget e IPC Handlers per Deep Search",
            "description": "Implementare il widget Svelte 5 per visualizzare le quote di utilizzo dei provider di ricerca, il client TypeScript per comunicare con il sidecar, e gli handler IPC Electron per collegare frontend e backend.",
            "dependencies": [
              3,
              4
            ],
            "details": "Creare src/lib/services/deep-search.ts con DeepSearchClient che espone metodi search(), trendResearch() e getQuotaStatus() tramite window.electronAPI. Implementare src/lib/stores/search-quota.svelte.ts come Svelte 5 runes store con stato reattivo per quota, lastUpdated, e metodi refresh() e getUsagePercentage(). Creare src/lib/components/custom/SearchQuotaWidget.svelte con Progress bar per Jina e Firecrawl e Badge 'Unlimited' per DuckDuckGo. Estendere electron/ipc-handlers.ts con handler 'deep-search:query', 'deep-search:trends' e 'deep-search:quota' che chiamano il sidecar FastAPI. Aggiungere FastAPI endpoints in python/main.py: POST /search/query, POST /search/trends, GET /search/quota. Implementare auto-refresh quota ogni 30 secondi nel store.",
            "status": "pending",
            "testStrategy": "Test unitari TypeScript per DeepSearchClient con mock window.electronAPI. Test Svelte per SearchQuotaWidget verificando rendering corretto di progress bar e badge. Test IPC handlers con mock sidecar responses. Test FastAPI endpoints con pytest per verificare serializzazione corretta delle risposte. Test E2E per verificare aggiornamento reattivo della UI quando le quote cambiano.",
            "parentId": "18"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Configurazione Jina AI e Firecrawl MCP servers, 2) Rate limiter con token bucket per API calls, 3) Search orchestrator con fallback chain Jina → Firecrawl → DuckDuckGo, 4) Integrazione con CaptioningAgent per trend research, 5) UI quota widget e settings per configurazione"
      },
      {
        "id": "19",
        "title": "OPTIONAL UPGRADE: Docker Model Runner per LLM Locali",
        "description": "Implementare l'integrazione opzionale con Docker Model Runner per l'esecuzione locale di modelli LLM (Qwen, Llama, Mistral, Gemma) senza costi API, includendo detection Docker Desktop 4.40+, UI Model Browser con download manager, benchmark performance e integrazione come provider 'dmr' in cagent.yaml con fallback automatico a cloud.",
        "details": "## Struttura Directory\n\n```\nelectron/\n├── docker-model-runner.ts          # Detection e gestione Docker Model Runner\n├── dmr-benchmark.ts                 # Benchmark locale vs cloud\n└── ipc-handlers.ts                  # Estensione con handler DMR\n\npython/\n├── providers/\n│   ├── __init__.py\n│   ├── dmr_provider.py              # Provider LLM per Docker Model Runner\n│   └── fallback_manager.py          # Gestione fallback locale → cloud\n\nsrc/lib/\n├── services/\n│   └── dmr-client.ts                # Client TypeScript per Docker Model Runner\n├── stores/\n│   └── dmr-models.svelte.ts         # Store Svelte 5 per modelli locali\n└── components/custom/\n    ├── DMRModelBrowser.svelte       # Browser modelli disponibili\n    ├── DMRDownloadManager.svelte    # Download con progress bar\n    └── DMRBenchmarkCard.svelte      # Risultati benchmark\n\nsrc/routes/settings/\n└── local-llm/\n    └── +page.svelte                 # Pagina settings LLM locali\n```\n\n## 1. Detection Docker Desktop e Model Runner (`electron/docker-model-runner.ts`)\n\n```typescript\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\ninterface DockerDesktopInfo {\n  installed: boolean;\n  version: string | null;\n  modelRunnerEnabled: boolean;\n  platform: 'macos' | 'windows' | 'linux';\n  architecture: 'arm64' | 'amd64';\n}\n\ninterface DMRModel {\n  name: string;\n  size: string;\n  quantization: string;\n  downloaded: boolean;\n  downloadProgress?: number;\n}\n\nexport class DockerModelRunnerDetector {\n  async detectDockerDesktop(): Promise<DockerDesktopInfo> {\n    try {\n      // Verifica Docker Desktop (NON solo Engine)\n      const { stdout: versionOutput } = await execAsync('docker version --format \"{{.Server.Platform.Name}}\"');\n      const isDesktop = versionOutput.includes('Docker Desktop');\n      \n      if (!isDesktop) {\n        return { installed: false, version: null, modelRunnerEnabled: false, platform: this.getPlatform(), architecture: this.getArch() };\n      }\n      \n      // Estrai versione Docker Desktop\n      const { stdout: fullVersion } = await execAsync('docker version --format \"{{.Client.Version}}\"');\n      const version = fullVersion.trim();\n      const [major, minor] = version.split('.').map(Number);\n      \n      // Richiede Docker Desktop 4.40+\n      const meetsMinVersion = major > 4 || (major === 4 && minor >= 40);\n      \n      // Verifica Model Runner enabled\n      const modelRunnerEnabled = meetsMinVersion && await this.checkModelRunnerEnabled();\n      \n      return {\n        installed: true,\n        version,\n        modelRunnerEnabled,\n        platform: this.getPlatform(),\n        architecture: this.getArch()\n      };\n    } catch (error) {\n      return { installed: false, version: null, modelRunnerEnabled: false, platform: this.getPlatform(), architecture: this.getArch() };\n    }\n  }\n  \n  private async checkModelRunnerEnabled(): Promise<boolean> {\n    try {\n      // Docker Model Runner espone endpoint OpenAI-compatibile su localhost\n      const { stdout } = await execAsync('curl -s http://localhost:12434/v1/models');\n      return stdout.includes('models');\n    } catch {\n      return false;\n    }\n  }\n  \n  async listAvailableModels(): Promise<DMRModel[]> {\n    // Modelli supportati da Docker Model Runner\n    return [\n      { name: 'ai/qwen2.5:7B-Q4_K_M', size: '4.4GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/qwen2.5:14B-Q4_K_M', size: '8.9GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/llama3.2:3B-Q4_K_M', size: '2.0GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/llama3.1:8B-Q4_K_M', size: '4.9GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/mistral:7B-Q4_K_M', size: '4.4GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/gemma2:9B-Q4_K_M', size: '5.4GB', quantization: 'Q4_K_M', downloaded: false },\n    ];\n  }\n  \n  async pullModel(modelName: string, onProgress: (progress: number) => void): Promise<boolean> {\n    return new Promise((resolve, reject) => {\n      const proc = exec(`docker model pull ${modelName}`);\n      \n      proc.stdout?.on('data', (data) => {\n        // Parse progress da output Docker\n        const match = data.match(/(\\d+)%/);\n        if (match) onProgress(parseInt(match[1]));\n      });\n      \n      proc.on('close', (code) => resolve(code === 0));\n      proc.on('error', reject);\n    });\n  }\n}\n```\n\n## 2. Provider Python per Docker Model Runner (`python/providers/dmr_provider.py`)\n\n```python\nfrom typing import AsyncIterator, Optional\nimport httpx\nimport json\n\nclass DockerModelRunnerProvider:\n    \"\"\"Provider LLM che utilizza Docker Model Runner via API OpenAI-compatibile.\"\"\"\n    \n    def __init__(self, base_url: str = \"http://localhost:12434/v1\"):\n        self.base_url = base_url\n        self.client = httpx.AsyncClient(base_url=base_url, timeout=120.0)\n    \n    async def health_check(self) -> bool:\n        \"\"\"Verifica che Docker Model Runner sia attivo.\"\"\"\n        try:\n            response = await self.client.get(\"/models\")\n            return response.status_code == 200\n        except httpx.RequestError:\n            return False\n    \n    async def list_models(self) -> list[dict]:\n        \"\"\"Elenca modelli disponibili localmente.\"\"\"\n        response = await self.client.get(\"/models\")\n        data = response.json()\n        return data.get(\"data\", [])\n    \n    async def chat_completion(\n        self,\n        model: str,\n        messages: list[dict],\n        temperature: float = 0.7,\n        max_tokens: int = 2048,\n        stream: bool = False\n    ) -> AsyncIterator[str] | dict:\n        \"\"\"Esegue inference locale con streaming opzionale.\"\"\"\n        payload = {\n            \"model\": model,\n            \"messages\": messages,\n            \"temperature\": temperature,\n            \"max_tokens\": max_tokens,\n            \"stream\": stream\n        }\n        \n        if stream:\n            async with self.client.stream(\"POST\", \"/chat/completions\", json=payload) as response:\n                async for line in response.aiter_lines():\n                    if line.startswith(\"data: \"):\n                        chunk = line[6:]\n                        if chunk != \"[DONE]\":\n                            yield json.loads(chunk)[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n        else:\n            response = await self.client.post(\"/chat/completions\", json=payload)\n            return response.json()\n    \n    async def close(self):\n        await self.client.aclose()\n```\n\n## 3. Fallback Manager (`python/providers/fallback_manager.py`)\n\n```python\nfrom typing import Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass FallbackManager:\n    \"\"\"Gestisce fallback automatico da locale a cloud.\"\"\"\n    \n    def __init__(self, local_provider, cloud_providers: dict):\n        self.local = local_provider\n        self.cloud_providers = cloud_providers  # {'anthropic': ..., 'openai': ...}\n        self.local_failures = 0\n        self.max_local_failures = 3\n    \n    async def execute_with_fallback(\n        self,\n        model: str,\n        messages: list[dict],\n        preferred_cloud: str = \"anthropic\",\n        **kwargs\n    ):\n        \"\"\"Esegue locale con fallback automatico a cloud.\"\"\"\n        \n        # Tentativo locale\n        if self.local_failures < self.max_local_failures:\n            try:\n                if await self.local.health_check():\n                    result = await self.local.chat_completion(model, messages, **kwargs)\n                    self.local_failures = 0  # Reset su successo\n                    return {\"source\": \"local\", \"result\": result}\n            except Exception as e:\n                self.local_failures += 1\n                logger.warning(f\"Local model failed ({self.local_failures}/{self.max_local_failures}): {e}\")\n        \n        # Fallback a cloud\n        cloud = self.cloud_providers.get(preferred_cloud)\n        if cloud:\n            logger.info(f\"Falling back to cloud provider: {preferred_cloud}\")\n            result = await cloud.chat_completion(messages, **kwargs)\n            return {\"source\": \"cloud\", \"provider\": preferred_cloud, \"result\": result}\n        \n        raise RuntimeError(\"No available LLM provider (local failed, no cloud configured)\")\n```\n\n## 4. UI Model Browser (`src/lib/components/custom/DMRModelBrowser.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { Card, CardContent, CardHeader, CardTitle } from '$lib/components/ui/card';\n  import { Button } from '$lib/components/ui/button';\n  import { Progress } from '$lib/components/ui/progress';\n  import { Badge } from '$lib/components/ui/badge';\n  import { dmrModelsStore } from '$lib/stores/dmr-models.svelte';\n  import { Download, Check, Cpu, HardDrive } from 'lucide-svelte';\n  \n  interface Model {\n    name: string;\n    displayName: string;\n    size: string;\n    quantization: string;\n    downloaded: boolean;\n    downloading: boolean;\n    downloadProgress: number;\n    recommended: boolean;\n    minRam: string;\n  }\n  \n  let { models, dockerStatus } = $derived(dmrModelsStore);\n  \n  async function downloadModel(model: Model) {\n    await window.electronAPI.dmr.pullModel(model.name);\n  }\n  \n  function formatModelName(name: string): string {\n    return name.replace('ai/', '').replace(/:.*/, '');\n  }\n</script>\n\n<div class=\"space-y-4\">\n  {#if !dockerStatus.modelRunnerEnabled}\n    <Card class=\"border-yellow-500 bg-yellow-50 dark:bg-yellow-950\">\n      <CardContent class=\"pt-6\">\n        <p class=\"text-yellow-800 dark:text-yellow-200\">\n          Docker Desktop 4.40+ con Model Runner è richiesto per i modelli locali.\n          <a href=\"https://docs.docker.com/desktop/features/model-runner/\" class=\"underline\" target=\"_blank\">\n            Scopri come abilitarlo\n          </a>\n        </p>\n      </CardContent>\n    </Card>\n  {:else}\n    <div class=\"grid gap-4 md:grid-cols-2\">\n      {#each models as model}\n        <Card class:border-green-500={model.downloaded}>\n          <CardHeader class=\"pb-2\">\n            <div class=\"flex items-center justify-between\">\n              <CardTitle class=\"text-lg\">{formatModelName(model.name)}</CardTitle>\n              {#if model.recommended}\n                <Badge variant=\"secondary\">Raccomandato</Badge>\n              {/if}\n            </div>\n          </CardHeader>\n          <CardContent>\n            <div class=\"flex items-center gap-4 text-sm text-muted-foreground mb-4\">\n              <span class=\"flex items-center gap-1\">\n                <HardDrive class=\"h-4 w-4\" />\n                {model.size}\n              </span>\n              <span class=\"flex items-center gap-1\">\n                <Cpu class=\"h-4 w-4\" />\n                {model.minRam} RAM min\n              </span>\n              <Badge variant=\"outline\">{model.quantization}</Badge>\n            </div>\n            \n            {#if model.downloading}\n              <Progress value={model.downloadProgress} class=\"mb-2\" />\n              <p class=\"text-sm text-muted-foreground\">{model.downloadProgress}% completato</p>\n            {:else if model.downloaded}\n              <Button variant=\"outline\" disabled class=\"w-full\">\n                <Check class=\"mr-2 h-4 w-4\" />\n                Installato\n              </Button>\n            {:else}\n              <Button onclick={() => downloadModel(model)} class=\"w-full\">\n                <Download class=\"mr-2 h-4 w-4\" />\n                Download\n              </Button>\n            {/if}\n          </CardContent>\n        </Card>\n      {/each}\n    </div>\n  {/if}\n</div>\n```\n\n## 5. Integrazione cagent.yaml con provider 'dmr'\n\nEstendere `src/lib/services/cagent-config.ts` per supportare il provider DMR:\n\n```typescript\n// Aggiungere a CagentConfig interface\ntype LLMProvider = 'anthropic' | 'openai' | 'google' | 'perplexity' | 'dmr';\n\ninterface AgentRole {\n  name: string;\n  model: string;\n  provider: LLMProvider;\n  fallbackProvider?: LLMProvider; // Fallback automatico se locale fallisce\n  // ...\n}\n\n// Template YAML per DMR\nconst DMR_CONFIG_TEMPLATE = `\nagents:\n  captioning_agent:\n    provider: dmr\n    model: ai/qwen2.5:7B-Q4_K_M\n    fallback_provider: anthropic\n    fallback_model: claude-3-haiku\n  extraction_agent:\n    provider: dmr\n    model: ai/llama3.2:3B-Q4_K_M\n    fallback_provider: openai\n    fallback_model: gpt-4o-mini\n`;\n```\n\n## 6. Benchmark Performance (`electron/dmr-benchmark.ts`)\n\n```typescript\ninterface BenchmarkResult {\n  model: string;\n  provider: 'local' | 'cloud';\n  tokensPerSecond: number;\n  latencyMs: number;\n  memoryUsageMB: number;\n  quality: 'high' | 'medium' | 'low';\n}\n\nexport async function runBenchmark(\n  localModel: string,\n  cloudProvider: string,\n  cloudModel: string,\n  testPrompt: string\n): Promise<{local: BenchmarkResult, cloud: BenchmarkResult}> {\n  // Benchmark locale\n  const localStart = Date.now();\n  const localResult = await callDMR(localModel, testPrompt);\n  const localLatency = Date.now() - localStart;\n  \n  // Benchmark cloud\n  const cloudStart = Date.now();\n  const cloudResult = await callCloud(cloudProvider, cloudModel, testPrompt);\n  const cloudLatency = Date.now() - cloudStart;\n  \n  return {\n    local: {\n      model: localModel,\n      provider: 'local',\n      tokensPerSecond: calculateTPS(localResult, localLatency),\n      latencyMs: localLatency,\n      memoryUsageMB: await getProcessMemory(),\n      quality: evaluateQuality(localResult, cloudResult) // Usa cloud come riferimento\n    },\n    cloud: {\n      model: cloudModel,\n      provider: 'cloud',\n      tokensPerSecond: calculateTPS(cloudResult, cloudLatency),\n      latencyMs: cloudLatency,\n      memoryUsageMB: 0,\n      quality: 'high'\n    }\n  };\n}\n```\n\n## Requisiti Hardware Documentati\n\nAggiungere in UI e documentazione:\n\n| Modello | RAM Minima | RAM Raccomandata | Note |\n|---------|------------|------------------|------|\n| 3B (Llama 3.2) | 8GB | 12GB | Veloce, qualità base |\n| 7B (Qwen, Mistral) | 16GB | 24GB | Buon compromesso |\n| 14B (Qwen) | 32GB | 48GB | Alta qualità, lento |\n\n- Apple Silicon M1+ raccomandato per performance ottimali\n- Su Intel/AMD, aspettarsi 2-5x più lento rispetto a Apple Silicon\n- GPU dedicata non utilizzata (Docker Model Runner usa CPU)",
        "testStrategy": "## Test Unitari TypeScript\n\n### 1. `test/docker-model-runner.test.ts`\n- Test `detectDockerDesktop()` con mock exec che simula Docker Desktop 4.40+ installato\n- Test `detectDockerDesktop()` con mock che simula solo Docker Engine (non Desktop)\n- Test `detectDockerDesktop()` con versione < 4.40 (modelRunnerEnabled deve essere false)\n- Test `checkModelRunnerEnabled()` con mock curl response successo\n- Test `checkModelRunnerEnabled()` con timeout/errore connessione\n- Test `listAvailableModels()` ritorna lista modelli corretta\n- Test `pullModel()` con mock progress events\n\n### 2. `test/dmr-client.test.ts`\n- Test client HTTP verso endpoint DMR mock\n- Test streaming response parsing\n- Test timeout handling (modelli locali possono essere lenti)\n- Test retry logic su errori temporanei\n\n## Test Unitari Python\n\n### 1. `tests/unit/test_dmr_provider.py`\n- Test `health_check()` con mock server attivo → True\n- Test `health_check()` con connection refused → False\n- Test `chat_completion()` non-streaming con risposta valida\n- Test `chat_completion()` streaming con chunks multipli\n- Test handling errori API (4xx, 5xx)\n- Test timeout su risposte lente\n\n### 2. `tests/unit/test_fallback_manager.py`\n- Test che locale venga usato se disponibile\n- Test fallback a cloud dopo 3 fallimenti locali consecutivi\n- Test reset contatore fallimenti dopo successo\n- Test errore se né locale né cloud disponibili\n- Test preferenza cloud provider rispettata\n\n## Test Integrazione\n\n### 1. `tests/integration/test_dmr_e2e.py`\n- Test con Docker Model Runner reale (skip se non disponibile)\n- Test pull modello piccolo (3B) e verifica download\n- Test inference base con prompt semplice\n- Test performance: latency < 30s per prompt corto su M1+\n\n### 2. Test UI Svelte\n- Test rendering DMRModelBrowser con modelli mock\n- Test progress bar aggiornamento durante download\n- Test stato \"non disponibile\" quando Docker Desktop manca\n- Test click download triggera IPC corretto\n- Test badge \"Installato\" appare dopo download completato\n\n## Test Benchmark\n\n### 1. `tests/benchmark/test_performance.ts`\n- Test calcolo tokens/secondo corretto\n- Test comparazione locale vs cloud produce risultati validi\n- Test memory usage tracking durante inference\n\n## Test E2E\n\n### 1. `e2e/dmr-flow.test.ts`\n- Flow completo: detect Docker → mostra UI → download modello → configura come provider → esegui inference\n- Verifica fallback automatico: disabilita Docker → verifica switch a cloud\n- Verifica persistenza: riavvia app → modelli scaricati ancora visibili\n- Test settings: assegna modello locale a ruolo → verifica cagent.yaml generato correttamente",
        "status": "pending",
        "dependencies": [
          "3",
          "4",
          "5",
          "16"
        ],
        "priority": "low",
        "subtasks": [
          {
            "id": "1",
            "title": "Detection Docker Desktop 4.40+ e Model Runner Status",
            "description": "Implementare il modulo di rilevamento Docker Desktop con verifica versione minima 4.40+ e stato di abilitazione del Model Runner.",
            "dependencies": [],
            "details": "Creare `electron/docker-model-runner.ts` con classe `DockerModelRunnerDetector` che: 1) Esegue `docker version` per verificare presenza Docker Desktop (non solo Engine), 2) Estrae e valida versione >= 4.40, 3) Verifica Model Runner attivo tramite health check su `http://localhost:12434/v1/models`, 4) Rileva piattaforma (macos/windows/linux) e architettura (arm64/amd64), 5) Espone IPC handlers in `ipc-handlers.ts` per query stato da renderer. Gestire tutti i casi di errore con fallback graceful.",
            "status": "pending",
            "testStrategy": "Test unitari con mock di exec per simulare: Docker Desktop installato 4.40+, versione < 4.40, solo Docker Engine senza Desktop, Docker non installato. Test integrazione per health check Model Runner con mock HTTP.",
            "parentId": "19"
          },
          {
            "id": "2",
            "title": "UI Model Browser con Lista Modelli Disponibili",
            "description": "Creare interfaccia Svelte per visualizzare i modelli LLM disponibili (Qwen, Llama, Mistral, Gemma) con informazioni su dimensione, quantizzazione e requisiti hardware.",
            "dependencies": [
              1
            ],
            "details": "Implementare: 1) Store Svelte 5 `dmr-models.svelte.ts` con stato modelli e Docker status usando runes ($state, $derived), 2) Componente `DMRModelBrowser.svelte` con grid card per ogni modello mostrando: nome, dimensione disco, quantizzazione (Q4_K_M), RAM minima richiesta, badge 'Raccomandato' per modelli ottimali, 3) Warning card se Docker Desktop < 4.40 o Model Runner disabilitato con link documentazione, 4) Pagina settings `src/routes/settings/local-llm/+page.svelte` integrata nel menu esistente. Utilizzare componenti shadcn-svelte (Card, Badge, Button).",
            "status": "pending",
            "testStrategy": "Test componente con mock store per verificare rendering corretto card modelli, stato Docker warning, badge raccomandato. Test accessibilità e responsive design.",
            "parentId": "19"
          },
          {
            "id": "3",
            "title": "Download Manager con Progress Tracking",
            "description": "Implementare sistema di download modelli con progress bar real-time, gestione errori e resume capability.",
            "dependencies": [
              1,
              2
            ],
            "details": "Estendere `DockerModelRunnerDetector` con metodo `pullModel()` che: 1) Esegue `docker model pull <nome>` in background, 2) Parsa output per estrarre percentuale progresso, 3) Emette eventi IPC per aggiornare UI in tempo reale. Creare componente `DMRDownloadManager.svelte` con: Progress bar per download attivo, stato 'Installato' per modelli già scaricati, gestione cancellazione download, persistenza stato in store. Gestire edge cases: interruzione rete, spazio disco insufficiente, download paralleli.",
            "status": "pending",
            "testStrategy": "Test mock processo docker con output simulato per parsing progress. Test UI per transizioni stato pending→downloading→installed. Test gestione errori con mock failure scenarios.",
            "parentId": "19"
          },
          {
            "id": "4",
            "title": "Provider Python per Docker Model Runner API OpenAI-compatibile",
            "description": "Creare provider Python che utilizza l'API OpenAI-compatibile esposta da Docker Model Runner per inference locale.",
            "dependencies": [],
            "details": "Implementare `python/providers/dmr_provider.py` con classe `DockerModelRunnerProvider`: 1) Client httpx async con base URL `http://localhost:12434/v1`, 2) Metodo `health_check()` per verifica disponibilità, 3) Metodo `list_models()` per elenco modelli installati, 4) Metodo `chat_completion()` con supporto streaming SSE, 5) Parametri: model, messages, temperature, max_tokens. Timeout configurabile (default 120s per modelli lenti). Gestione errori con eccezioni specifiche per timeout, connessione refused, modello non trovato.",
            "status": "pending",
            "testStrategy": "Test unitari con mock httpx per verificare: chiamate API corrette, parsing response, streaming chunks, gestione timeout. Test integrazione con Docker Model Runner reale se disponibile.",
            "parentId": "19"
          },
          {
            "id": "5",
            "title": "Fallback Manager Locale → Cloud",
            "description": "Implementare gestore fallback automatico che passa da modello locale a provider cloud quando l'inference locale fallisce.",
            "dependencies": [
              4
            ],
            "details": "Creare `python/providers/fallback_manager.py` con classe `FallbackManager`: 1) Accetta provider locale + dizionario provider cloud (anthropic, openai), 2) Metodo `execute_with_fallback()` che tenta prima locale, poi cloud su failure, 3) Circuit breaker: dopo 3 fallimenti consecutivi locali, bypassa diretto a cloud per N minuti, 4) Logging dettagliato source (local/cloud) per analytics, 5) Reset contatore fallimenti su successo locale. Integrare in FastAPI sidecar come middleware per tutti gli endpoint agent. Configurazione fallback_provider in cagent.yaml per-agent.",
            "status": "pending",
            "testStrategy": "Test unitari per: fallback dopo N failures, circuit breaker activation/reset, selezione provider cloud corretto. Test integrazione con mock providers per verificare retry logic.",
            "parentId": "19"
          },
          {
            "id": "6",
            "title": "Benchmark Performance Locale vs Cloud",
            "description": "Creare sistema di benchmark per confrontare performance (tokens/sec, latenza) tra modelli locali Docker Model Runner e provider cloud.",
            "dependencies": [
              1,
              4
            ],
            "details": "Implementare `electron/dmr-benchmark.ts` con funzione `runBenchmark()`: 1) Prompt di test standardizzato (~100 token input), 2) Misura tempo risposta e calcola tokens/secondo per locale e cloud, 3) Rileva memoria utilizzata dal processo Docker, 4) Valutazione qualità comparando output locale vs cloud reference. Creare componente `DMRBenchmarkCard.svelte` con: bottone 'Esegui Benchmark', risultati tabulari (locale vs cloud), indicatori visivi performance (verde/giallo/rosso), raccomandazione automatica quale modello usare per ogni ruolo agent. Salvare risultati in localStorage per riferimento.",
            "status": "pending",
            "testStrategy": "Test con mock timing per verificare calcoli TPS corretti. Test UI per rendering risultati e raccomandazioni. Test persistenza localStorage.",
            "parentId": "19"
          }
        ],
        "complexity": 6,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Detection Docker Desktop 4.40+ e Model Runner status, 2) UI Model Browser con lista modelli disponibili (Qwen, Llama, Mistral, Gemma), 3) Download manager con progress tracking, 4) Provider Python per Docker Model Runner API OpenAI-compatibile, 5) Fallback manager locale → cloud, 6) Benchmark performance locale vs cloud"
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-01-06T21:46:43.815Z",
      "taskCount": 19,
      "completedCount": 1,
      "tags": [
        "master"
      ]
    }
  }
}
