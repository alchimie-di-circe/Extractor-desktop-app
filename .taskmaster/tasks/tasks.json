{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Configurazione shadcn-svelte e Sistema UI Base",
        "description": "Installare e configurare shadcn-svelte come libreria UI principale, insieme ai componenti fondamentali per l'interfaccia dell'applicazione.",
        "details": "1. Eseguire `npx shadcn-svelte@latest init` per inizializzare shadcn-svelte\n2. Configurare il file `components.json` con le preferenze di stile (default, new-york)\n3. Installare i componenti base: button, card, dialog, input, form, toast, dropdown-menu, tabs\n4. Creare la struttura delle cartelle: `src/lib/components/ui/` per componenti shadcn\n5. Configurare il tema dark/light mode con CSS variables\n6. Creare un layout base con sidebar navigation in `src/routes/+layout.svelte`\n7. Implementare le route base: dashboard (#/), brands (#/brands), extract (#/extract), edit (#/edit), publish (#/publish), settings (#/settings)\n\nPseudo-codice per layout:\n```svelte\n<script>\n  import { page } from '$app/stores';\n  const routes = [\n    { path: '#/', label: 'Dashboard', icon: 'home' },\n    { path: '#/extract', label: 'Estrai', icon: 'image' },\n    // ...\n  ];\n</script>\n<div class=\"flex h-screen\">\n  <aside class=\"w-64 border-r\">\n    {#each routes as route}\n      <a href={route.path} class:active={$page.url.hash === route.path}>{route.label}</a>\n    {/each}\n  </aside>\n  <main class=\"flex-1\"><slot /></main>\n</div>\n```",
        "testStrategy": "Test unitari per verificare il rendering dei componenti shadcn. Test di navigazione per assicurarsi che tutte le route funzionino correttamente con hash routing. Verificare che il tema dark/light switch funzioni.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Inizializzazione shadcn-svelte con Risoluzione Conflitti TailwindCSS v4",
            "description": "Inizializzare shadcn-svelte nel progetto gestendo la compatibilità con TailwindCSS v4 e Svelte 5 runes. Configurare components.json con le preferenze di stile e risolvere eventuali conflitti di configurazione.",
            "dependencies": [],
            "details": "1. Verificare la compatibilità di shadcn-svelte con TailwindCSS v4 (attualmente usa la sintassi @import 'tailwindcss' e @plugin)\n2. Eseguire `npx shadcn-svelte@latest init` e selezionare le opzioni appropriate\n3. Configurare components.json scegliendo lo stile (default/new-york), colori, e percorso componenti ($lib/components/ui)\n4. Se shadcn-svelte richiede TailwindCSS v3, valutare: a) downgrade a v3, b) configurazione manuale delle CSS variables\n5. Aggiornare app.css per includere le variabili CSS di shadcn mantenendo la sintassi v4\n6. Creare la struttura cartelle: src/lib/components/ui/ e src/lib/components/custom/\n7. Verificare che vite.config.ts e svelte.config.js siano configurati correttamente\n8. Testare che il build funzioni senza errori con `npm run check`",
            "status": "done",
            "testStrategy": "Eseguire `npm run check` per verificare assenza errori TypeScript. Verificare che la build vite funzioni con `npm run start`. Controllare che le CSS variables siano caricate correttamente ispezionando il DOM nel browser.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.134Z"
          },
          {
            "id": 2,
            "title": "Installazione Componenti Base shadcn-svelte",
            "description": "Installare tutti i componenti UI fondamentali richiesti: button, card, dialog, input, form, toast, dropdown-menu, tabs usando il CLI di shadcn-svelte.",
            "dependencies": [
              1
            ],
            "details": "1. Installare i componenti uno alla volta per gestire eventuali errori:\n   - `npx shadcn-svelte@latest add button`\n   - `npx shadcn-svelte@latest add card`\n   - `npx shadcn-svelte@latest add dialog`\n   - `npx shadcn-svelte@latest add input`\n   - `npx shadcn-svelte@latest add form`\n   - `npx shadcn-svelte@latest add toast` (include sonner o toaster)\n   - `npx shadcn-svelte@latest add dropdown-menu`\n   - `npx shadcn-svelte@latest add tabs`\n2. Installare dipendenze aggiuntive se richieste (bits-ui, formsnap, sveltekit-superforms per form)\n3. Verificare che tutti i componenti siano stati creati in src/lib/components/ui/\n4. Creare un file index.ts in src/lib/components/ui/ per re-export centralizzato\n5. Installare lucide-svelte per le icone: `npm install lucide-svelte`\n6. Testare l'import di ogni componente in +page.svelte temporaneamente",
            "status": "done",
            "testStrategy": "Creare una pagina test temporanea che importa e renderizza tutti i componenti. Verificare che ogni componente sia visibile e styled correttamente. Eseguire `npm run check` per confermare assenza errori di tipo.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.151Z"
          },
          {
            "id": 3,
            "title": "Configurazione Sistema Tema Dark/Light con CSS Variables e Toggle",
            "description": "Implementare un sistema completo di theming dark/light mode usando CSS variables, persistenza locale, e un componente toggle accessibile.",
            "dependencies": [
              1
            ],
            "details": "1. Estendere app.css con le CSS variables per entrambi i temi:\n   ```css\n   :root {\n     --background: 0 0% 100%;\n     --foreground: 222.2 84% 4.9%;\n     /* ... altre variabili shadcn */\n   }\n   .dark {\n     --background: 222.2 84% 4.9%;\n     --foreground: 210 40% 98%;\n   }\n   ```\n2. Creare src/lib/stores/theme.svelte.ts con Svelte 5 runes:\n   ```typescript\n   let theme = $state<'light' | 'dark'>('light');\n   export function toggleTheme() { ... }\n   export function getTheme() { return theme; }\n   ```\n3. Implementare persistenza in localStorage e rispetto di prefers-color-scheme\n4. Creare src/lib/components/custom/ThemeToggle.svelte con icone sun/moon\n5. Aggiungere script in app.html per prevenire flash of unstyled content (FOUC)\n6. Applicare classe 'dark' al tag html in base alla preferenza",
            "status": "done",
            "testStrategy": "Verificare che il toggle cambi effettivamente il tema visivamente. Testare persistenza ricaricando la pagina. Verificare che prefers-color-scheme sia rispettato al primo caricamento. Testare accessibilità del toggle con screen reader.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.157Z"
          },
          {
            "id": 4,
            "title": "Creazione Layout Sidebar con Navigazione Responsive",
            "description": "Implementare il layout principale dell'applicazione con sidebar navigation responsive, supporto mobile con hamburger menu, e indicatore di route attiva.",
            "dependencies": [
              2,
              3
            ],
            "details": "1. Creare src/routes/+layout.svelte con struttura flex:\n   ```svelte\n   <script>\n     import { page } from '$app/stores';\n     import ThemeToggle from '$lib/components/custom/ThemeToggle.svelte';\n     import { Home, Image, Edit, Send, Settings, Menu } from 'lucide-svelte';\n     \n     const routes = [\n       { path: '/', label: 'Dashboard', icon: Home },\n       { path: '/brands', label: 'Brand', icon: Folder },\n       { path: '/extract', label: 'Estrai', icon: Image },\n       { path: '/edit', label: 'Modifica', icon: Edit },\n       { path: '/publish', label: 'Pubblica', icon: Send },\n       { path: '/settings', label: 'Impostazioni', icon: Settings },\n     ];\n     let sidebarOpen = $state(true);\n   </script>\n   ```\n2. Implementare sidebar collapsible con transizioni smooth\n3. Aggiungere responsive breakpoint: sidebar nascosta sotto 768px, visibile hamburger\n4. Creare header con logo app, breadcrumb, e ThemeToggle\n5. Stilare active state per link corrente usando $page.url.pathname\n6. Aggiungere hover e focus states accessibili\n7. Implementare Sheet/Drawer da shadcn per mobile sidebar",
            "status": "done",
            "testStrategy": "Testare navigazione cliccando tutti i link. Verificare che l'active state si aggiorni correttamente. Testare responsive ridimensionando la finestra. Verificare accessibilità keyboard navigation (Tab, Enter).",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.161Z"
          },
          {
            "id": 5,
            "title": "Implementazione Sistema Hash Routing per Tutte le Route",
            "description": "Creare le pagine per tutte le route dell'applicazione (dashboard, brands, extract, edit, publish, settings) sfruttando l'hash router già configurato in svelte.config.js.",
            "dependencies": [
              4
            ],
            "details": "1. Il progetto ha già hash routing configurato in svelte.config.js (router: { type: 'hash' })\n2. Creare le cartelle route in src/routes/:\n   - src/routes/+page.svelte (Dashboard - già esistente, da aggiornare)\n   - src/routes/brands/+page.svelte\n   - src/routes/extract/+page.svelte\n   - src/routes/edit/+page.svelte\n   - src/routes/publish/+page.svelte\n   - src/routes/settings/+page.svelte\n3. Ogni pagina deve avere:\n   - Titolo h1 con nome sezione\n   - Placeholder Card shadcn con descrizione funzionalità futura\n   - Layout consistente con padding appropriato\n4. Aggiornare Dashboard (+page.svelte) con cards di overview\n5. Settings deve includere placeholder per sottosezioni (LLM Providers, API Keys, Preferences)\n6. Verificare che la navigazione hash funzioni: /#/, /#/brands, /#/extract, ecc.\n7. Aggiungere meta title dinamico per ogni pagina",
            "status": "done",
            "testStrategy": "Navigare manualmente a ogni route e verificare il rendering. Testare deep linking aprendo direttamente URL come /#/settings. Verificare che il back/forward del browser funzioni. Controllare che non ci siano errori 404 in console.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.166Z"
          }
        ],
        "tags": [
          "frontend",
          "ui-framework",
          "phase-0-foundation",
          "svelte"
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi questo task in subtask che coprono: 1) Inizializzazione shadcn-svelte con risoluzione conflitti TailwindCSS v4, 2) Installazione componenti base (button, card, dialog, input, form, toast, dropdown-menu, tabs), 3) Configurazione sistema tema dark/light con CSS variables e toggle, 4) Creazione layout sidebar con navigazione responsive, 5) Implementazione sistema hash routing per tutte le route (dashboard, brands, extract, edit, publish, settings)",
        "updatedAt": "2026-02-04T02:27:18.166Z"
      },
      {
        "id": 2,
        "title": "Sistema IPC Bridge e Gestione Sicura delle Credenziali",
        "description": "Implementare il sistema IPC tra main process e renderer, includendo un servizio keychain per la memorizzazione sicura delle API keys tramite OS keychain nativo.",
        "details": "1. Estendere `electron/preload.ts` con contextBridge per esporre API sicure:\n```typescript\nimport { contextBridge, ipcRenderer } from 'electron';\ncontextBridge.exposeInMainWorld('electronAPI', {\n  // Keychain\n  saveCredential: (service: string, account: string, password: string) => \n    ipcRenderer.invoke('keychain:save', service, account, password),\n  getCredential: (service: string, account: string) => \n    ipcRenderer.invoke('keychain:get', service, account),\n  deleteCredential: (service: string, account: string) => \n    ipcRenderer.invoke('keychain:delete', service, account),\n  // Config\n  getConfig: (key: string) => ipcRenderer.invoke('config:get', key),\n  setConfig: (key: string, value: any) => ipcRenderer.invoke('config:set', key, value),\n});\n```\n2. Creare `electron/keychain.ts` usando `keytar` per macOS keychain nativo\n3. Creare `electron/ipc-handlers.ts` per gestire tutti gli handler IPC\n4. Creare `electron/config-manager.ts` per gestire configurazioni persistenti con electron-store\n5. Aggiornare `electron/main.ts` per registrare tutti gli handler IPC\n6. Installare dipendenze: `keytar`, `electron-store`\n7. Creare tipi TypeScript in `src/app.d.ts` per l'API esposta\n8. Abilitare context isolation e sandbox nel BrowserWindow",
        "testStrategy": "Test di integrazione per verificare che le credenziali vengano salvate e recuperate correttamente dal keychain. Test per assicurarsi che il context isolation sia attivo e che il renderer non possa accedere direttamente a Node.js APIs.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Installazione dipendenze native keytar ed electron-store con configurazione build",
            "description": "Installare keytar per l'accesso al keychain nativo di macOS e electron-store per la persistenza delle configurazioni, includendo la configurazione necessaria per i moduli nativi Node.",
            "dependencies": [],
            "details": "1. Eseguire `pnpm add keytar electron-store` per installare le dipendenze\n2. Aggiungere `keytar` alla configurazione `pnpm.onlyBuiltDependencies` in package.json per garantire la compilazione corretta dei moduli nativi\n3. Verificare che electron-rebuild sia disponibile o installarlo se necessario per la ricompilazione dei moduli nativi\n4. Testare che keytar venga compilato correttamente eseguendo `pnpm start`\n5. In caso di errori di build, configurare node-gyp con le dipendenze di sistema richieste (Xcode Command Line Tools su macOS)",
            "status": "done",
            "testStrategy": "Eseguire `pnpm start` e verificare che l'app si avvii senza errori relativi a moduli nativi. Verificare che keytar e electron-store siano presenti in node_modules e che keytar abbia i binding nativi compilati.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.170Z"
          },
          {
            "id": 2,
            "title": "Implementazione modulo keychain.ts con wrapper keytar cross-platform",
            "description": "Creare il modulo electron/keychain.ts che incapsula le operazioni di keytar per la gestione sicura delle credenziali tramite il keychain nativo del sistema operativo.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `electron/keychain.ts` con le seguenti funzioni:\n   - `saveCredential(service: string, account: string, password: string): Promise<void>`\n   - `getCredential(service: string, account: string): Promise<string | null>`\n   - `deleteCredential(service: string, account: string): Promise<boolean>`\n2. Implementare gestione degli errori con messaggi descrittivi\n3. Definire costanti per il service name dell'applicazione (es. 'com.electron-svelte.credentials')\n4. Aggiungere logging per debugging in development\n5. Gestire il caso in cui keytar non sia disponibile (fallback o errore esplicito)",
            "status": "done",
            "testStrategy": "Test unitari per verificare save/get/delete delle credenziali. Test per gestione errori quando service o account sono vuoti. Verificare manualmente che le credenziali appaiano nel Keychain Access di macOS.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.174Z"
          },
          {
            "id": 3,
            "title": "Implementazione config-manager.ts con electron-store per configurazioni persistenti",
            "description": "Creare il modulo electron/config-manager.ts per gestire le configurazioni persistenti dell'applicazione utilizzando electron-store con schema tipizzato.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `electron/config-manager.ts` con interfaccia tipizzata per le configurazioni:\n   ```typescript\n   interface AppConfig {\n     selectedProvider?: string;\n     selectedModel?: string;\n     theme?: 'light' | 'dark' | 'system';\n     // altre configurazioni non sensibili\n   }\n   ```\n2. Inizializzare electron-store con schema e valori di default\n3. Implementare funzioni:\n   - `getConfig<K extends keyof AppConfig>(key: K): AppConfig[K]`\n   - `setConfig<K extends keyof AppConfig>(key: K, value: AppConfig[K]): void`\n   - `getAllConfig(): AppConfig`\n4. NON memorizzare API keys in electron-store (usare keychain)\n5. Configurare la directory di storage appropriata per l'app",
            "status": "done",
            "testStrategy": "Test unitari per get/set configurazioni. Verificare che i dati persistano tra riavvii dell'app. Test che i valori di default siano applicati correttamente. Verificare che il file JSON di configurazione sia creato nella directory corretta.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.178Z"
          },
          {
            "id": 4,
            "title": "Creazione ipc-handlers.ts centralizzato per keychain e config",
            "description": "Implementare il modulo electron/ipc-handlers.ts che registra tutti gli handler IPC per keychain e configurazioni, centralizzando la logica di comunicazione main-renderer.",
            "dependencies": [
              2,
              3
            ],
            "details": "1. Creare `electron/ipc-handlers.ts` con funzione `registerIPCHandlers()`\n2. Registrare handler per keychain:\n   - `keychain:save` -> invoca keychain.saveCredential\n   - `keychain:get` -> invoca keychain.getCredential  \n   - `keychain:delete` -> invoca keychain.deleteCredential\n3. Registrare handler per config:\n   - `config:get` -> invoca configManager.getConfig\n   - `config:set` -> invoca configManager.setConfig\n4. Implementare validazione degli input per prevenire injection\n5. Aggiungere try-catch con messaggi di errore appropriati per ogni handler\n6. Loggare operazioni sensibili per audit trail",
            "status": "done",
            "testStrategy": "Test di integrazione per verificare che gli handler IPC rispondano correttamente alle chiamate invoke. Test per validazione input (service/account vuoti, tipi incorretti). Verificare che errori vengano propagati correttamente al renderer.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.182Z"
          },
          {
            "id": 5,
            "title": "Estensione preload.ts con contextBridge API sicure",
            "description": "Implementare il preload script che espone API sicure al renderer tramite contextBridge, creando un'interfaccia tipizzata per keychain e configurazioni.",
            "dependencies": [
              4
            ],
            "details": "1. Modificare `electron/preload.ts` per importare contextBridge e ipcRenderer\n2. Usare `contextBridge.exposeInMainWorld('electronAPI', {...})` per esporre:\n   - `saveCredential(service, account, password)` -> ipcRenderer.invoke('keychain:save', ...)\n   - `getCredential(service, account)` -> ipcRenderer.invoke('keychain:get', ...)\n   - `deleteCredential(service, account)` -> ipcRenderer.invoke('keychain:delete', ...)\n   - `getConfig(key)` -> ipcRenderer.invoke('config:get', ...)\n   - `setConfig(key, value)` -> ipcRenderer.invoke('config:set', ...)\n3. NON esporre ipcRenderer direttamente\n4. Aggiornare `src/app.d.ts` con dichiarazione globale:\n   ```typescript\n   interface ElectronAPI {\n     saveCredential(service: string, account: string, password: string): Promise<void>;\n     getCredential(service: string, account: string): Promise<string | null>;\n     deleteCredential(service: string, account: string): Promise<boolean>;\n     getConfig(key: string): Promise<unknown>;\n     setConfig(key: string, value: unknown): Promise<void>;\n   }\n   declare global {\n     interface Window {\n       electronAPI: ElectronAPI;\n     }\n   }\n   ```",
            "status": "done",
            "testStrategy": "Verificare che window.electronAPI sia disponibile nel renderer. Test che le chiamate vengano correttamente inoltrate al main process. Verificare che ipcRenderer non sia esposto globalmente. Test TypeScript per la tipizzazione corretta.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.185Z"
          },
          {
            "id": 6,
            "title": "Aggiornamento main.ts con security settings e registrazione handlers",
            "description": "Configurare BrowserWindow con le impostazioni di sicurezza Electron (context isolation, sandbox, nodeIntegration:false) e integrare la registrazione degli handler IPC.",
            "dependencies": [
              4,
              5
            ],
            "details": "1. Modificare `electron/main.ts` per importare e chiamare `registerIPCHandlers()` prima di app.on('ready')\n2. Aggiornare webPreferences di BrowserWindow:\n   ```typescript\n   webPreferences: {\n     preload: path.join(import.meta.dirname, 'preload.js'),\n     contextIsolation: true,\n     sandbox: true,\n     nodeIntegration: false,\n     webSecurity: true,\n   }\n   ```\n3. Aggiungere Content Security Policy appropriata\n4. Implementare gestione errori per la registrazione degli handler\n5. Verificare che il preload script venga caricato correttamente\n6. Aggiungere logging all'avvio per confermare che tutti i moduli siano inizializzati",
            "status": "done",
            "testStrategy": "Test che context isolation sia attivo verificando che process e require non siano disponibili nel renderer. Test che le API esposte tramite electronAPI funzionino correttamente. Verificare in DevTools che le impostazioni di sicurezza siano applicate. Test E2E per il flusso completo: salvataggio e recupero credenziali.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.190Z"
          }
        ],
        "tags": [
          "electron-main",
          "security",
          "phase-0-foundation",
          "electron"
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Installazione dipendenze native keytar ed electron-store con configurazione build, 2) Implementazione modulo keychain.ts con wrapper keytar cross-platform, 3) Implementazione config-manager.ts con electron-store per configurazioni persistenti, 4) Creazione ipc-handlers.ts centralizzato per keychain e config, 5) Estensione preload.ts con contextBridge API sicure, 6) Aggiornamento main.ts con security settings (context isolation, sandbox, nodeIntegration:false) e registrazione handlers",
        "updatedAt": "2026-02-04T02:27:18.190Z"
      },
      {
        "id": 3,
        "title": "UI Configurazione Provider LLM Multi-Provider",
        "description": "Creare l'interfaccia utente per configurare multipli provider LLM (Anthropic, OpenAI, Google, Perplexity) con validazione delle connessioni e memorizzazione sicura delle API keys.",
        "details": "1. Creare `src/routes/settings/llm-providers/+page.svelte` con form per ogni provider\n2. Implementare componente `src/lib/components/custom/LLMProviderCard.svelte`:\n```svelte\n<script lang=\"ts\">\n  import { Card, CardContent, CardHeader } from '$lib/components/ui/card';\n  import { Input } from '$lib/components/ui/input';\n  import { Button } from '$lib/components/ui/button';\n  \n  export let provider: { id: string; name: string; logo: string; models: string[] };\n  let apiKey = '';\n  let selectedModel = '';\n  let connectionStatus: 'idle' | 'testing' | 'success' | 'error' = 'idle';\n  \n  async function testConnection() {\n    connectionStatus = 'testing';\n    try {\n      await window.electronAPI.testLLMConnection(provider.id, apiKey, selectedModel);\n      connectionStatus = 'success';\n    } catch { connectionStatus = 'error'; }\n  }\n  \n  async function saveCredentials() {\n    await window.electronAPI.saveCredential('llm-provider', provider.id, apiKey);\n  }\n</script>\n```\n3. Creare servizio `src/lib/services/llm-config.ts` per interagire con IPC\n4. Implementare store Svelte 5 runes per stato provider: `src/lib/stores/llm-providers.svelte.ts`\n5. Creare IPC handler in main process per test connessione ai provider\n6. Provider supportati: Anthropic (Claude), OpenAI (GPT-4), Google (Gemini), Perplexity (Research)\n7. Memorizzare preferenze modello per ruolo: main, fallback, research",
        "testStrategy": "Test unitari per form validation. Test di mock per verificare che le API keys vengano salvate correttamente. Test E2E per il flusso completo: inserimento key -> test connessione -> salvataggio.",
        "priority": "high",
        "dependencies": [
          "1",
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Creazione Route Settings LLM Providers con Layout Tab",
            "description": "Creare la pagina principale di configurazione dei provider LLM con navigazione a tab per ogni provider supportato (Anthropic, OpenAI, Google, Perplexity).",
            "dependencies": [],
            "details": "1. Creare la struttura delle cartelle: `src/routes/settings/llm-providers/+page.svelte`\n2. Importare componenti shadcn-svelte: Tabs, TabsList, TabsTrigger, TabsContent\n3. Definire i 4 provider con i loro metadati (id, name, logo, modelli disponibili)\n4. Implementare layout responsive con tab orizzontali su desktop e verticali su mobile\n5. Aggiungere breadcrumb navigation: Settings > LLM Providers\n6. Configurare SvelteKit routing con hash-based navigation per Electron compatibility",
            "status": "done",
            "testStrategy": "Verificare che la route sia accessibile, che i tab cambino correttamente e che il layout sia responsive.",
            "parentId": "undefined",
            "updatedAt": "2026-01-10T10:10:25.272Z"
          },
          {
            "id": 2,
            "title": "Implementazione Componente LLMProviderCard.svelte",
            "description": "Sviluppare il componente riutilizzabile per la configurazione di ogni singolo provider LLM con form, validazione e indicatore stato connessione.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `src/lib/components/custom/LLMProviderCard.svelte` con Card shadcn-svelte\n2. Implementare form con Input per API key (tipo password con toggle visibilità)\n3. Creare Select/Dropdown per selezione modello dal provider\n4. Aggiungere stati visivi per connectionStatus: idle, testing, success, error con icone appropriate\n5. Implementare validazione form: API key required, formato minimo caratteri\n6. Usare Svelte 5 runes ($state, $derived) per gestione stato locale\n7. Aggiungere skeleton loading durante operazioni async",
            "status": "done",
            "testStrategy": "Test unitari per validazione form, test rendering degli stati connessione, test toggle visibilità password.",
            "parentId": "undefined",
            "updatedAt": "2026-01-10T10:10:25.305Z"
          },
          {
            "id": 3,
            "title": "Creazione Store llm-providers.svelte.ts con Svelte 5 Runes",
            "description": "Implementare lo store globale per la gestione dello stato dei provider LLM utilizzando Svelte 5 runes per reattività e persistenza.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `src/lib/stores/llm-providers.svelte.ts`\n2. Definire interfacce TypeScript: LLMProvider, LLMProviderState, ModelRole\n3. Implementare stato con $state rune per: providers[], selectedModels, connectionStatuses\n4. Creare $derived per computed properties: hasValidMainProvider, configuredProviders\n5. Implementare funzioni per update stato: setApiKey, setModel, updateConnectionStatus\n6. Aggiungere persistenza preferenze modello per ruolo (main, fallback, research)\n7. Creare funzione initFromStorage per caricare configurazione salvata all'avvio",
            "status": "done",
            "testStrategy": "Test unitari per tutte le funzioni dello store, test reattività con mock data, test persistenza.",
            "parentId": "undefined",
            "updatedAt": "2026-01-10T10:10:25.316Z"
          },
          {
            "id": 4,
            "title": "Implementazione IPC Handlers per Test Connessione Multi-Provider",
            "description": "Creare gli handler IPC nel main process Electron per testare la connessione ai diversi provider LLM (Anthropic, OpenAI, Google, Perplexity).",
            "dependencies": [
              2,
              3
            ],
            "details": "1. Estendere `electron/main.ts` con ipcMain.handle per 'llm:test-connection'\n2. Creare `electron/services/llm-connector.ts` con classe LLMConnector\n3. Implementare metodi specifici per ogni provider:\n   - testAnthropicConnection(apiKey, model) - POST a api.anthropic.com/v1/messages\n   - testOpenAIConnection(apiKey, model) - POST a api.openai.com/v1/chat/completions\n   - testGoogleConnection(apiKey, model) - POST a generativelanguage.googleapis.com\n   - testPerplexityConnection(apiKey, model) - POST a api.perplexity.ai\n4. Gestire timeout (10s) e error handling specifico per ogni provider\n5. Esporre via preload.ts: window.electronAPI.testLLMConnection()",
            "status": "done",
            "testStrategy": "Test con mock HTTP responses, test timeout handling, test error codes specifici per provider.",
            "parentId": "undefined",
            "updatedAt": "2026-01-10T10:10:25.321Z"
          },
          {
            "id": 5,
            "title": "Integrazione Keychain e Configurazione Ruoli Modello",
            "description": "Collegare il sistema keychain per salvataggio sicuro delle API keys e implementare la configurazione dei ruoli modello (main, fallback, research).",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "1. Creare `src/lib/services/llm-config.ts` per interazione con IPC\n2. Implementare funzioni:\n   - saveProviderCredentials(providerId, apiKey) - salva in keychain via IPC\n   - loadProviderCredentials(providerId) - recupera da keychain\n   - deleteProviderCredentials(providerId) - rimuove da keychain\n3. Creare UI per assegnazione ruoli: main (uso primario), fallback (backup), research (Perplexity)\n4. Implementare Select component per scegliere quale provider usare per ogni ruolo\n5. Salvare configurazione ruoli in electron-store (non sensibile)\n6. Aggiungere validazione: almeno un provider main configurato prima di procedere\n7. Creare Toast notifications per feedback operazioni (save success/error)",
            "status": "done",
            "testStrategy": "Test E2E flusso completo: inserimento key -> test connessione -> salvataggio keychain -> assegnazione ruolo.",
            "parentId": "undefined",
            "updatedAt": "2026-01-10T10:10:25.325Z"
          }
        ],
        "tags": [
          "frontend",
          "ai-config",
          "phase-1-config",
          "svelte"
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Creazione route settings/llm-providers con layout tab, 2) Implementazione componente LLMProviderCard.svelte con form validazione e stato connessione, 3) Creazione store llm-providers.svelte.ts con Svelte 5 runes per stato globale, 4) Implementazione IPC handlers per test connessione multi-provider (Anthropic, OpenAI, Google, Perplexity), 5) Integrazione con keychain per salvataggio sicuro API keys e configurazione ruoli modello (main, fallback, research)",
        "updatedAt": "2026-01-10T10:10:25.325Z"
      },
      {
        "id": 4,
        "title": "Python Sidecar con FastAPI e Lifecycle Management",
        "description": "Implementare il sistema di sidecar Python con FastAPI che ospiterà il Cagent engine, includendo gestione del ciclo di vita del processo dal main Electron.",
        "details": "1. Creare struttura `python/`:\n   - `python/main.py` - FastAPI server con SSE support\n   - `python/requirements.txt` - dipendenze (fastapi, uvicorn, sse-starlette, cagent)\n   - `python/agents/` - implementazioni agenti\n   - `python/tools/` - wrapper MCP tools\n2. Implementare FastAPI server:\n```python\nfrom fastapi import FastAPI, Request\nfrom sse_starlette.sse import EventSourceResponse\nimport asyncio\n\napp = FastAPI()\n\n@app.get(\"/health\")\nasync def health():\n    return {\"status\": \"ok\"}\n\n@app.post(\"/agent/execute\")\nasync def execute_agent(request: Request):\n    data = await request.json()\n    # Esegui agente con Cagent\n    return {\"result\": \"...\"}\n\n@app.get(\"/agent/stream\")\nasync def stream_events(request: Request):\n    async def event_generator():\n        while True:\n            yield {\"data\": \"...\"}\n            await asyncio.sleep(0.1)\n    return EventSourceResponse(event_generator())\n```\n3. Creare `electron/sidecar-manager.ts`:\n   - spawn processo Python con uvicorn\n   - health check polling\n   - graceful shutdown su app quit\n   - restart automatico su crash\n4. Bundling: includere Python embedded o usare pyinstaller per distribuzione\n5. Creare `src/lib/services/cagent-client.ts` per HTTP client verso sidecar",
        "testStrategy": "Test unitari per FastAPI endpoints. Test di integrazione per verificare spawn/shutdown del sidecar. Test health check polling. Test SSE streaming.",
        "priority": "high",
        "dependencies": [
          "2"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Creazione struttura directory python/ con requirements.txt",
            "description": "Creare la struttura completa della directory python/ con tutti i file e sottocartelle necessarie per il sidecar FastAPI, incluso requirements.txt con tutte le dipendenze.",
            "dependencies": [],
            "details": "Creare la seguente struttura:\n- `python/main.py` - entry point vuoto iniziale\n- `python/requirements.txt` con dipendenze: fastapi>=0.104.0, uvicorn[standard]>=0.24.0, sse-starlette>=1.8.0, pydantic>=2.5.0, python-dotenv>=1.0.0\n- `python/agents/__init__.py` - package per implementazioni agenti\n- `python/tools/__init__.py` - package per wrapper MCP tools\n- `python/config.py` - configurazione server (host, port, log level)\n- `python/.gitignore` per __pycache__, .venv, *.pyc\n\nAggiungere commenti placeholder che indicano dove verranno implementate le funzionalità successive.",
            "status": "done",
            "testStrategy": "Verificare che tutti i file e directory esistano. Eseguire `pip install -r requirements.txt` in un virtualenv per validare le dipendenze. Verificare che la struttura sia importabile con `python -c 'import python.agents; import python.tools'`.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.194Z"
          },
          {
            "id": 2,
            "title": "Implementazione FastAPI server con endpoint health e execute",
            "description": "Implementare il server FastAPI base in main.py con gli endpoint /health per monitoring e /agent/execute per esecuzione sincrona degli agenti.",
            "dependencies": [
              1
            ],
            "details": "Implementare in `python/main.py`:\n```python\nfrom fastapi import FastAPI, Request, HTTPException\nfrom pydantic import BaseModel\nimport logging\n\napp = FastAPI(title='Cagent Sidecar', version='1.0.0')\nlogger = logging.getLogger(__name__)\n\nclass AgentRequest(BaseModel):\n    agent_id: str\n    input: dict\n    context: dict | None = None\n\nclass AgentResponse(BaseModel):\n    result: dict\n    execution_time: float\n    agent_id: str\n\n@app.get('/health')\nasync def health():\n    return {'status': 'ok', 'version': '1.0.0'}\n\n@app.post('/agent/execute', response_model=AgentResponse)\nasync def execute_agent(request: AgentRequest):\n    # Placeholder per integrazione Cagent\n    pass\n```\nAggiungere middleware per logging request/response e CORS per comunicazione con Electron.",
            "status": "done",
            "testStrategy": "Test unitari con pytest e httpx.AsyncClient per entrambi gli endpoint. Verificare che /health restituisca 200 con payload corretto. Verificare validazione Pydantic su /agent/execute con input malformati. Test timeout handling.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.198Z"
          },
          {
            "id": 3,
            "title": "Implementazione SSE streaming per eventi agenti",
            "description": "Aggiungere endpoint SSE (Server-Sent Events) per streaming real-time degli eventi durante l'esecuzione degli agenti verso il frontend Electron.",
            "dependencies": [
              2
            ],
            "details": "Implementare in `python/main.py`:\n```python\nfrom sse_starlette.sse import EventSourceResponse\nimport asyncio\nfrom typing import AsyncGenerator\n\nclass StreamEvent(BaseModel):\n    event_type: str  # 'thinking', 'tool_call', 'result', 'error'\n    data: dict\n    timestamp: float\n\nasync def agent_event_generator(agent_id: str, request_id: str) -> AsyncGenerator:\n    # Queue per eventi dall'agente\n    event_queue = asyncio.Queue()\n    try:\n        while True:\n            event = await asyncio.wait_for(event_queue.get(), timeout=30.0)\n            yield {'event': event.event_type, 'data': event.json()}\n            if event.event_type in ('result', 'error'):\n                break\n    except asyncio.TimeoutError:\n        yield {'event': 'keepalive', 'data': '{}'}\n\n@app.get('/agent/stream/{request_id}')\nasync def stream_events(request_id: str, request: Request):\n    return EventSourceResponse(agent_event_generator(request_id))\n```\nGestire disconnessione client e cleanup risorse.",
            "status": "done",
            "testStrategy": "Test SSE connection con httpx-sse. Verificare che gli eventi vengano ricevuti nell'ordine corretto. Test disconnessione prematura del client. Test keepalive per connessioni idle. Verificare cleanup risorse post-stream.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.202Z"
          },
          {
            "id": 4,
            "title": "Creazione sidecar-manager.ts in Electron per spawn/kill processo Python",
            "description": "Implementare il modulo TypeScript in Electron che gestisce lo spawn del processo Python uvicorn e la terminazione controllata del sidecar.",
            "dependencies": [
              1
            ],
            "details": "Creare `electron/sidecar-manager.ts`:\n```typescript\nimport { spawn, ChildProcess } from 'child_process';\nimport path from 'path';\nimport { app } from 'electron';\n\nexport class SidecarManager {\n  private process: ChildProcess | null = null;\n  private readonly port: number = 8765;\n  private readonly host: string = '127.0.0.1';\n\n  async start(): Promise<void> {\n    const pythonPath = this.getPythonPath();\n    const scriptPath = path.join(app.getAppPath(), 'python', 'main.py');\n    \n    this.process = spawn(pythonPath, [\n      '-m', 'uvicorn',\n      'main:app',\n      '--host', this.host,\n      '--port', String(this.port)\n    ], { cwd: path.dirname(scriptPath) });\n    \n    this.setupEventHandlers();\n  }\n\n  async stop(): Promise<void> {\n    // SIGTERM con timeout, poi SIGKILL\n  }\n\n  getBaseUrl(): string {\n    return `http://${this.host}:${this.port}`;\n  }\n}\n```\nGestire stdout/stderr logging e rilevamento errori startup.",
            "status": "done",
            "testStrategy": "Test spawn processo con mock child_process. Verificare che il processo venga avviato con argomenti corretti. Test stop() con verifica SIGTERM inviato. Test gestione errori se Python non trovato. Integration test con processo Python reale.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.206Z"
          },
          {
            "id": 5,
            "title": "Implementazione health check polling con auto-restart e backoff esponenziale",
            "description": "Aggiungere sistema di health check polling al SidecarManager con logica di auto-restart in caso di crash e backoff esponenziale per evitare restart loop.",
            "dependencies": [
              4
            ],
            "details": "Estendere `electron/sidecar-manager.ts`:\n```typescript\ninterface HealthCheckConfig {\n  interval: number;        // 5000ms default\n  timeout: number;         // 2000ms default  \n  maxRetries: number;      // 3 prima di restart\n  maxRestarts: number;     // 5 prima di circuit breaker\n  backoffMultiplier: number; // 2.0\n  maxBackoff: number;      // 60000ms\n}\n\nclass SidecarManager {\n  private healthCheckTimer: NodeJS.Timer | null = null;\n  private restartCount: number = 0;\n  private currentBackoff: number = 1000;\n\n  private async checkHealth(): Promise<boolean> {\n    try {\n      const response = await fetch(`${this.getBaseUrl()}/health`, {\n        signal: AbortSignal.timeout(this.config.timeout)\n      });\n      return response.ok;\n    } catch {\n      return false;\n    }\n  }\n\n  private async handleUnhealthy(): Promise<void> {\n    if (this.restartCount >= this.config.maxRestarts) {\n      this.emit('circuit-breaker-open');\n      return;\n    }\n    await this.restart();\n    this.currentBackoff = Math.min(\n      this.currentBackoff * this.config.backoffMultiplier,\n      this.config.maxBackoff\n    );\n  }\n}\n```\nEmettere eventi per UI feedback sullo stato del sidecar.",
            "status": "done",
            "testStrategy": "Test health check con mock fetch. Test backoff esponenziale verificando timing tra restart. Test circuit breaker dopo maxRestarts. Test reset contatori dopo periodo stabile. Test eventi emessi per ogni stato.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.210Z"
          },
          {
            "id": 6,
            "title": "Gestione graceful shutdown su app quit con timeout e SIGTERM/SIGKILL",
            "description": "Implementare la logica di shutdown graceful del sidecar Python quando l'app Electron viene chiusa, con escalation da SIGTERM a SIGKILL dopo timeout.",
            "dependencies": [
              5
            ],
            "details": "Estendere `electron/sidecar-manager.ts` e integrare con lifecycle Electron:\n```typescript\nimport { app } from 'electron';\n\nclass SidecarManager {\n  private readonly shutdownTimeout: number = 5000;\n\n  registerShutdownHandlers(): void {\n    app.on('before-quit', async (event) => {\n      if (this.process) {\n        event.preventDefault();\n        await this.gracefulShutdown();\n        app.quit();\n      }\n    });\n\n    process.on('SIGINT', () => this.gracefulShutdown());\n    process.on('SIGTERM', () => this.gracefulShutdown());\n  }\n\n  private async gracefulShutdown(): Promise<void> {\n    if (!this.process) return;\n    \n    this.stopHealthCheck();\n    \n    // Notifica sidecar di shutdown\n    try {\n      await fetch(`${this.getBaseUrl()}/shutdown`, { method: 'POST' });\n    } catch {}\n\n    // SIGTERM\n    this.process.kill('SIGTERM');\n    \n    // Attendi o forza SIGKILL\n    const killed = await this.waitForExit(this.shutdownTimeout);\n    if (!killed) {\n      this.process.kill('SIGKILL');\n    }\n  }\n}\n```\nAggiungere endpoint /shutdown in FastAPI per cleanup risorse Python.",
            "status": "done",
            "testStrategy": "Test SIGTERM inviato come primo segnale. Test escalation a SIGKILL dopo timeout. Test che app.quit() venga chiamato dopo shutdown. Test cleanup risorse Python verificando log. Integration test shutdown completo con processo reale.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.214Z"
          },
          {
            "id": 7,
            "title": "Bundling strategy con PyInstaller per distribuzione cross-platform",
            "description": "Configurare PyInstaller per creare un eseguibile standalone del sidecar Python che può essere distribuito insieme all'app Electron su Windows, macOS e Linux.",
            "dependencies": [
              6
            ],
            "details": "Creare `python/build/` con configurazione PyInstaller:\n1. `python/pyinstaller.spec`:\n```python\na = Analysis(\n    ['main.py'],\n    pathex=[],\n    binaries=[],\n    datas=[('agents', 'agents'), ('tools', 'tools')],\n    hiddenimports=['uvicorn.logging', 'uvicorn.protocols.http'],\n    hookspath=[],\n    noarchive=False,\n)\npyz = PYZ(a.pure)\nexe = EXE(\n    pyz, a.scripts, a.binaries, a.datas,\n    name='cagent-sidecar',\n    console=False,\n    onefile=True\n)\n```\n2. Script `scripts/build-sidecar.sh`:\n```bash\n#!/bin/bash\npyinstaller --clean --noconfirm python/pyinstaller.spec\ncp dist/cagent-sidecar resources/sidecar/\n```\n3. Modificare `SidecarManager.getPythonPath()` per usare eseguibile bundled in produzione:\n```typescript\ngetSidecarPath(): string {\n  if (app.isPackaged) {\n    return path.join(process.resourcesPath, 'sidecar', 'cagent-sidecar');\n  }\n  return 'python3'; // Dev mode\n}\n```\n4. Aggiornare electron-builder config per includere sidecar negli extraResources.",
            "status": "done",
            "testStrategy": "Build PyInstaller su CI per ogni piattaforma. Verificare che l'eseguibile si avvii correttamente standalone. Test dimensione bundle < 100MB. Test che health check funzioni con sidecar bundled. Integration test completo dell'app packaged.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.218Z"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "phase-2-core",
          "python",
          "fastapi"
        ],
        "complexity": 8,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Espandi in subtask: 1) Creazione struttura directory python/ con requirements.txt, 2) Implementazione FastAPI server con endpoint health e execute, 3) Implementazione SSE streaming per eventi agenti, 4) Creazione sidecar-manager.ts in Electron per spawn/kill processo Python, 5) Implementazione health check polling con auto-restart e backoff esponenziale, 6) Gestione graceful shutdown su app quit con timeout e SIGTERM/SIGKILL, 7) Bundling strategy con PyInstaller per distribuzione cross-platform",
        "updatedAt": "2026-02-04T02:27:18.218Z"
      },
      {
        "id": 5,
        "title": "Generazione Dinamica cagent.yaml e Configurazione Agenti",
        "description": "Implementare il sistema che genera dinamicamente python/team.yaml con 7 agenti specializzati (Orchestrator, Extraction, Creative Planner, Creative Worker, Captioning, Scheduling, IDEA-VALIDATOR), MCP tools ufficiali (Perplexity, Firecrawl, Jina, Cloudinary, Shotstack), e RAG condivisa.",
        "details": "Vedere specifiche complete in: .taskmaster/docs/task-5-upgrade-spec.md\n\nImplementazione completata:\n- ✅ 7 agenti in python/team.yaml (non file .ts separati)\n- ✅ TypeScript generator (src/lib/services/cagent-generator.ts) genera team.yaml\n- ✅ UI settings (src/routes/settings/agents/+page.svelte) per configurare 7 agenti\n- ✅ MCP tools verificati: Perplexity, Firecrawl, Jina, Cloudinary, Shotstack\n- ✅ RAG: brand_guidelines, platform_specs, competitors, mcp_tools_knowledge\n- ✅ System prompts modulari con add_prompt_files (non instruction_file)\n- ✅ IPC handlers per scrittura YAML e hot-reload sidecar\n\nArchitettura:\n- Orchestrator coordina i 6 sub-agents\n- Creative Planner (Sonnet) pianifica → Creative Worker (Haiku) esegue\n- IDEA-VALIDATOR valida contenuti e ricerca trend\n- Tutti gli agenti condividono RAG knowledge bases\n",
        "testStrategy": "Test unitari per generazione YAML corretta. Test di validazione configurazione. Test che il sidecar riceva correttamente le notifiche di reload.",
        "priority": "high",
        "dependencies": [
          "3",
          "4"
        ],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Definizione TypeScript Interfaces per CagentConfig e 7-Agent Team",
            "description": "Creare le interfacce TypeScript complete per la configurazione team.yaml con 7 agenti specializzati, includendo AgentRole, CagentConfig, RAGConfig e MCPConfig.",
            "dependencies": [],
            "details": "Creare il file `src/lib/types/cagent.ts` con le seguenti interfacce: 1) `AgentRole` con proprietà name, model, provider, systemPrompt e tools (array di stringhe), 2) `RAGConfig` con vectorStore e embeddingModel, 3) `MCPConfig` con array servers, 4) `CagentConfig` con version, array agents di tipo AgentRole[], rag di tipo RAGConfig e mcp di tipo MCPConfig. Aggiungere type guards per validazione runtime: `isAgentRole()`, `isCagentConfig()`. Definire costanti per i ruoli predefiniti: ORCHESTRATOR, EXTRACTION, EDITING, CAPTIONING, SCHEDULING. Creare tipi utility come `PartialAgentRole` per update parziali. Esportare tutto dal barrel file `src/lib/types/index.ts`.",
            "status": "done",
            "testStrategy": "Test unitari per type guards con casi validi e invalidi. Verificare che i tipi siano esportati correttamente e utilizzabili in altri moduli. Test di compilazione TypeScript per verificare correttezza tipi. Testare che PartialAgentRole permetta update parziali corretti.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.223Z"
          },
          {
            "id": 2,
            "title": "Creazione cagent-generator.ts per Generazione team.yaml Dinamica",
            "description": "Implementare il servizio principale in src/lib/services/cagent-generator.ts per la generazione del file YAML team.yaml con 7 agenti, serializzazione YAML, e template di default.",
            "dependencies": [
              1
            ],
            "details": "Installare dipendenza `js-yaml` e relativi types `@types/js-yaml`. Creare `src/lib/services/cagent-config.ts` con: 1) Funzione `generateCagentYaml(config: CagentConfig): string` che serializza la configurazione in formato YAML, 2) Funzione `parseCagentYaml(yaml: string): CagentConfig` per il parsing inverso, 3) Funzione `getDefaultConfig(): CagentConfig` che ritorna la configurazione di default con tutti e 5 i ruoli agente preconfigurati, 4) Funzione `mergeWithDefaults(partial: Partial<CagentConfig>): CagentConfig` per merge intelligente, 5) Funzione `validateConfig(config: unknown): ValidationResult` per validazione schema. Creare template YAML di default in `resources/cagent-template.yaml` come riferimento. Gestire edge cases: config vuota, valori mancanti, tipi incorretti.",
            "status": "done",
            "testStrategy": "Test unitari per generateCagentYaml con varie configurazioni. Test round-trip YAML->Config->YAML per verificare integrità dati. Test merge con defaults. Test gestione casi limite (config vuota, valori mancanti). Test parsing YAML malformato.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.227Z"
          },
          {
            "id": 3,
            "title": "Implementazione UI Settings/Agents per Configurazione 7 Agenti",
            "description": "Creare l'interfaccia utente Svelte in src/routes/settings/agents/+page.svelte per la configurazione dei 7 agenti, permettendo di assegnare modelli LLM a ruoli e modificare system prompts.",
            "dependencies": [
              1,
              2
            ],
            "details": "Creare la struttura directory `src/routes/settings/agents/` con +page.svelte e +page.ts. Implementare UI con: 1) Lista dei 5 ruoli agente (Orchestrator, Extraction, Editing, Captioning, Scheduling) con card espandibili, 2) Select dropdown per assegnare provider e modello a ciascun ruolo (popolato da Task 3 - config providers), 3) Textarea per modificare system prompt di ogni agente con preview markdown, 4) Checkbox list per tools abilitati per ogni agente, 5) Pulsante 'Salva Configurazione' che chiama l'IPC handler, 6) Pulsante 'Ripristina Default' per reset. Utilizzare Svelte store per stato locale. Implementare validazione form con feedback visivo. Aggiungere skeleton loading mentre si caricano i dati. Integrare con il layout settings esistente aggiungendo link nella sidebar.",
            "status": "done",
            "testStrategy": "Test componenti con Svelte Testing Library. Test interazioni utente (selezione modelli, modifica prompts, toggle tools). Test validazione form con casi validi e invalidi. Test integrazione con store. Screenshot testing per UI consistency.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.230Z"
          },
          {
            "id": 4,
            "title": "IPC Handler per Scrittura team.yaml e Validazione Schema",
            "description": "Implementare gli handler IPC Electron per scrivere il file team.yaml nel filesystem con validazione schema JSON/YAML completa e gestione errori.",
            "dependencies": [
              2
            ],
            "details": "Nel processo main Electron creare handler IPC in `src-electron/ipc/cagent-handlers.ts`: 1) `cagent:save-config` - riceve CagentConfig, valida con JSON Schema, genera YAML, scrive su disco in `~/.trae-extractor/cagent.yaml`, 2) `cagent:load-config` - legge file YAML esistente e ritorna CagentConfig, 3) `cagent:validate-config` - valida configurazione senza salvare, 4) `cagent:get-config-path` - ritorna path del file config. Implementare backup automatico prima di ogni scrittura (cagent.yaml.bak). Gestire errori: permessi insufficienti, disco pieno, file locked. Creare JSON Schema per validazione in `resources/cagent-schema.json`. Registrare handlers in main.ts. Creare preload bridge per esporre funzioni al renderer process.",
            "status": "done",
            "testStrategy": "Test unitari per validazione schema con casi validi e invalidi. Test scrittura/lettura filesystem con mock fs. Test gestione errori (permessi, disco pieno, file corrotto). Test backup automatico funzionante. Test integrazione IPC end-to-end.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.234Z"
          },
          {
            "id": 5,
            "title": "Implementazione Hot-Reload Notifica al Sidecar Python",
            "description": "Implementare il meccanismo di notifica al sidecar Python quando la configurazione team.yaml viene modificata dall'UI, permettendo il reload dinamico senza riavvio.",
            "dependencies": [
              4
            ],
            "details": "Estendere la comunicazione con il sidecar Python (da Task 4) per supportare hot-reload: 1) Nel sidecar FastAPI aggiungere endpoint `POST /config/reload` che ricarica cagent.yaml e reinizializza gli agenti, 2) Nel frontend implementare chiamata HTTP all'endpoint reload dopo salvataggio config riuscito, 3) Implementare retry logic con backoff esponenziale se il sidecar non risponde (max 3 tentativi), 4) Mostrare toast notification in UI con stato reload (successo/fallimento), 5) Aggiungere file watcher opzionale in Python per rilevare modifiche esterne al file, 6) Implementare WebSocket channel `/ws/config-events` per notifiche bidirezionali real-time tra Electron e sidecar. Gestire graceful degradation: se reload fallisce, mantenere configurazione precedente e notificare utente.",
            "status": "done",
            "testStrategy": "Test comunicazione HTTP con mock sidecar per endpoint reload. Test timeout e retry logic con simulazione fallimenti. Test file watcher con modifiche filesystem simulate. Test E2E completo: modifica UI -> salvataggio -> notifica -> reload Python -> conferma successo.",
            "parentId": "undefined",
            "updatedAt": "2026-02-04T02:27:18.238Z"
          }
        ],
        "tags": [
          "python-backend",
          "ai-config",
          "phase-1-config",
          "python",
          "cagent"
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Definizione TypeScript interfaces per CagentConfig e AgentRole, 2) Creazione cagent-config.ts con funzione generateCagentYaml e serializzazione YAML, 3) Implementazione UI Settings/Agents per configurazione ruoli e system prompts, 4) IPC handler per scrittura file YAML con validazione schema, 5) Implementazione hot-reload notifica al sidecar Python quando config cambia",
        "updatedAt": "2026-02-04T02:27:18.238Z"
      },
      {
        "id": 6,
        "title": "osxphotos Sandboxed Process + Agent Extraction Integration",
        "description": "Implementare stack estrazione foto sicuro: processo Python isolato (sandboxed) per osxphotos, bridge IPC Electron, supervisione lifecycle lato main process e integrazione Cagent agent 'extraction'. Comunica con FastAPI sidecar via Unix socket (JSON-RPC 2.0). Include auto-grouping temporale: se gap > 6min tra asset → crea nuova folder \"momento\".",
        "status": "pending",
        "dependencies": [
          "4",
          "20"
        ],
        "priority": "high",
        "details": "Super Task (unificazione ex-task 6 + 15). Architettura a 5 layer:\n\n┌─────────────────────────────────────────────────────────────┐\n│  LAYER 1 – INFRA SANDBOXED  (python/sandboxed/)            │\n│  ├─ server.py           # Unix socket JSON-RPC 2.0 server  │\n│  ├─ jsonrpc_handler.py  # Dispatcher metodi                │\n│  ├─ network_lock.py     # monkey-patch socket per blocco   │\n│  └─ path_whitelist.py   # Validazione ~/Exports only       │\n└─────────────────────────────────────────────────────────────┘\n         ↕ Unix Socket (/tmp/trae-osxphotos.sock)\n┌─────────────────────────────────────────────────────────────┐\n│  LAYER 2 – LOGICA ESTRAZIONE                               │\n│  python/sandboxed/\n│  ├─ photos_service.py   # Wrapper osxphotos                │\n│  │   (list_albums, get_photos, export_photo, get_metadata)  │\n│  └─ temporal_grouping.py # Auto-grouping 6min gap logic    │\n└─────────────────────────────────────────────────────────────┘\n         ↕ IPC Bridge (Electron ↔ Python)\n┌─────────────────────────────────────────────────────────────┐\n│  LAYER 3 – ELECTRON SUPERVISOR                             │\n│  electron/osxphotos-supervisor.ts                          │\n│  ├─ Lifecycle processo (spawn, kill, restart)              │\n│  ├─ Circuit Breaker (stop dopo 3 crash in 5 min)          │\n│  ├─ IPC Bridge: channels osxphotos:*                      │\n│  └─ Integrazione con SidecarManager esistente             │\n│      (electron/sidecar-manager.ts pattern di riferimento)  │\n└─────────────────────────────────────────────────────────────┘\n         ↕ Agent Tool\n┌─────────────────────────────────────────────────────────────┐\n│  LAYER 4 – AGENT INTEGRATION                               │\n│  python/tools/osxphotos_tool.py                            │\n│  ├─ Client Unix socket verso sandboxed process             │\n│  ├─ Metodi: list_albums, extract_photos, extract_by_date   │\n│  └─ Registrazione in python/team.yaml → agente extraction  │\n└─────────────────────────────────────────────────────────────┘\n         ↕ UI\n┌─────────────────────────────────────────────────────────────┐\n│  LAYER 5 – UI                                              │\n│  src/routes/extract/+page.svelte                           │\n│  ├─ Tab: Upload (esistente) | Photos Library (NUOVO)      │\n│  ├─ Album browser tree view                               │\n│  ├─ Date picker per estrazione giornaliera                │\n│  ├─ Toggle \"Auto-group per momenti\" (default ON)          │\n│  ├─ Preview griglia foto                                  │\n│  └─ SSE progress bar durante estrazione                   │\n└─────────────────────────────────────────────────────────────┘\n\nFILE ESISTENTI DA MODIFICARE/ESTENDERE:\n- electron/sidecar-manager.ts → pattern di riferimento per supervisor (Circuit Breaker, health check, exponential backoff già implementati)\n- electron/ipc-handlers.ts → aggiungere registerOsxphotosHandlers()\n- electron/preload.ts → aggiungere osxphotosApi nel desktopApi\n- shared/ipc-channels.ts → aggiungere OsxphotosChannels\n- src/app.d.ts → estendere ElectronAPI con sezione osxphotos\n- python/main.py → aggiungere proxy endpoint /agent/extract che forwarda a Unix socket\n- src/routes/extract/+page.svelte → ristrutturare con tabs Upload/Photos Library\n\nFILE NUOVI DA CREARE:\n- python/sandboxed/server.py\n- python/sandboxed/jsonrpc_handler.py\n- python/sandboxed/network_lock.py\n- python/sandboxed/path_whitelist.py\n- python/sandboxed/photos_service.py\n- python/sandboxed/temporal_grouping.py\n- python/sandboxed/requirements.txt (osxphotos>=0.68.0)\n- python/tools/osxphotos_tool.py\n- electron/osxphotos-supervisor.ts\n\nSICUREZZA:\n- monkey-patch socket.socket per impedire connessioni di rete dal processo sandboxed\n- Read-only su Photos Library\n- Write SOLO su whitelist: ~/Exports/, ~/Documents/TraeExports/\n- Path validation: reject '..', symlinks non risolti, null bytes (pattern da ipc-handlers.ts:42-72)\n- Circuit Breaker: max 3 restart in 5 min (pattern da sidecar-manager.ts:337-346)",
        "testStrategy": "## Unit Tests\n\n1. Test `list_albums` con mock osxphotos.PhotosDB\n2. Test PermissionError handling per Full Disk Access\n3. Test `export_photo` con mock photo objects e EXIF preservation\n4. Test validazione destination path (no path traversal) in path_whitelist.py\n5. Test network_lock.py blocca connessioni socket\n6. Test temporal_grouping.py: gap > 6min crea nuova folder\n7. Test temporal_grouping.py: asset nello stesso momento restano nella stessa folder\n8. Test osxphotos_tool.py client socket con mock server\n\n## Integration Tests\n\n1. Test JSON-RPC round-trip: client → Unix socket → server → response\n2. Test Circuit Breaker in osxphotos-supervisor.ts (simulare 3 crash)\n3. Test IPC Bridge: renderer → preload → main → supervisor → sandboxed process\n4. Test che il tool osxphotos sia registrato in team.yaml e visibile dall'agente extraction\n5. Test proxy endpoint /agent/extract in python/main.py\n\n## UI Tests\n\n1. Test rendering tabs Upload/Photos Library in src/routes/extract/+page.svelte\n2. Test toggle Auto-group attivo/disattivo\n3. Test album browser tree view con mock data\n4. Test SSE progress bar durante estrazione simulata\n5. Test selezione multipla in griglia foto",
        "subtasks": [
          {
            "id": 1,
            "title": "INFRA SANDBOXED: Unix Socket Server + JSON-RPC + Security Lock",
            "description": "Creare python/sandboxed/ con Unix socket JSON-RPC 2.0 server, dispatcher metodi, monkey-patch socket per blocco rete e path whitelist per ~/Exports.",
            "dependencies": [],
            "details": "Creare la directory python/sandboxed/ e i seguenti file:\n\n1. **server.py**: Unix socket server JSON-RPC 2.0 su /tmp/trae-osxphotos.sock\n   - Accettare connessioni su socket Unix\n   - Leggere richieste JSON-RPC, delegare a jsonrpc_handler.py\n   - Gestire graceful shutdown (SIGTERM/SIGINT)\n   - Logging strutturato\n\n2. **jsonrpc_handler.py**: Dispatcher metodi JSON-RPC\n   - Registrare metodi: list_albums, get_photos, export_photo, extract_by_date, get_metadata\n   - Validare parametri con Pydantic\n   - Gestire errori JSON-RPC standard (method not found, invalid params, internal error)\n\n3. **network_lock.py**: Monkey-patch socket al boot del processo\n   - Sovrascrivere socket.socket.__init__ per bloccare AF_INET / AF_INET6\n   - Permettere solo AF_UNIX\n   - Importare prima di qualsiasi altro modulo\n\n4. **path_whitelist.py**: Validazione percorsi di output\n   - Whitelist: ~/Exports/, ~/Documents/TraeExports/\n   - Reject: '..', null bytes, symlink non risolti\n   - Pattern da ipc-handlers.ts:42-72 (validateAndNormalizePath)\n\n5. **requirements.txt**: osxphotos>=0.68.0\n\nRiferimento architettura: il sidecar FastAPI esiste già in python/main.py con pattern simile per health check e SSE streaming.",
            "status": "pending",
            "testStrategy": "Unit test per network_lock.py: verificare che socket.socket(AF_INET) lanci errore. Test path_whitelist.py: percorsi validi e invalidi (traversal, symlink, null bytes). Test server.py: avvio, ricezione JSON-RPC, shutdown. Test jsonrpc_handler.py: dispatch metodi, errori standard.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "LOGICA ESTRAZIONE: PhotosService + Temporal Grouping",
            "description": "Implementare photos_service.py (wrapper osxphotos con list_albums, get_photos, export_photo, get_metadata) e temporal_grouping.py (auto-grouping 6min gap logic).",
            "dependencies": [
              1
            ],
            "details": "Creare in python/sandboxed/:\n\n1. **photos_service.py**: Wrapper su osxphotos library\n   - `list_albums()` → lista album con count, date range\n   - `get_photos(album_uuid)` → lista foto con thumbnail, metadata base\n   - `export_photo(uuid, dest_path)` → export singola foto con EXIF preservato\n   - `extract_by_date(date, auto_group=True)` → export tutte le foto di un giorno\n   - `get_metadata(uuid)` → metadata completo (EXIF, faces, labels, location)\n   - Gestire PermissionError per Full Disk Access mancante\n   - Usare osxphotos.PhotosDB() per accesso alla libreria\n\n2. **temporal_grouping.py**: Logica auto-grouping\n   - Input: lista asset con timestamp, directory di destinazione\n   - Ordinare asset per timestamp\n   - Se gap > 6 minuti tra asset consecutivi → nuova folder 'momento_N'\n   - Output: ~/Exports/YYYY-MM-DD/momento_1/, momento_2/, etc.\n   - Usare path_whitelist.py per validare tutte le directory di output\n\n3. Integrare photos_service con jsonrpc_handler.py registrando i metodi\n\nNOTA: usare osxphotos come library Python, NON come CLI subprocess.",
            "status": "pending",
            "testStrategy": "Test list_albums con mock PhotosDB. Test export_photo con mock photo objects e verifica EXIF preservato. Test PermissionError handling. Test temporal_grouping: gap > 6min crea folder, gap < 6min stessa folder. Test con edge case: 0 foto, 1 foto, foto senza timestamp.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "ELECTRON SUPERVISOR: osxphotos-supervisor.ts + IPC Bridge",
            "description": "Creare electron/osxphotos-supervisor.ts per lifecycle management del processo sandboxed, Circuit Breaker, e IPC bridge con canali osxphotos:*.",
            "dependencies": [
              1
            ],
            "details": "1. **electron/osxphotos-supervisor.ts**: Modellato su sidecar-manager.ts (electron/sidecar-manager.ts)\n   - Spawn processo Python: `python3 python/sandboxed/server.py`\n   - Health check via JSON-RPC ping su Unix socket\n   - Circuit Breaker: max 3 crash in 5 min → stop (pattern da sidecar-manager.ts:337-346)\n   - Exponential backoff su restart (pattern da sidecar-manager.ts:358-361)\n   - Graceful shutdown: SIGTERM → wait 2s → SIGKILL\n   - Emettere eventi a renderer: 'osxphotos:event'\n   - Export singleton: `export const osxphotosSupervisor = new OsxphotosSupervisor()`\n\n2. **shared/ipc-channels.ts**: Aggiungere OsxphotosChannels\n   ```typescript\n   export const OsxphotosChannels = {\n     START: 'osxphotos:start',\n     STOP: 'osxphotos:stop',\n     STATUS: 'osxphotos:status',\n     LIST_ALBUMS: 'osxphotos:list-albums',\n     EXTRACT: 'osxphotos:extract',\n     EXTRACT_BY_DATE: 'osxphotos:extract-by-date',\n     EVENT: 'osxphotos:event',\n   } as const;\n   ```\n\n3. **electron/ipc-handlers.ts**: Aggiungere `registerOsxphotosHandlers()`\n   - Handler per ogni canale OsxphotosChannels\n   - Validazione input (pattern da registerKeychainHandlers)\n   - Chiamare registerOsxphotosHandlers() dentro registerIpcHandlers()\n\n4. **electron/preload.ts**: Aggiungere `osxphotosApi` nel desktopApi\n   - listAlbums, extract, extractByDate, start, stop, status, onEvent\n\n5. **src/app.d.ts**: Estendere ElectronAPI con sezione osxphotos",
            "status": "pending",
            "testStrategy": "Test Circuit Breaker: simulare 3 crash consecutivi → verifica stop. Test IPC round-trip: mock supervisor → handler → preload. Test graceful shutdown. Test che OsxphotosChannels sia registrato in ipc-handlers.ts.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "AGENT INTEGRATION: osxphotos_tool.py + team.yaml Update",
            "description": "Creare python/tools/osxphotos_tool.py come client Unix socket verso il processo sandboxed e aggiornare python/team.yaml per registrarlo nell'agente 'extraction'.",
            "dependencies": [
              1,
              2
            ],
            "details": "1. **python/tools/osxphotos_tool.py**: Client Cagent tool\n   - Classe OsxphotosTool che implementa l'interfaccia tool Cagent\n   - Connessione a Unix socket /tmp/trae-osxphotos.sock\n   - Metodi esposti come tool actions:\n     - `list_albums()` → JSON-RPC call a sandboxed server\n     - `extract_photos(album_uuid, dest)` → forward con progress callback\n     - `extract_by_date(date, auto_group)` → forward con streaming\n     - `get_metadata(uuid)` → forward\n   - Timeout configurabile per ogni call\n   - Retry logic per connessione socket\n\n2. **python/team.yaml** update:\n   - Aggiungere il tool osxphotos nell'agente 'extraction'\n   - NON usare MCP per osxphotos (è processo separato sandboxed)\n   - L'agente extraction invoca il tool che a sua volta parla con il sandboxed process\n\n3. **python/main.py**: Aggiungere proxy endpoint\n   - POST /agent/extract → forward richiesta a Unix socket\n   - GET /agent/extract/stream/{request_id} → SSE streaming progress\n   - Riusare pattern SSE da agent_event_generator() esistente (python/main.py:116-152)\n   - Validazione input + path whitelist enforcement lato API\n\nNOTA: Dipende da Task 20 (Integrazione Runtime Cagent) per il runtime effettivo degli agenti.",
            "status": "pending",
            "testStrategy": "Test osxphotos_tool.py con mock Unix socket server. Test che team.yaml sia valido YAML dopo l'update. Test proxy endpoint /agent/extract con mock sandboxed server. Test SSE streaming progress. Test timeout e retry logic.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "UI: Extract Page con Tabs Upload/Photos Library + Album Browser",
            "description": "Ristrutturare src/routes/extract/+page.svelte con sistema a tabs (Upload esistente | Photos Library nuovo), album browser tree view, date picker, toggle auto-group e SSE progress bar.",
            "dependencies": [
              3
            ],
            "details": "Modificare src/routes/extract/+page.svelte (attualmente ha solo upload area + placeholder cards).\n\n1. **Tabs shadcn**: Upload (contenuto esistente) | Photos Library (nuovo)\n   - Usare componente Tabs da shadcn-svelte (già installato in src/lib/components/ui/tabs/)\n   - Tab Upload: mantenere Card upload + Extraction Options esistenti\n   - Tab Photos Library: nuovo contenuto\n\n2. **Photos Library tab**:\n   - Album Browser: tree view con album gerarchici\n     - Chiamare `window.electronAPI.osxphotos.listAlbums()` via IPC\n     - Mostrare nome album, count foto, date range\n   - Date Picker: componente per selezionare un giorno specifico\n     - Usare shadcn-svelte date picker (installare se necessario)\n   - Toggle \"Auto-group per momenti temporali\" (default ON)\n     - Switch shadcn-svelte\n   - Preview griglia foto (thumbnail grid)\n     - Lazy loading con IntersectionObserver\n   - Progress bar SSE durante estrazione\n     - Connessione SSE a /agent/extract/stream/{id}\n     - Mostrare percentuale, file corrente, tempo stimato\n\n3. **States**: empty, loading, error, success\n   - Empty: istruzioni per abilitare Full Disk Access\n   - Loading: skeleton cards\n   - Error: messaggio con retry\n   - Success: link alla cartella di output\n\n4. **Svelte 5 runes**: usare $state, $derived, $effect\n\nValidare con svelte-autofixer MCP prima di finalizzare.",
            "status": "pending",
            "testStrategy": "Test rendering tabs Upload/Photos Library. Test toggle auto-group stato on/off. Test album browser con mock data (IPC mock). Test progress bar SSE con mock stream. Test empty/loading/error states. Validare con svelte-autofixer.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Setup osxphotos in ambiente Python e test accesso Photos library con gestione permessi macOS Full Disk Access, 2) Implementazione ExtractionAgent class con metodi list_albums e extract_photos, 3) Creazione endpoint FastAPI /agent/extract con progress streaming SSE, 4) UI extract page con album browser tree view, 5) Implementazione griglia preview con selezione multipla e filtri (data, tipo, persone), 6) Integrazione preservazione EXIF e metadata faces/labels per suggerimenti AI"
      },
      {
        "id": 7,
        "title": "Integrazione Cloudinary MCP per Editing Agent",
        "description": "Implementare l'agente di editing che utilizza i server MCP ufficiali di Cloudinary per trasformazioni media avanzate come background removal, upscale e auto-crop.",
        "details": "1. Configurare Cloudinary MCP in `.mcp.json`:\n```json\n{\n  \"mcpServers\": {\n    \"cloudinary\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@cloudinary/mcp-server\"],\n      \"env\": {\n        \"CLOUDINARY_URL\": \"cloudinary://...\"\n      }\n    }\n  }\n}\n```\n2. Creare `python/agents/editing_agent.py`:\n```python\nfrom cagent import Agent, Tool\n\nclass EditingAgent(Agent):\n    tools = [\n        Tool('cloudinary_upload', 'Carica media su Cloudinary'),\n        Tool('cloudinary_transform', 'Applica trasformazioni'),\n        Tool('cloudinary_remove_bg', 'Rimuovi sfondo'),\n        Tool('cloudinary_upscale', 'Upscale immagine'),\n    ]\n    \n    async def process_media(self, media_path: str, transformations: List[str]):\n        # Esegui trasformazioni via MCP\n        pass\n```\n3. Creare UI in `src/routes/edit/+page.svelte`:\n   - Preview prima/dopo trasformazione\n   - Pannello trasformazioni con preset\n   - Slider per parametri (qualità, dimensioni)\n   - Batch processing per multiple immagini\n4. Implementare cache locale per preview\n5. Gestione quota Cloudinary e fallback",
        "testStrategy": "Test con mock MCP server per Cloudinary. Test UI per selezione trasformazioni. Test batch processing con multiple immagini.",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Configurazione Cloudinary MCP Server in .mcp.json",
            "description": "Aggiungere la configurazione del server MCP Cloudinary al file .mcp.json esistente, includendo il comando npx per il package @cloudinary/mcp-server e le variabili ambiente necessarie per l'autenticazione.",
            "dependencies": [],
            "details": "1. Aprire il file `.mcp.json` esistente che già contiene la configurazione task-master-ai\n2. Aggiungere una nuova entry `cloudinary` nell'oggetto `mcpServers`\n3. Configurare il comando: `\"command\": \"npx\"` con args `[\"-y\", \"@cloudinary/mcp-server\"]`\n4. Aggiungere le variabili ambiente: `CLOUDINARY_URL` (formato cloudinary://API_KEY:API_SECRET@CLOUD_NAME), `CLOUDINARY_CLOUD_NAME`, `CLOUDINARY_API_KEY`, `CLOUDINARY_API_SECRET`\n5. Creare file `.env.example` con placeholder per le credenziali Cloudinary\n6. Documentare nel README come ottenere le credenziali dalla dashboard Cloudinary",
            "status": "pending",
            "testStrategy": "Verificare che il server MCP Cloudinary si avvii correttamente con `npx @cloudinary/mcp-server`. Testare la connessione con credenziali valide. Verificare che non ci siano conflitti con altri server MCP configurati.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implementazione EditingAgent Python con wrapper MCP tools",
            "description": "Creare l'agente Python per l'editing che incapsula le chiamate ai tool MCP di Cloudinary, gestendo upload, trasformazioni, background removal e upscale delle immagini.",
            "dependencies": [
              1
            ],
            "details": "1. Creare la directory `python/agents/` se non esiste\n2. Creare `python/agents/editing_agent.py` con classe `EditingAgent`\n3. Implementare metodi wrapper per tool MCP:\n   - `upload_media(file_path: str) -> str` - Carica su Cloudinary e ritorna public_id\n   - `apply_transform(public_id: str, transformations: dict) -> str` - Applica trasformazioni\n   - `remove_background(public_id: str) -> str` - Rimuovi sfondo con AI\n   - `upscale_image(public_id: str, scale: float) -> str` - Upscale con IA\n   - `auto_crop(public_id: str, aspect_ratio: str) -> str` - Crop intelligente\n4. Implementare gestione errori e retry logic per chiamate MCP\n5. Creare types/models per input/output delle trasformazioni\n6. Aggiungere logging per debug delle operazioni MCP",
            "status": "pending",
            "testStrategy": "Creare mock del server MCP Cloudinary per test unitari. Testare ogni metodo wrapper con mock responses. Testare error handling con simulazione di errori di rete e API.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "UI Edit Page con preview before/after e pannello trasformazioni",
            "description": "Creare la pagina di editing in Svelte con visualizzazione side-by-side prima/dopo le trasformazioni, pannello per selezionare e configurare le trasformazioni disponibili.",
            "dependencies": [
              2
            ],
            "details": "1. Creare `src/routes/edit/+page.svelte` come pagina principale di editing\n2. Implementare componente `BeforeAfterPreview.svelte`:\n   - Layout split-view con slider trascinabile\n   - Immagine originale a sinistra, trasformata a destra\n   - Opzione toggle per view overlay\n3. Creare `TransformationsPanel.svelte` con:\n   - Lista preset trasformazioni (background removal, upscale 2x/4x, auto-crop)\n   - Slider per parametri regolabili (qualità 1-100, dimensioni)\n   - Pulsanti per applicare/annullare trasformazioni\n4. Implementare store Svelte 5 `editing-state.svelte.ts` per:\n   - Immagine corrente e cronologia trasformazioni\n   - Stato loading per ogni operazione\n   - Undo/redo stack\n5. Integrare con EditingAgent tramite IPC per operazioni reali",
            "status": "pending",
            "testStrategy": "Test E2E con Playwright per interazioni UI. Test del componente BeforeAfterPreview con immagini di test. Test dello slider trasformazioni. Test dello store per undo/redo.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implementazione batch processing con progress tracking",
            "description": "Estendere l'UI e l'agent per supportare l'elaborazione batch di multiple immagini con barra di progresso, gestione code e possibilità di annullamento.",
            "dependencies": [
              3
            ],
            "details": "1. Creare componente `BatchProcessor.svelte` con:\n   - Drag-drop zone per upload multiplo\n   - Lista immagini in coda con status individuale\n   - Barra progresso globale e per-immagine\n   - Pulsanti pausa/riprendi/annulla\n2. Implementare `BatchQueue` class in EditingAgent:\n   - Coda FIFO con priorità opzionale\n   - Processamento parallelo configurabile (max concurrent)\n   - Gestione errori senza bloccare la coda\n   - Emit eventi per aggiornamento progress\n3. Creare `batch-progress.svelte.ts` store per:\n   - Tracking stato ogni immagine (pending/processing/done/error)\n   - Percentuale completamento globale\n   - Tempo stimato rimanente\n4. Implementare IPC handlers per streaming progress updates\n5. Salvare risultati batch in directory configurabile",
            "status": "pending",
            "testStrategy": "Test batch con 10+ immagini di varie dimensioni. Test annullamento a metà elaborazione. Test gestione errori per immagini corrotte. Test progress tracking accuracy.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Cache locale preview e gestione quota Cloudinary con fallback",
            "description": "Implementare sistema di cache locale per le preview delle trasformazioni, monitoraggio quota Cloudinary e meccanismo di fallback per quando la quota è esaurita.",
            "dependencies": [
              4
            ],
            "details": "1. Creare `src/lib/services/preview-cache.ts`:\n   - Cache LRU in memoria con limite configurabile\n   - Persistenza su disco per preview già generate\n   - Chiave cache basata su hash immagine + parametri trasformazione\n   - TTL configurabile per invalidazione\n2. Implementare `CloudinaryQuotaManager` in `quota-manager.ts`:\n   - Polling periodico API Cloudinary per usage stats\n   - Threshold warning (80%) e critical (95%)\n   - Emit eventi per notifiche UI\n3. Creare fallback chain:\n   - Primario: Cloudinary cloud\n   - Secondario: Processamento locale con Sharp (npm)\n   - Notifica utente quando in modalità fallback\n4. UI per visualizzare stato quota:\n   - Badge nell'header con % utilizzo\n   - Modal dettagli quota quando cliccato\n5. Configurazione in settings per soglie e comportamento fallback",
            "status": "pending",
            "testStrategy": "Test cache hit/miss con immagini identiche. Test invalidazione cache. Test threshold quota con mock API responses. Test fallback a Sharp quando quota esaurita. Test performance confronto cache vs non-cache.",
            "parentId": "undefined"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "media-processing",
          "phase-3-agents",
          "python",
          "cloudinary"
        ],
        "complexity": 5,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Configurazione Cloudinary MCP Server in .mcp.json con variabili ambiente, 2) Implementazione EditingAgent Python con wrapper MCP tools, 3) UI Edit Page con preview before/after e pannello trasformazioni, 4) Implementazione batch processing con progress tracking, 5) Cache locale preview e gestione quota Cloudinary con fallback"
      },
      {
        "id": 8,
        "title": "Native RAG con SQLite e Captioning Agent",
        "description": "Implementare il sistema RAG nativo di Cagent con storage SQLite locale per knowledge base del brand, e l'agente di captioning che genera descrizioni contestuali.",
        "details": "1. Creare struttura `resources/brand-assets/` per documenti brand\n2. Creare `resources/vector-store/` per SQLite embeddings\n3. Implementare `python/rag/indexer.py`:\n```python\nimport sqlite3\nfrom sentence_transformers import SentenceTransformer\n\nclass BrandKnowledgeBase:\n    def __init__(self, db_path: str):\n        self.db = sqlite3.connect(db_path)\n        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n        self._init_schema()\n    \n    def index_document(self, doc_path: str, doc_type: str):\n        # Estrai testo, genera embeddings, salva in SQLite\n        pass\n    \n    def search(self, query: str, top_k: int = 5) -> List[Dict]:\n        query_embedding = self.model.encode(query)\n        # Ricerca similarità coseno\n        pass\n```\n4. Creare `python/agents/captioning_agent.py`:\n   - Integrazione con RAG per contesto brand\n   - Generazione caption per piattaforma (IG, LinkedIn, Twitter)\n   - Tone of voice personalizzabile\n   - Hashtag suggestions\n5. UI in `src/routes/edit/+page.svelte` sezione captions:\n   - Editor caption con preview per piattaforma\n   - Suggerimenti AI in tempo reale\n   - Storico captions generate",
        "testStrategy": "Test unitari per indexing e search RAG. Test qualità caption generate con metriche. Test integrazione con brand guidelines.",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup SQLite Vector Store e Schema per Embeddings",
            "description": "Creare la struttura delle directory e lo schema del database SQLite per memorizzare gli embeddings vettoriali della knowledge base del brand.",
            "dependencies": [],
            "details": "1. Creare directory `resources/brand-assets/` per documenti brand (PDF, TXT, MD)\n2. Creare directory `resources/vector-store/` per database SQLite\n3. Implementare schema SQLite in `python/rag/schema.py`:\n   - Tabella `documents`: id, path, doc_type, content, created_at, updated_at\n   - Tabella `embeddings`: id, document_id, chunk_text, embedding (BLOB), chunk_index\n   - Tabella `metadata`: key, value per configurazione\n4. Creare script di inizializzazione database con indici per ricerca efficiente\n5. Implementare migration system per futuri aggiornamenti schema",
            "status": "pending",
            "testStrategy": "Test unitari per creazione schema, verifica integrità database, test inserimento e recupero dati base.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implementazione BrandKnowledgeBase con Sentence-Transformers",
            "description": "Sviluppare la classe BrandKnowledgeBase per l'indicizzazione dei documenti brand utilizzando sentence-transformers per la generazione degli embeddings.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `python/rag/indexer.py` con classe BrandKnowledgeBase\n2. Inizializzare SentenceTransformer con modello 'all-MiniLM-L6-v2'\n3. Implementare `index_document()` per:\n   - Leggere documento da path (supporto PDF, TXT, MD)\n   - Chunking intelligente del testo (overlap windows)\n   - Generazione embeddings per ogni chunk\n   - Salvataggio in SQLite con serializzazione numpy\n4. Implementare `index_directory()` per batch indexing\n5. Gestire aggiornamento incrementale documenti esistenti\n6. Logging progressi indicizzazione",
            "status": "pending",
            "testStrategy": "Test indexing con documenti sample di vari formati, verifica embeddings dimensione corretta (384 dim), test persistence nel database.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Creazione Funzione Search con Cosine Similarity",
            "description": "Implementare la funzionalità di ricerca semantica con calcolo della similarità coseno per recuperare i documenti più rilevanti dalla knowledge base.",
            "dependencies": [
              2
            ],
            "details": "1. Implementare metodo `search()` in BrandKnowledgeBase:\n   - Generare embedding della query\n   - Caricare embeddings da SQLite\n   - Calcolare cosine similarity vettoriale\n   - Ordinare risultati per score decrescente\n2. Ottimizzare con numpy vectorization per performance\n3. Implementare caching query frequenti\n4. Aggiungere filtri per doc_type e date range\n5. Restituire top_k risultati con metadata (path, chunk, score)\n6. Implementare threshold minimo di similarità configurabile",
            "status": "pending",
            "testStrategy": "Test ricerca con query note, verifica ranking corretto, benchmark performance con dataset di test, test edge cases (query vuota, nessun match).",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implementazione CaptioningAgent con Integrazione RAG",
            "description": "Sviluppare l'agente di captioning che utilizza il sistema RAG per generare descrizioni contestuali basate sulla knowledge base del brand.",
            "dependencies": [
              3
            ],
            "details": "1. Creare `python/agents/captioning_agent.py` con classe CaptioningAgent\n2. Integrare BrandKnowledgeBase per recupero contesto brand\n3. Implementare `generate_caption()` con parametri:\n   - media_description: descrizione immagine/video\n   - platform: target social platform\n   - tone_of_voice: stile comunicazione\n   - context_query: query per RAG\n4. Costruire prompt dinamico con:\n   - Contesto brand da RAG (top 3 chunks)\n   - Guidelines piattaforma specifica\n   - Tone of voice richiesto\n5. Supportare streaming output per UI realtime\n6. Generare suggerimenti hashtag pertinenti",
            "status": "pending",
            "testStrategy": "Test generazione caption con mock LLM, verifica inclusione contesto brand, test qualità output per diverse piattaforme e tone of voice.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "UI Caption Editor con Preview e Suggestions AI",
            "description": "Creare l'interfaccia utente per l'editing delle caption con preview per piattaforma, suggerimenti AI in tempo reale e storico delle caption generate.",
            "dependencies": [
              4
            ],
            "details": "1. Estendere `src/routes/edit/+page.svelte` con sezione captions\n2. Creare componenti:\n   - CaptionEditor: textarea con character counter per piattaforma\n   - PlatformPreview: mockup visivo post per IG/LinkedIn/Twitter\n   - HashtagSuggestions: chip selezionabili con hashtag suggeriti\n   - CaptionHistory: lista caption precedenti con riutilizzo\n3. Implementare debounced AI suggestions durante typing\n4. Aggiungere indicatori limiti caratteri per piattaforma\n5. Preview responsive che simula aspetto reale del post\n6. Salvataggio bozze automatico in localStorage",
            "status": "pending",
            "testStrategy": "Test componenti UI con testing library, test character counting, test responsive design, test interazione con mock API suggestions.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Supporto Multi-Piattaforma con Tone of Voice Configurabile",
            "description": "Implementare il supporto completo per Instagram, LinkedIn e Twitter con profili tone of voice personalizzabili e ottimizzazioni specifiche per ogni piattaforma.",
            "dependencies": [
              5
            ],
            "details": "1. Creare `src/lib/config/platforms.ts` con configurazioni:\n   - Instagram: 2200 char limit, 30 hashtags, emoji-friendly\n   - LinkedIn: 3000 char limit, professionale, hashtag moderati\n   - Twitter/X: 280 char limit, conciso, 2-3 hashtag\n2. Implementare `src/lib/config/tone-profiles.ts`:\n   - Profili predefiniti: professionale, casual, engaging, informativo\n   - Editor profili custom con sliders (formalità, emoji usage, etc.)\n3. Creare store Svelte per preferenze utente\n4. Adattare CaptioningAgent per rispettare constraints piattaforma\n5. UI selector piattaforma con icone e switch rapido\n6. Salvataggio preferenze tone of voice per brand",
            "status": "pending",
            "testStrategy": "Test limiti caratteri per piattaforma, test generazione con diversi tone profiles, test persistenza preferenze, test UI selectors.",
            "parentId": "undefined"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "media-processing",
          "phase-3-agents",
          "python",
          "rag"
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Setup SQLite vector store e schema per embeddings, 2) Implementazione BrandKnowledgeBase con sentence-transformers per indexing documenti, 3) Creazione funzione search con cosine similarity, 4) Implementazione CaptioningAgent con integrazione RAG per contesto brand, 5) UI Caption Editor con preview per piattaforma e suggestions AI, 6) Supporto multi-piattaforma (IG, LinkedIn, Twitter) con tone of voice configurabile"
      },
      {
        "id": 9,
        "title": "Integrazione Postiz API e Scheduling Agent",
        "description": "Implementare l'agente di scheduling che utilizza l'API Postiz per pubblicare contenuti su multiple piattaforme social con analytics webhook.",
        "details": "1. Creare `src/lib/services/postiz.ts`:\n```typescript\nconst POSTIZ_BASE_URL = 'https://api.postiz.com/v1';\n\nexport class PostizClient {\n  constructor(private apiKey: string) {}\n  \n  async schedulePost(post: {\n    content: string;\n    media: string[];\n    platforms: string[];\n    scheduledAt: Date;\n  }) {\n    return fetch(`${POSTIZ_BASE_URL}/posts`, {\n      method: 'POST',\n      headers: { 'Authorization': `Bearer ${this.apiKey}` },\n      body: JSON.stringify(post)\n    });\n  }\n  \n  async getAnalytics(postId: string) { /* ... */ }\n}\n```\n2. Creare `python/agents/scheduling_agent.py`:\n   - Ottimizzazione orari pubblicazione per piattaforma\n   - Suggerimenti basati su analytics storici\n   - Gestione code pubblicazione\n3. Creare UI in `src/routes/publish/+page.svelte`:\n   - Form scheduling con date picker\n   - Preview post per ogni piattaforma\n   - Lista post schedulati\n4. Implementare webhook listener in main process per analytics\n5. Salvare analytics in SQLite locale\n6. Piattaforme: Instagram, Facebook, LinkedIn, Twitter, TikTok",
        "testStrategy": "Test con mock Postiz API. Test UI per scheduling flow. Test webhook processing. Test E2E per flusso completo di pubblicazione.",
        "priority": "medium",
        "dependencies": [
          "5"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Creazione PostizClient TypeScript con metodi API completi",
            "description": "Implementare il client TypeScript per l'API Postiz con tutti i metodi necessari: schedulePost per la programmazione dei post, getAnalytics per recuperare le metriche, cancelPost per annullare pubblicazioni e getScheduledPosts per elencare i post programmati.",
            "dependencies": [],
            "details": "Creare `src/lib/services/postiz.ts` con la classe PostizClient che incapsula tutte le chiamate REST all'API Postiz. Implementare gestione errori robusta con retry logic, tipizzazione TypeScript completa per request/response, e supporto per rate limiting. Includere metodi: schedulePost(post), getAnalytics(postId), cancelPost(postId), getScheduledPosts(), updatePost(postId, updates). Utilizzare fetch con timeout configurabile e headers di autenticazione Bearer token.",
            "status": "pending",
            "testStrategy": "Test unitari con mock fetch per ogni metodo API. Test gestione errori (401, 429 rate limit, 500). Test retry logic. Test tipizzazione con dati malformati.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implementazione SchedulingAgent Python con ottimizzazione orari",
            "description": "Creare l'agente Python di scheduling che analizza gli analytics storici per suggerire orari di pubblicazione ottimali per ogni piattaforma social, gestendo code di pubblicazione intelligenti.",
            "dependencies": [
              1
            ],
            "details": "Creare `python/agents/scheduling_agent.py` estendendo la classe Agent di cagent. Implementare logica di ottimizzazione orari basata su: engagement rate storico per fascia oraria, best practices per piattaforma (es. LinkedIn mattina, Instagram sera), analisi pattern utente specifici. Gestire coda pubblicazioni con priorità e conflict resolution. Esporre tool MCP: suggest_best_time(platform, content_type), optimize_schedule(posts_batch), get_platform_insights(platform).",
            "status": "pending",
            "testStrategy": "Test unitari per algoritmo ottimizzazione con dataset mock. Test suggerimenti per ogni piattaforma. Test gestione coda con conflitti temporali. Test integrazione con PostizClient tramite mock.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "UI Publish Page con form scheduling e preview multi-piattaforma",
            "description": "Sviluppare l'interfaccia utente completa per la pubblicazione in `src/routes/publish/+page.svelte` con form di scheduling, date picker, preview per ogni piattaforma e lista post schedulati.",
            "dependencies": [
              1
            ],
            "details": "Creare pagina Svelte 5 con: form scheduling usando componenti shadcn-svelte (Input, Textarea, DatePicker, Select per piattaforme), preview real-time del post adattato a ogni piattaforma selezionata (diversi limiti caratteri, aspect ratio immagini), upload media con drag-drop, lista post schedulati con filtri per data/piattaforma/status, azioni quick (modifica, cancella, duplica). Utilizzare store Svelte 5 runes per stato reattivo. Integrare con PostizClient via IPC per operazioni CRUD.",
            "status": "pending",
            "testStrategy": "Test componenti UI con Vitest e Testing Library. Test form validation. Test preview rendering per ogni piattaforma. Test interazioni utente (scheduling, cancellazione). Test E2E del flusso completo.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implementazione webhook listener in Electron main process",
            "description": "Creare un server HTTP nel main process Electron per ricevere webhook di analytics da Postiz, processando e inoltrando i dati al renderer process tramite IPC.",
            "dependencies": [
              1
            ],
            "details": "Creare `electron/webhook-server.ts` con server HTTP Express/Fastify leggero su porta configurabile. Implementare endpoint POST /webhooks/postiz/analytics per ricevere notifiche. Validare signature webhook per sicurezza. Parsare payload analytics (impressions, engagement, clicks, shares per post). Inoltrare dati al renderer via IPC per aggiornamento UI real-time. Gestire lifecycle server (start/stop con app). Implementare retry queue per webhook falliti. Configurare ngrok/localtunnel per sviluppo locale.",
            "status": "pending",
            "testStrategy": "Test server HTTP con supertest. Test validazione signature. Test parsing payload analytics. Test IPC communication con mock. Test resilienza a webhook malformati.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Storage analytics SQLite con query e visualizzazione grafici",
            "description": "Implementare lo storage locale degli analytics in SQLite con schema ottimizzato per query temporali e creare componenti di visualizzazione con grafici storici delle performance.",
            "dependencies": [
              4
            ],
            "details": "Estendere schema SQLite in `src/lib/db/schema.ts` con tabelle: post_analytics (post_id, platform, timestamp, impressions, engagement, clicks, shares), daily_aggregates (date, platform, totals). Creare `src/lib/services/analytics-storage.ts` con metodi: saveAnalytics(), getAnalyticsByPost(), getAnalyticsByPlatform(), getTimeRangeAggregates(). Creare componenti grafici in `src/lib/components/analytics/` usando libreria charts (Chart.js o similar): EngagementChart, PlatformComparison, TimelinePerformance. Implementare filtri data range e export CSV.",
            "status": "pending",
            "testStrategy": "Test CRUD SQLite per analytics. Test query aggregazioni temporali. Test rendering grafici con dati mock. Test filtri e export. Test performance con grandi dataset.",
            "parentId": "undefined"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "publishing",
          "phase-3-agents",
          "python",
          "postiz"
        ],
        "complexity": 6,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Creazione PostizClient TypeScript con metodi API completi (schedulePost, getAnalytics, cancelPost), 2) Implementazione SchedulingAgent Python con ottimizzazione orari per piattaforma, 3) UI Publish Page con form scheduling, date picker e preview multi-piattaforma, 4) Implementazione webhook listener in Electron main process per analytics, 5) Storage analytics SQLite locale con query e visualizzazione grafici storici"
      },
      {
        "id": 10,
        "title": "Integrazione Timeline Twick con A2UI Widgets",
        "description": "Implementare un'interfaccia di scheduling basata su calendario con viste mese/settimana/Kanban per la gestione della programmazione dei post social. Utilizza @event-calendar/core (compatibile Svelte) o FullCalendar. Integrazione bidirezionale con Postiz API.",
        "status": "pending",
        "dependencies": [
          "1",
          "4",
          "9"
        ],
        "priority": null,
        "details": "## NOTA CRITICA: @twick/svelte NON ESISTE\nTwick è solo React. L'implementazione originale deve essere completamente sostituita con un widget calendario.\n\n## Libreria Raccomandata\n`@event-calendar/core` - nativamente compatibile con Svelte 5, oppure `@fullcalendar/core` con adapter\n\n## Struttura File\n\n```\nsrc/\n├── routes/scheduling/\n│   └── +page.svelte              # Pagina principale calendario\n├── lib/\n│   ├── stores/\n│   │   └── calendar-state.svelte.ts   # Store Svelte 5 runes\n│   ├── services/\n│   │   └── postiz-sync.ts        # Sync bidirezionale Postiz\n│   └── components/custom/\n│       ├── CalendarWidget.svelte  # Wrapper calendario principale\n│       ├── PostEventCard.svelte   # Card evento nel calendario\n│       └── KanbanBoard.svelte     # Vista Kanban alternativa\n```\n\n## Implementazione Store (Svelte 5 Runes)\n```typescript\n// src/lib/stores/calendar-state.svelte.ts\nimport type { ScheduledPost } from '$lib/types';\n\nexport type CalendarView = 'month' | 'week' | 'kanban';\n\nlet currentView = $state<CalendarView>('month');\nlet scheduledPosts = $state<ScheduledPost[]>([]);\nlet selectedPost = $state<ScheduledPost | null>(null);\nlet isSyncing = $state<boolean>(false);\n\nexport const calendarState = {\n  get currentView() { return currentView; },\n  get scheduledPosts() { return scheduledPosts; },\n  get selectedPost() { return selectedPost; },\n  get isSyncing() { return isSyncing; },\n  setView: (view: CalendarView) => { currentView = view; },\n  selectPost: (post: ScheduledPost | null) => { selectedPost = post; },\n};\n```\n\n## Funzionalità Principali\n1. Vista calendario (mese di default) con eventi post schedulati\n2. Toggle rapido tra viste: Month/Week/Kanban\n3. Drag-drop per rischedulare post tra date/orari\n4. Time picker per scheduling orario specifico\n5. Preview card del post sull'evento calendario\n6. Indicatori status: pending (giallo), published (verde), failed (rosso)\n7. Export calendario iCal (.ics)\n8. Kanban board: colonne per giorni o status (draft, scheduled, published)\n\n## Integrazione Postiz (via Task 9)\n- Sync automatico al cambio schedule\n- Fallback a stato locale se sync fallisce\n- Indicatore visivo stato sync\n\n## Sistema A2UI (Mantenuto Separato)\nIl sistema AgentWidget per widget dinamici dagli agenti rimane valido ma separato dal calendario scheduling.",
        "testStrategy": "Test rendering eventi calendario con mock data. Test funzionalità drag-drop con Playwright E2E. Test sync Postiz con API mock (intercettori MSW). Test toggle viste (month/week/kanban). Test responsive design su viewport diversi. Test export iCal verifica formato valido.",
        "subtasks": [
          {
            "id": 1,
            "title": "Installazione libreria calendario Svelte-compatibile e verifica Svelte 5",
            "description": "Installare @event-calendar/core (o alternativa FullCalendar) e verificare compatibilità con Svelte 5 runes. Creare wrapper se necessario.",
            "dependencies": [],
            "details": "1. Valutare le due opzioni:\n   - **@event-calendar/core**: Nativo Svelte, leggero (~35KB), API semplice\n   - **@fullcalendar/core**: Più feature, richiede adapter, più pesante\n2. Installare la libreria scelta:\n   ```bash\n   # Opzione A (raccomandata)\n   npm install @event-calendar/core @event-calendar/day-grid @event-calendar/time-grid @event-calendar/interaction\n   \n   # Opzione B\n   npm install @fullcalendar/core @fullcalendar/daygrid @fullcalendar/timegrid @fullcalendar/interaction\n   ```\n3. Creare `src/lib/components/custom/CalendarWidget.svelte` con import base\n4. Testare rendering in una pagina di prova con eventi mock\n5. Verificare compatibilità Svelte 5 runes: usare `$state` per opzioni calendario\n6. Se incompatibilità, creare wrapper che converte runes in props legacy\n7. Documentare scelta finale e workaround in commenti",
            "status": "pending",
            "testStrategy": "Test di rendering con Vitest + @testing-library/svelte. Verificare che il calendario si renderizza senza warning deprecation. Test props reactive con Svelte 5 syntax."
          },
          {
            "id": 2,
            "title": "Creazione Store calendar-state con Svelte 5 runes e tipi TypeScript",
            "description": "Implementare lo store Svelte 5 per lo stato del calendario con tipi TypeScript completi, seguendo il pattern esistente in llm-providers.svelte.ts.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `src/lib/stores/calendar-state.svelte.ts` seguendo pattern esistente:\n```typescript\nexport type CalendarView = 'month' | 'week' | 'kanban';\nexport type PostStatus = 'draft' | 'pending' | 'published' | 'failed';\n\nexport interface ScheduledPost {\n  id: string;\n  title: string;\n  content: string;\n  platform: 'instagram' | 'tiktok' | 'youtube' | 'twitter' | 'linkedin';\n  scheduledAt: Date;\n  media: string[];\n  status: PostStatus;\n  postizId?: string;\n}\n\nlet currentView = $state<CalendarView>('month');\nlet scheduledPosts = $state<ScheduledPost[]>([]);\nlet selectedPost = $state<ScheduledPost | null>(null);\nlet isSyncing = $state<boolean>(false);\nlet lastSyncAt = $state<Date | null>(null);\nlet syncError = $state<string | null>(null);\n\nconst postsByDate = $derived.by(() => {\n  const grouped = new Map<string, ScheduledPost[]>();\n  for (const post of scheduledPosts) {\n    const dateKey = post.scheduledAt.toISOString().split('T')[0];\n    const existing = grouped.get(dateKey) ?? [];\n    grouped.set(dateKey, [...existing, post]);\n  }\n  return grouped;\n});\n```\n2. Implementare azioni CRUD: addPost, updatePost, removePost, reschedulePost\n3. Aggiungere metodi per conversione calendario events format\n4. Esportare store oggetto con getters reattivi e actions",
            "status": "pending",
            "testStrategy": "Test unitari per operazioni CRUD sullo store. Test $derived per raggruppamento per data. Test serializzazione/deserializzazione date. Verificare reattività con component mock."
          },
          {
            "id": 3,
            "title": "Implementazione pagina scheduling con viste Month/Week/Kanban",
            "description": "Creare la route /scheduling con componente calendario principale, toggle per cambio vista, e layout responsivo.",
            "dependencies": [
              1,
              2
            ],
            "details": "1. Creare `src/routes/scheduling/+page.svelte`:\n```svelte\n<script lang=\"ts\">\n  import { calendarState } from '$lib/stores/calendar-state.svelte';\n  import CalendarWidget from '$lib/components/custom/CalendarWidget.svelte';\n  import KanbanBoard from '$lib/components/custom/KanbanBoard.svelte';\n  import { Button } from '$lib/components/ui/button';\n</script>\n\n<div class=\"flex flex-col h-full\">\n  <header class=\"flex justify-between items-center p-4 border-b\">\n    <h1 class=\"text-2xl font-bold\">Scheduling</h1>\n    <div class=\"flex gap-2\">\n      <Button variant=\"outline\" onclick={() => calendarState.setView('month')}>Month</Button>\n      <Button variant=\"outline\" onclick={() => calendarState.setView('week')}>Week</Button>\n      <Button variant=\"outline\" onclick={() => calendarState.setView('kanban')}>Kanban</Button>\n    </div>\n  </header>\n  \n  {#if calendarState.currentView === 'kanban'}\n    <KanbanBoard posts={calendarState.scheduledPosts} />\n  {:else}\n    <CalendarWidget view={calendarState.currentView} events={calendarState.scheduledPosts} />\n  {/if}\n</div>\n```\n2. Creare `CalendarWidget.svelte` con integrazione libreria calendario\n3. Creare `KanbanBoard.svelte` con colonne per status o giorni\n4. Creare `PostEventCard.svelte` per preview post su evento\n5. Aggiungere link in sidebar AppSidebar.svelte\n6. Implementare responsive: calendario full su desktop, lista su mobile",
            "status": "pending",
            "testStrategy": "Test navigazione verso /scheduling. Test toggle tra viste con click. Test rendering eventi nel calendario. Test responsive con viewport diversi. E2E con Playwright per interazioni complete."
          },
          {
            "id": 4,
            "title": "Implementazione drag-drop rescheduling e time picker",
            "description": "Aggiungere funzionalità drag-drop per spostare post tra date/orari nel calendario, con time picker per scheduling preciso.",
            "dependencies": [
              2,
              3
            ],
            "details": "1. Configurare plugin interaction della libreria calendario:\n   - eventDrag per spostamento eventi\n   - eventResize per modifica durata\n   - eventDrop handler per persistenza\n2. Implementare handler onEventDrop in CalendarWidget:\n```typescript\nasync function handleEventDrop(info: EventDropInfo) {\n  const { event, oldStart, newStart } = info;\n  const postId = event.id;\n  \n  calendarState.reschedulePost(postId, newStart);\n  \n  const success = await postizSync.reschedule(postId, newStart);\n  if (!success) {\n    calendarState.reschedulePost(postId, oldStart);\n    toast.error('Reschedule fallito');\n  }\n}\n```\n3. Creare componente time picker usando shadcn-svelte DatePicker/TimePicker\n4. Integrare time picker nel dialog di creazione/modifica post\n5. Validare orari: no scheduling nel passato, rispetto limiti piattaforma\n6. Animazioni smooth durante drag con feedback visivo",
            "status": "pending",
            "testStrategy": "Test E2E drag-drop con Playwright. Test validazione orari passati. Test rollback su errore sync. Test time picker input/output. Test animazioni non bloccano interazione."
          },
          {
            "id": 5,
            "title": "Integrazione servizio postiz-sync con fallback locale",
            "description": "Creare servizio TypeScript per sincronizzazione bidirezionale con Postiz API, con gestione errori e fallback a stato locale.",
            "dependencies": [
              2
            ],
            "details": "1. Creare `src/lib/services/postiz-sync.ts`:\n```typescript\nimport { calendarState } from '$lib/stores/calendar-state.svelte';\n\nexport class PostizSyncService {\n  private syncInProgress = false;\n  private retryQueue: ScheduledPost[] = [];\n  \n  async syncAll(): Promise<SyncResult> {\n    if (this.syncInProgress) return { status: 'in-progress' };\n    calendarState.setSyncing(true);\n    \n    try {\n      const remotePosts = await this.fetchFromPostiz();\n      const merged = this.mergeWithLocal(remotePosts);\n      calendarState.setScheduledPosts(merged);\n      calendarState.setSyncTimestamp(new Date());\n      return { status: 'success', count: merged.length };\n    } catch (error) {\n      calendarState.setSyncError(error.message);\n      return { status: 'error', error };\n    } finally {\n      calendarState.setSyncing(false);\n    }\n  }\n  \n  async reschedule(postId: string, newDate: Date): Promise<boolean> {\n    const result = await window.electronAPI.postiz.reschedule(postId, newDate);\n    return result.success;\n  }\n}\n\nexport const postizSync = new PostizSyncService();\n```\n2. Implementare logica merge: remote wins per conflict, preserva modifiche locali non sincronizzate\n3. Auto-sync on startup e ogni 5 minuti in background\n4. Retry queue per operazioni fallite\n5. Indicatore visivo stato sync in UI (icona sync nella header)",
            "status": "pending",
            "testStrategy": "Test sync con mock Postiz API (MSW interceptor). Test merge conflict resolution. Test retry queue. Test auto-sync timing. Test fallback quando API non disponibile."
          },
          {
            "id": 6,
            "title": "Implementazione export iCal e indicatori status post",
            "description": "Aggiungere export calendario in formato iCal (.ics) e indicatori visivi colorati per status dei post (pending, published, failed).",
            "dependencies": [
              3
            ],
            "details": "1. Implementare export iCal in `src/lib/services/ical-export.ts`:\n```typescript\nimport { calendarState } from '$lib/stores/calendar-state.svelte';\n\nexport function generateICalFile(): string {\n  const posts = calendarState.scheduledPosts;\n  let ical = `BEGIN:VCALENDAR\\nVERSION:2.0\\nPRODID:-//TRAE Extractor//Scheduling//EN\\n`;\n  \n  for (const post of posts) {\n    ical += `BEGIN:VEVENT\\nUID:${post.id}@trae-extractor\\nDTSTART:${formatICalDate(post.scheduledAt)}\\nSUMMARY:[${post.platform}] ${post.title}\\nDESCRIPTION:${post.content.substring(0, 100)}\\nEND:VEVENT\\n`;\n  }\n  \n  ical += 'END:VCALENDAR';\n  return ical;\n}\n\nexport function downloadICalFile(): void {\n  const content = generateICalFile();\n  const blob = new Blob([content], { type: 'text/calendar' });\n}\n```\n2. Aggiungere bottone Export iCal nella header scheduling\n3. Implementare colori status in PostEventCard:\n   - draft: grigio (#9CA3AF)\n   - pending: giallo (#EAB308)\n   - published: verde (#22C55E)\n   - failed: rosso (#EF4444)\n4. Aggiungere icone status (Lucide: Clock, CheckCircle, XCircle)\n5. Legend colori visibile in header o sidebar\n6. Tooltip su hover con dettagli status",
            "status": "pending",
            "testStrategy": "Test generazione iCal valida (validatore online). Test download file. Test colori corretti per ogni status. Test tooltip accessibilità. Test icone renderizzate correttamente."
          }
        ]
      },
      {
        "id": 11,
        "title": "Orchestrator Agent e Comunicazione A2A",
        "description": "Implementare l'agente orchestratore che coordina tutti gli altri agenti specializzati, gestendo il protocollo A2A (Agent-to-Agent) per passaggio contesto e handoff.",
        "details": "1. Creare `python/agents/orchestrator_agent.py`:\n```python\nfrom cagent import Agent, Handoff\n\nclass OrchestratorAgent(Agent):\n    name = 'orchestrator'\n    description = 'Coordina il workflow completo di gestione media'\n    \n    sub_agents = [\n        'extraction_agent',\n        'editing_agent', \n        'captioning_agent',\n        'scheduling_agent'\n    ]\n    \n    async def process_request(self, user_request: str, context: Dict):\n        # Analizza richiesta e determina workflow\n        workflow = self.plan_workflow(user_request)\n        \n        results = {}\n        for step in workflow:\n            agent = self.get_agent(step.agent_name)\n            result = await agent.execute(step.task, context={**context, **results})\n            results[step.agent_name] = result\n            \n            # Notifica UI via SSE\n            await self.emit_event('step_complete', {\n                'agent': step.agent_name,\n                'result': result\n            })\n        \n        return results\n    \n    def plan_workflow(self, request: str) -> List[WorkflowStep]:\n        # LLM determina sequenza agenti\n        pass\n```\n2. Implementare protocollo A2A:\n   - Schema contesto condiviso\n   - Handoff con preservazione stato\n   - Error handling e retry\n3. Dashboard orchestrazione in `src/routes/+page.svelte`:\n   - Visualizzazione workflow attivo\n   - Status ogni agente\n   - Interruzione/pausa workflow\n4. Logging conversazioni agenti per debug",
        "testStrategy": "Test unitari per planning workflow. Test A2A handoff tra agenti. Test error recovery. Test E2E per workflow completo extraction->edit->caption->schedule.",
        "priority": "high",
        "dependencies": [
          "6",
          "7",
          "8",
          "9"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Definizione Protocollo A2A con Schema Contesto Condiviso",
            "description": "Progettare e implementare il protocollo Agent-to-Agent (A2A) con uno schema tipizzato per il contesto condiviso tra agenti, includendo serializzazione e validazione dei dati.",
            "dependencies": [],
            "details": "Creare `python/protocols/a2a_protocol.py` con:\n1. Definizione Pydantic models per A2AContext:\n   - `SharedContext`: dati condivisi (media_paths, metadata, user_preferences)\n   - `AgentState`: stato corrente dell'agente (status, progress, errors)\n   - `HandoffPayload`: payload per trasferimento tra agenti\n2. Definire `A2AMessage` con fields: sender, receiver, action, context, timestamp, correlation_id\n3. Implementare `ContextValidator` per validazione schema prima di handoff\n4. Creare `ContextSerializer` per JSON serialization con supporto per tipi complessi (datetime, Path, bytes)\n5. Definire enum `A2AAction`: START, HANDOFF, COMPLETE, ERROR, ROLLBACK\n6. Implementare versioning dello schema per backward compatibility",
            "status": "pending",
            "testStrategy": "Test unitari per validazione schema con dati validi/invalidi. Test serializzazione/deserializzazione roundtrip. Test versioning schema con payload legacy.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implementazione OrchestratorAgent Base con Registro Sub-Agents",
            "description": "Creare la classe OrchestratorAgent con sistema di registrazione dinamica degli agenti specializzati e discovery automatico.",
            "dependencies": [
              1
            ],
            "details": "Creare `python/agents/orchestrator_agent.py`:\n1. Classe `OrchestratorAgent` che estende `Agent` dal cagent framework\n2. Implementare `AgentRegistry` con:\n   - `register_agent(name, agent_class)`: registra agente\n   - `get_agent(name)`: recupera istanza agente\n   - `list_agents()`: lista agenti disponibili\n   - `agent_capabilities`: mapping nome -> capabilities\n3. Auto-discovery agenti da `python/agents/` usando importlib\n4. Implementare `AgentPool` per gestione istanze con lazy initialization\n5. Definire interfaccia `ISpecializedAgent` che tutti gli agenti devono implementare\n6. Metodo `validate_agents()` per verificare tutti i sub-agents siano disponibili\n7. Configurazione agenti via YAML/JSON per flessibilità deployment",
            "status": "pending",
            "testStrategy": "Test registrazione/deregistrazione agenti. Test discovery automatico. Test lazy initialization. Test con mock agents per isolamento.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Implementazione Workflow Planner con LLM",
            "description": "Sviluppare il sistema di pianificazione workflow che utilizza LLM per analizzare richieste utente e determinare la sequenza ottimale di agenti da invocare.",
            "dependencies": [
              2
            ],
            "details": "Creare `python/agents/workflow_planner.py`:\n1. Classe `WorkflowPlanner` con metodo `plan_workflow(user_request, available_agents) -> List[WorkflowStep]`\n2. `WorkflowStep` dataclass: agent_name, task_description, expected_inputs, expected_outputs, timeout\n3. Prompt engineering per LLM:\n   - System prompt con descrizione capabilities ogni agente\n   - Few-shot examples per workflow comuni\n   - Output strutturato JSON per parsing affidabile\n4. Implementare `WorkflowOptimizer` per:\n   - Parallelizzazione step indipendenti\n   - Eliminazione step ridondanti\n   - Stima durata workflow\n5. Cache LRU per workflow comuni (hash della richiesta)\n6. Fallback a regole statiche se LLM non disponibile\n7. Validazione workflow: verifica dipendenze soddisfatte, agenti esistenti",
            "status": "pending",
            "testStrategy": "Test con mock LLM responses. Test parsing output strutturato. Test ottimizzazione parallelismo. Test fallback regole statiche. Test cache hit/miss.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Sistema Handoff con Preservazione Stato e Checkpoint",
            "description": "Implementare il meccanismo di handoff tra agenti con salvataggio dello stato per permettere rollback e recovery in caso di errori.",
            "dependencies": [
              1,
              2
            ],
            "details": "Creare `python/protocols/handoff_manager.py`:\n1. Classe `HandoffManager` con:\n   - `initiate_handoff(from_agent, to_agent, context)`: avvia trasferimento\n   - `complete_handoff(handoff_id)`: conferma completamento\n   - `rollback_handoff(handoff_id)`: ripristina stato precedente\n2. Sistema checkpoint:\n   - `CheckpointStore` con storage SQLite per persistenza\n   - Salvataggio automatico prima di ogni handoff\n   - Metadata: timestamp, agent_state, context_snapshot\n3. Implementare `StateSnapshot` per deep copy dello stato agente\n4. `HandoffTransaction` per garantire atomicità:\n   - Prepare -> Commit/Rollback pattern\n   - Timeout automatico per handoff pendenti\n5. Event emitter per notifiche handoff (start, complete, rollback)\n6. Cleanup automatico checkpoint vecchi (configurable retention)",
            "status": "pending",
            "testStrategy": "Test handoff completo tra agenti mock. Test rollback dopo errore. Test persistenza checkpoint. Test recovery dopo crash simulato. Test cleanup automatico.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Error Handling Robusto con Retry Policies e Circuit Breaker",
            "description": "Implementare sistema di gestione errori avanzato con retry configurabili, circuit breaker pattern e graceful degradation.",
            "dependencies": [
              4
            ],
            "details": "Creare `python/resilience/error_handler.py`:\n1. `RetryPolicy` configurabile:\n   - max_retries, backoff_strategy (exponential, linear, fixed)\n   - retry_exceptions: lista eccezioni da ritentare\n   - on_retry callback per logging/metriche\n2. `CircuitBreaker` per ogni agente:\n   - Stati: CLOSED, OPEN, HALF_OPEN\n   - failure_threshold, recovery_timeout, success_threshold\n   - Metriche: failure_count, last_failure_time\n3. `ErrorClassifier` per categorizzare errori:\n   - Transient (retry), Permanent (fail fast), Unknown\n4. `GracefulDegradation` strategies:\n   - Skip agent non critico\n   - Use cached result\n   - Partial workflow completion\n5. `ErrorAggregator` per raccogliere errori multipli in workflow\n6. Integration con logging strutturato per troubleshooting\n7. Alerting hooks per errori critici",
            "status": "pending",
            "testStrategy": "Test retry con diverse policies. Test circuit breaker state transitions. Test graceful degradation scenarios. Test error classification accuracy. Test alerting hooks.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Dashboard Orchestrazione UI con Workflow Visualization Real-time",
            "description": "Sviluppare l'interfaccia utente Svelte per visualizzare lo stato del workflow in tempo reale con controlli per pausa, interruzione e dettagli agenti.",
            "dependencies": [
              3,
              4
            ],
            "details": "Creare/estendere `src/routes/+page.svelte` e componenti:\n1. `WorkflowVisualization.svelte`:\n   - Grafo workflow con nodi agenti e frecce transizioni\n   - Colori stato: pending (grigio), running (blu), complete (verde), error (rosso)\n   - Animazioni transizioni handoff\n2. `AgentStatusCard.svelte` per ogni agente:\n   - Nome, descrizione, stato corrente\n   - Progress bar se disponibile\n   - Ultimo output/errore\n3. Controlli workflow:\n   - Pulsante Pause/Resume\n   - Pulsante Stop con conferma\n   - Pulsante Retry per step falliti\n4. SSE listener per aggiornamenti real-time da backend\n5. Store Svelte `workflowStore` per stato globale workflow\n6. Timeline laterale con cronologia eventi\n7. Modal dettagli per inspect contesto ogni step",
            "status": "pending",
            "testStrategy": "Test componenti con Vitest. Test SSE updates con mock server. Test controlli UI (pause, stop, retry). Test E2E flusso completo con Playwright.",
            "parentId": "undefined"
          },
          {
            "id": 7,
            "title": "Logging e Tracing Conversazioni Agenti per Debug",
            "description": "Implementare sistema completo di logging strutturato e distributed tracing per tracciare conversazioni e interazioni tra agenti a fini di debug e analisi.",
            "dependencies": [
              5
            ],
            "details": "Creare `python/observability/agent_logger.py`:\n1. `StructuredLogger` con output JSON:\n   - Fields: timestamp, correlation_id, agent_name, action, payload, duration_ms\n   - Log levels: DEBUG, INFO, WARN, ERROR con filtering\n2. `ConversationTracer` per A2A:\n   - Trace ID unico per ogni workflow\n   - Span per ogni step agente\n   - Parent-child relationships per nested calls\n3. `LogStore` con SQLite per query storiche:\n   - Ricerca per correlation_id, agent, timerange\n   - Aggregazioni per analytics\n4. UI componente `DebugPanel.svelte`:\n   - Vista conversazioni per workflow\n   - Filtri per agente/livello\n   - Export logs come JSON\n5. Integration con Python logging module\n6. Log rotation e cleanup automatico\n7. Sensitive data masking (API keys, tokens)",
            "status": "pending",
            "testStrategy": "Test structured logging output format. Test correlation ID propagation. Test query storiche su LogStore. Test UI filtri e export. Test masking dati sensibili.",
            "parentId": "undefined"
          }
        ],
        "tags": [
          "python-backend",
          "agents",
          "phase-3-agents",
          "python",
          "cagent"
        ],
        "complexity": 9,
        "recommendedSubtasks": 7,
        "expansionPrompt": "Espandi in subtask: 1) Definizione protocollo A2A con schema contesto condiviso, 2) Implementazione OrchestratorAgent base con registro sub-agents, 3) Implementazione Workflow Planner con LLM per determinare sequenza agenti, 4) Sistema handoff con preservazione stato e checkpoint per rollback, 5) Error handling robusto con retry policies e circuit breaker, 6) Dashboard orchestrazione UI con workflow visualization real-time, 7) Logging e tracing conversazioni agenti per debug"
      },
      {
        "id": 12,
        "title": "Brand Management UI e Asset Organization",
        "description": "Creare l'interfaccia per gestione brand con organizzazione assets, upload documenti brand guidelines per RAG, e configurazione profili social.",
        "details": "1. Creare `src/routes/brands/+page.svelte`:\n   - Lista brand cards con logo e stats\n   - Modal creazione nuovo brand\n2. Creare `src/routes/brands/[brandId]/+page.svelte`:\n```svelte\n<script>\n  import { page } from '$app/stores';\n  import { Tabs, TabsContent } from '$lib/components/ui/tabs';\n</script>\n<Tabs>\n  <TabsContent value=\"assets\">\n    <!-- Griglia assets del brand -->\n  </TabsContent>\n  <TabsContent value=\"guidelines\">\n    <!-- Upload PDF/docs per RAG indexing -->\n  </TabsContent>\n  <TabsContent value=\"social\">\n    <!-- Configurazione account social -->\n  </TabsContent>\n  <TabsContent value=\"analytics\">\n    <!-- Dashboard analytics aggregati -->\n  </TabsContent>\n</Tabs>\n```\n3. Implementare upload documenti con indexing automatico RAG\n4. Creare store brand con SQLite backend\n5. Componenti:\n   - AssetGrid con filtri e ricerca\n   - BrandColorPalette estratta da guidelines\n   - SocialAccountConnector per OAuth",
        "testStrategy": "Test CRUD operazioni brand. Test upload e indexing documenti. Test UI per navigazione brand e assets.",
        "priority": "medium",
        "dependencies": [
          "1",
          "8"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Creazione Route Brands con Lista Brand Cards e Modal Creazione",
            "description": "Implementare la pagina principale `src/routes/brands/+page.svelte` con griglia di BrandCard per ogni brand registrato, includendo logo, statistiche e azioni rapide. Creare il modal per l'inserimento di nuovi brand con form validation.",
            "dependencies": [],
            "details": "1. Creare `src/routes/brands/+page.svelte` con layout griglia responsiva CSS Grid/Flexbox\n2. Implementare componente `BrandCard.svelte` che mostra: logo brand, nome, numero assets, data ultima modifica, badge stato\n3. Creare `CreateBrandModal.svelte` con form shadcn (Input, Button, Dialog):\n   - Campo nome brand (required, min 2 caratteri)\n   - Upload logo (preview immagine, max 2MB)\n   - Descrizione opzionale\n   - Selezione colore primario\n4. Aggiungere bottone 'Nuovo Brand' che apre il modal\n5. Implementare stati empty state quando non ci sono brand\n6. Collegare al brandStore per fetch lista brands all'onMount\n7. Gestire loading states e error handling con toast notifications",
            "status": "pending",
            "testStrategy": "Test unitari per rendering BrandCard con vari stati (con/senza logo, diverse statistiche). Test form validation per modal creazione (campi required, limiti caratteri, dimensione file). Test E2E per flusso creazione nuovo brand completo. Verificare layout responsivo su viewport mobile/tablet/desktop.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implementazione Route brands/[brandId] con Sistema Tabs",
            "description": "Creare la pagina dettaglio brand dinamica `src/routes/brands/[brandId]/+page.svelte` con navigazione a tabs per assets, guidelines, social accounts e analytics dashboard.",
            "dependencies": [
              1
            ],
            "details": "1. Creare `src/routes/brands/[brandId]/+page.svelte` con estrazione brandId da $page.params\n2. Implementare header brand con logo grande, nome, descrizione, edit button\n3. Configurare shadcn Tabs con 4 TabsContent:\n   - 'assets': placeholder per AssetGrid\n   - 'guidelines': placeholder per upload documenti\n   - 'social': placeholder per SocialAccountConnector\n   - 'analytics': placeholder per dashboard metriche\n4. Implementare URL persistence del tab attivo via query params (?tab=assets)\n5. Aggiungere page.ts per load function che fetcha dati brand\n6. Gestire 404 per brandId inesistente con redirect o error page\n7. Implementare breadcrumb navigation (Home > Brands > [Brand Name])\n8. Loading skeleton states per ogni tab durante fetch dati",
            "status": "pending",
            "testStrategy": "Test navigazione tra tabs e verifica contenuto corretto per ogni tab. Test URL persistence del tab selezionato dopo refresh pagina. Test 404 handling per brandId inesistenti. Test loading states durante fetch. Verificare che $page.params.brandId venga correttamente estratto e utilizzato.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Sistema Upload Documenti con RAG Indexing Automatico",
            "description": "Implementare l'interfaccia upload documenti brand guidelines (PDF, DOCX, MD) nel tab guidelines con pipeline di indexing automatico nel sistema RAG per ricerca semantica.",
            "dependencies": [
              2
            ],
            "details": "1. Creare `GuidelinesUploader.svelte` nel tab guidelines con:\n   - Drag & drop zone per file upload\n   - Supporto formati: PDF, DOCX, MD, TXT\n   - Preview lista documenti caricati con metadata\n   - Progress bar durante upload e indexing\n2. Implementare IPC handler 'documents:upload' in main process:\n   - Salvataggio file in cartella brand-specific\n   - Estrazione testo con librerie appropriate (pdf-parse, mammoth)\n3. Creare pipeline RAG indexing:\n   - Chunking documenti (500-1000 token per chunk con overlap)\n   - Generazione embeddings via provider LLM configurato\n   - Storage in vector database locale (sqlite-vec o chromadb)\n4. UI per visualizzare stato indexing per ogni documento\n5. Bottone per ri-indicizzare documento modificato\n6. Delete documento con rimozione da vector store",
            "status": "pending",
            "testStrategy": "Test upload file di vari formati (PDF, DOCX, MD) verificando salvataggio corretto. Test estrazione testo da PDF multi-pagina e DOCX con formattazione. Test chunking con verifica overlap e dimensioni. Test generazione embeddings con mock provider. Test query RAG con documenti di test e risultati attesi. Test UI stati upload (progress, success, error) e indexing status.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Store Brand con SQLite Backend via IPC",
            "description": "Creare lo store Svelte reattivo per gestione stato brands con persistenza SQLite tramite comunicazione IPC con main process Electron, includendo schema database e operazioni CRUD complete.",
            "dependencies": [],
            "details": "1. Definire schema SQLite in `electron/database/schema.sql`:\n   - Tabella `brands` (id, name, logo_path, description, primary_color, created_at, updated_at)\n   - Tabella `brand_assets` (id, brand_id FK, file_path, type, metadata_json, created_at)\n   - Tabella `brand_documents` (id, brand_id FK, file_path, indexed_at, chunks_count)\n2. Creare `electron/ipc/brandHandlers.ts` con handlers:\n   - 'brands:list' -> SELECT con paginazione\n   - 'brands:get' -> SELECT by id con relazioni\n   - 'brands:create' -> INSERT con validazione\n   - 'brands:update' -> UPDATE con timestamp\n   - 'brands:delete' -> DELETE con cascade assets/documents\n3. Creare `src/lib/stores/brandStore.ts` con Svelte writable:\n   - State: { brands: Brand[], loading: boolean, error: string | null, selectedBrand: Brand | null }\n   - Actions: fetchBrands(), getBrand(id), createBrand(data), updateBrand(id, data), deleteBrand(id)\n4. Implementare caching locale e invalidation strategy\n5. Gestire optimistic updates per UX migliore",
            "status": "pending",
            "testStrategy": "Test CRUD operations su SQLite con database in-memory. Test IPC handlers con mock database verificando query corrette. Test store Svelte con operazioni async e verifica state updates. Test rollback su errori database con verifica stato consistente. Verificare cascade delete per assets e documents quando brand viene eliminato.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Componenti AssetGrid, BrandColorPalette e SocialAccountConnector",
            "description": "Implementare i tre componenti UI principali: griglia assets con filtri e virtual scrolling, estrattore palette colori da guidelines, e connettore OAuth per account social.",
            "dependencies": [
              2,
              4
            ],
            "details": "1. Creare `AssetGrid.svelte`:\n   - Griglia responsiva con virtual scrolling (svelte-virtual-list o tanstack-virtual)\n   - Filtri per tipo asset (immagine, video, documento)\n   - Ricerca full-text per nome/tag\n   - Selezione multipla con bulk actions (delete, export, tag)\n   - Preview lightbox per immagini\n   - Ordinamento per data, nome, dimensione\n2. Creare `BrandColorPalette.svelte`:\n   - Estrazione automatica colori dominanti da logo/guidelines (color-thief o vibrant.js)\n   - Display palette con hex/rgb values\n   - Copy to clipboard per ogni colore\n   - Salvataggio palette custom nel brand\n3. Creare `SocialAccountConnector.svelte`:\n   - Card per ogni piattaforma (Instagram, TikTok, YouTube, Facebook)\n   - Stato connesso/disconnesso con icone\n   - Bottone Connect che avvia OAuth flow\n   - Display account name e avatar quando connesso\n   - Bottone Disconnect con conferma\n   - Placeholder per piattaforme non ancora implementate",
            "status": "pending",
            "testStrategy": "Test AssetGrid con vari numeri di assets (0, 10, 100, 1000+) verificando performance virtual scrolling. Test filtri con combinazioni multiple attive. Test estrazione colori da immagini di test con palette note. Test OAuth flow con mock providers verificando state management. Test UI stati connesso/disconnesso per ogni social account. Test copy to clipboard per colori palette.",
            "parentId": "undefined"
          }
        ],
        "tags": [
          "frontend",
          "ui-framework",
          "phase-4-integration",
          "svelte"
        ],
        "complexity": 5,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Creazione route brands con lista brand cards e modal creazione, 2) Implementazione route brands/[brandId] con sistema tabs (assets, guidelines, social, analytics), 3) Sistema upload documenti con RAG indexing automatico, 4) Store brand con SQLite backend via IPC, 5) Componenti AssetGrid, BrandColorPalette e SocialAccountConnector"
      },
      {
        "id": 13,
        "title": "Testing Suite Completa e CI/CD Setup",
        "description": "Implementare suite di test completa con unit, integration, e E2E tests, insieme a pipeline CI/CD per build automatiche.",
        "details": "1. Configurare test pyramid:\n   - 70% Unit tests (Vitest per frontend, pytest per Python)\n   - 20% Integration tests (IPC, agent communication)\n   - 10% E2E tests (Playwright)\n2. Creare `tests/` struttura:\n```\ntests/\n├── unit/\n│   ├── components/\n│   ├── services/\n│   └── stores/\n├── integration/\n│   ├── ipc/\n│   ├── agents/\n│   └── rag/\n└── e2e/\n    ├── workflows/\n    └── fixtures/\n```\n3. Test critici da implementare:\n   - Provider configuration validation\n   - Agent handoff context preservation\n   - A2UI component generation safety\n   - Timeline drag-drop scheduling\n   - Twick timeline rendering\n   - Electron context isolation\n4. CI/CD in `.github/workflows/`:\n   - Lint + Type check\n   - Unit tests\n   - Integration tests\n   - E2E tests\n   - Build artefatti per macOS/Windows/Linux\n5. Pre-commit hooks con husky",
        "testStrategy": "Meta-testing: verificare copertura test >80%. Test che CI pipeline completi senza errori. Test build artefatti su tutte le piattaforme.",
        "priority": "medium",
        "dependencies": [
          "11"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Configurazione Test Pyramid e Struttura Directory tests/",
            "description": "Creare la struttura organizzativa delle directory per test unitari, di integrazione ed E2E, configurando la test pyramid con rapporto 70/20/10",
            "dependencies": [],
            "details": "1. Creare la gerarchia di directory tests/ con subdirectory unit/, integration/, e2e/\n2. Configurare sottocartelle specifiche:\n   - tests/unit/components/, tests/unit/services/, tests/unit/stores/\n   - tests/integration/ipc/, tests/integration/agents/, tests/integration/rag/\n   - tests/e2e/workflows/, tests/e2e/fixtures/\n3. Estendere vite.config.ts per includere i nuovi percorsi di test\n4. Configurare vitest workspace per separare test client e server con ambienti appropriati (jsdom per componenti, node per servizi)\n5. Aggiungere script package.json per eseguire test per categoria (test:unit, test:integration, test:e2e)\n6. Creare file di setup vitest-setup-client.ts e vitest-setup-server.ts con mock globali\n7. Documentare la strategia test pyramid nel README con metriche di coverage target (70% unit, 20% integration, 10% E2E)",
            "status": "pending",
            "testStrategy": "Verificare che la struttura directory sia corretta con glob patterns. Test che tutti gli script npm run test:* funzionino correttamente. Validare che le configurazioni Vitest riconoscano i file di test nelle nuove posizioni.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Unit Tests per Componenti Svelte e Servizi TypeScript con Vitest",
            "description": "Implementare suite completa di test unitari per componenti Svelte 5 e servizi TypeScript utilizzando Vitest e Testing Library",
            "dependencies": [
              1
            ],
            "details": "1. Configurare @testing-library/svelte con supporto Svelte 5 runes e componenti\n2. Creare test per componenti UI critici:\n   - Timeline component (rendering, drag-drop handlers)\n   - Provider configuration forms (validazione input)\n   - A2UI generated components (safety checks)\n   - Twick timeline rendering\n3. Test per servizi TypeScript:\n   - IPC service mocking con vi.mock\n   - Store tests (Svelte stores e state management)\n   - API client tests con mock fetch\n4. Configurare coverage reporter (istanbul/v8) con soglia minima 70%\n5. Aggiungere snapshot testing per componenti UI stabili\n6. Creare helper utilities per render testing di componenti con contesto Svelte\n7. Mock per Electron APIs (contextBridge, ipcRenderer) nei test client\n8. Test per provider configuration validation con casi edge",
            "status": "pending",
            "testStrategy": "Eseguire npm run test:unit con --coverage. Verificare che coverage sia >= 70% per src/. Test matrix per browser environments diversi. Controllare che tutti i componenti critici abbiano test dedicati.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Unit Tests Python per Agenti e Sistema RAG con pytest",
            "description": "Creare suite di test unitari Python con pytest per il sistema di agenti Cagent e il modulo RAG con embeddings",
            "dependencies": [
              1
            ],
            "details": "1. Configurare pytest in python/ directory con pytest.ini e conftest.py\n2. Creare fixtures condivise per:\n   - Mock FastAPI TestClient\n   - Database SQLite in-memory per RAG tests\n   - Fake embeddings model per test veloci\n3. Test per agent communication:\n   - Handoff context preservation tra agenti\n   - Agent state machine transitions\n   - Tool invocation mocking\n4. Test per sistema RAG:\n   - Document indexing con embeddings mock\n   - Similarity search accuracy\n   - Brand knowledge base queries\n5. Test per captioning agent:\n   - Caption generation con mock LLM\n   - Brand guidelines adherence\n6. Configurare pytest-cov per coverage Python >= 80%\n7. Aggiungere pytest-asyncio per test async FastAPI endpoints\n8. Creare test parametrizzati per diverse configurazioni agente",
            "status": "pending",
            "testStrategy": "Eseguire pytest python/tests/ --cov=python/ --cov-report=html. Verificare coverage >= 80%. Test isolation con database in-memory. Validare che tutti gli agenti e RAG components abbiano coverage adeguata.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integration Tests per IPC e Agent Communication",
            "description": "Implementare test di integrazione per il bridge IPC tra Electron main/renderer e la comunicazione con il Python sidecar",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "1. Creare test framework per IPC integration:\n   - Mock Electron main process per test isolati\n   - Test contextBridge exposed APIs\n   - Verifica context isolation attivo\n2. Test IPC handlers:\n   - Keychain save/get/delete operations\n   - Provider API invocations\n   - Error propagation tra processi\n3. Test agent communication end-to-end:\n   - HTTP/SSE streaming dal Python sidecar\n   - Agent handoff con context preservation\n   - Timeout e retry logic\n4. Test RAG integration:\n   - Document upload attraverso IPC\n   - Query e retrieval pipeline\n5. Configurare test database SQLite per integration tests\n6. Mock external APIs (Postiz, provider APIs) con msw o simili\n7. Test health check polling del sidecar\n8. Verifica gestione errori di rete e reconnection",
            "status": "pending",
            "testStrategy": "Eseguire integration tests in ambiente isolato con mock server. Verificare che IPC messages siano correttamente serializzati/deserializzati. Test di stress per connessioni SSE. Coverage target 20% del totale test.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "E2E Tests per Workflow Critici con Playwright",
            "description": "Implementare test end-to-end con Playwright per validare i flussi utente critici dell'applicazione Electron",
            "dependencies": [
              1,
              4
            ],
            "details": "1. Estendere playwright.config.ts per Electron testing:\n   - Configurare electronPath per app packaging\n   - Setup fixture per app instance\n   - Screenshot e video recording su failure\n2. Test workflow critici:\n   - Provider configuration flow completo (add, validate, save)\n   - Timeline drag-drop scheduling operations\n   - Content generation e preview\n   - Posting workflow con scheduling\n3. Creare fixtures directory con:\n   - Test media assets (images, videos)\n   - Mock API responses\n   - Pre-configured app states\n4. Test A2UI component generation:\n   - Safety checks per generated code\n   - Rendering validation\n5. Test multi-window scenarios se applicabile\n6. Configurare retries e timeout appropriati per CI\n7. Parallel test execution con sharding\n8. Accessibility testing con axe-playwright",
            "status": "pending",
            "testStrategy": "Eseguire npx playwright test con --trace on-failure. Verificare che tutti i workflow critici passino. Test su multiple browser (chromium minimo per Electron). Visual regression testing per UI consistency.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "CI/CD Pipeline GitHub Actions con Build Multi-Piattaforma",
            "description": "Configurare pipeline CI/CD completa in GitHub Actions per test automatici, build multi-piattaforma e code signing",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "1. Creare .github/workflows/ci.yml con jobs:\n   - lint: ESLint + TypeScript type check\n   - test-unit: Vitest unit tests con coverage\n   - test-python: pytest per Python sidecar\n   - test-integration: Integration tests\n   - test-e2e: Playwright E2E (dopo build)\n2. Creare .github/workflows/build.yml:\n   - Build matrix: macOS-latest, windows-latest, ubuntu-latest\n   - electron-forge make per artefatti nativi\n   - Upload artifacts per ogni piattaforma\n3. Configurare code signing:\n   - macOS: Apple Developer ID con notarization\n   - Windows: Code signing certificate\n   - Secrets per certificati in GitHub Secrets\n4. Setup pre-commit hooks con husky:\n   - lint-staged per ESLint/Prettier\n   - Commit message validation\n   - Type check pre-push\n5. Configurare Dependabot per security updates\n6. Badge di status nel README\n7. Cache per node_modules e Python venv\n8. Conditional builds su tag per release",
            "status": "pending",
            "testStrategy": "Verificare che CI pipeline completi senza errori su ogni push. Test manuale dei build artefatti su tutte le piattaforme. Validare che code signing funzioni correttamente su macOS e Windows. Controllare che husky hooks si attivino correttamente.",
            "parentId": "undefined"
          }
        ],
        "tags": [
          "infrastructure",
          "testing",
          "phase-5-polish"
        ],
        "complexity": 6,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Configurazione test pyramid e struttura directory tests/ (unit, integration, e2e), 2) Unit tests per componenti Svelte e servizi TypeScript con Vitest, 3) Unit tests Python per agenti e sistema RAG con pytest, 4) Integration tests per IPC e agent communication, 5) E2E tests per workflow critici con Playwright, 6) CI/CD pipeline GitHub Actions con build multi-piattaforma e code signing"
      },
      {
        "id": 14,
        "title": "Electron Packaging e Distribuzione",
        "description": "Configurare il packaging finale dell'applicazione Electron con bundling Python sidecar, code signing, e setup per distribuzione.",
        "details": "1. Configurare Electron Forge in `forge.config.ts`:\n   - Maker DMG per macOS con notarization\n   - Maker Squirrel per Windows\n   - Maker DEB/RPM per Linux\n2. Bundling Python sidecar:\n   - Opzione A: PyInstaller per creare eseguibile standalone\n   - Opzione B: Embedded Python con venv\n```typescript\n// forge.config.ts\nconst config = {\n  packagerConfig: {\n    extraResource: ['./python-dist'],\n    osxSign: { identity: '...' },\n    osxNotarize: { appleId: '...', appleIdPassword: '...' }\n  },\n  makers: [\n    { name: '@electron-forge/maker-dmg', config: {} },\n    { name: '@electron-forge/maker-squirrel', config: {} },\n  ]\n};\n```\n3. Gestione aggiornamenti automatici con electron-updater\n4. Configurare code signing per macOS e Windows\n5. Setup GitHub Releases per distribuzione\n6. Documentazione installazione per utenti finali\n7. Verificare bundle size target: ~2.5MB (escludendo Python)",
        "testStrategy": "Test build su macOS, Windows, Linux. Test installazione pulita su sistema vergine. Test auto-update flow. Verificare code signing valido.",
        "priority": "low",
        "dependencies": [
          "11",
          "13"
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Configurazione Electron Forge Maker DMG con Notarization macOS",
            "description": "Configurare il maker DMG in forge.config.ts con supporto completo per code signing e notarization Apple, necessario per distribuzione su macOS Sequoia e versioni successive.",
            "dependencies": [],
            "details": "1. Aggiungere MakerDMG alla configurazione in forge.config.ts sostituendo MakerZIP per darwin\n2. Configurare packagerConfig con osxSign:\n   - identity: Developer ID Application certificate\n   - optionsForFile: funzione per configurare entitlements\n3. Configurare osxNotarize con:\n   - appleId: email sviluppatore Apple\n   - appleIdPassword: app-specific password (da Keychain @keychain:AC_PASSWORD)\n   - teamId: Apple Team ID\n4. Creare file entitlements.plist con capabilities necessarie (hardened-runtime, allow-unsigned-executable-memory per Python sidecar)\n5. Configurare environment variables in .env per credenziali Apple (APPLE_ID, APPLE_ID_PASSWORD, APPLE_TEAM_ID)\n6. Testare build locale con `npm run make` e verificare firma con `codesign -dv --verbose=4`\n7. Verificare notarization con `spctl -a -v` e `stapler validate`",
            "status": "pending",
            "testStrategy": "Eseguire build DMG su macOS e verificare: 1) codesign -dv mostra firma valida, 2) spctl -a -v approva l'app, 3) Gatekeeper non blocca l'apertura su sistema pulito, 4) Console.app non mostra errori di notarization.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Configurazione Maker Squirrel Windows con Code Signing Authenticode",
            "description": "Configurare MakerSquirrel per Windows con supporto Authenticode code signing, creazione installer NSIS/Squirrel, e gestione icone e metadata applicazione.",
            "dependencies": [],
            "details": "1. Configurare MakerSquirrel in forge.config.ts con opzioni:\n   - name: nome applicazione senza spazi\n   - authors: nome autore per metadata\n   - exe: nome eseguibile finale\n   - setupIcon: percorso icona .ico\n   - loadingGif: splash screen opzionale\n   - certificateFile: path al certificato .pfx\n   - certificatePassword: password certificato (da env var WINDOWS_CERTIFICATE_PASSWORD)\n2. Creare script PowerShell per signing: `sign-windows.ps1` con signtool.exe\n3. Configurare packagerConfig per Windows:\n   - icon: percorso icona .ico\n   - win32metadata: CompanyName, FileDescription, ProductName\n4. Aggiungere hook afterSign per verifica firma\n5. Creare assets: icon.ico (256x256, 128x128, 64x64, 48x48, 32x32, 16x16)\n6. Configurare environment variables: WINDOWS_CERTIFICATE_FILE, WINDOWS_CERTIFICATE_PASSWORD\n7. Documentare acquisizione certificato Authenticode (DigiCert, Sectigo, etc.)",
            "status": "pending",
            "testStrategy": "Test su Windows: 1) Eseguire build con `npm run make`, 2) Verificare firma con signtool verify /pa, 3) Installare su Windows vergine e verificare UAC non mostri 'publisher sconosciuto', 4) Testare uninstall completo.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Bundling Python Sidecar con PyInstaller Cross-Platform",
            "description": "Creare sistema di bundling per il Python sidecar usando PyInstaller, con build separati per macOS (universal2), Windows (x64), e Linux (x64/arm64), inclusi tutti i moduli Cagent.",
            "dependencies": [],
            "details": "1. Creare python/pyinstaller.spec con configurazione:\n   - Analysis: main.py come entry, hidden imports per FastAPI, uvicorn, sse-starlette, cagent\n   - Exclude: tkinter, matplotlib, test modules per ridurre size\n   - Datas: includere assets e config necessari\n   - hiddenimports: tutti i moduli dinamici di cagent e MCP tools\n2. Creare script build-python.sh / build-python.ps1:\n   - Attivare venv\n   - pip install -r requirements.txt\n   - pyinstaller --onefile --windowed (macOS) / --onefile (Windows/Linux)\n   - Copiare output in ./python-dist/\n3. Configurare forge.config.ts extraResource: ['./python-dist']\n4. Modificare main.ts per trovare sidecar in resources path:\n   - process.resourcesPath per production\n   - __dirname per development\n5. Creare Makefile/package.json scripts per build cross-platform\n6. Target size: ~50MB per sidecar (Python + dipendenze)\n7. Verificare che sidecar parta correttamente da extraResources",
            "status": "pending",
            "testStrategy": "Per ogni piattaforma: 1) Build sidecar con PyInstaller, 2) Eseguire standalone e verificare endpoint /health, 3) Package app Electron e verificare sidecar in Resources, 4) Test avvio app e comunicazione IPC con sidecar, 5) Verificare size finale < 100MB totale.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Implementazione Auto-Update con electron-updater e GitHub Releases",
            "description": "Implementare sistema di aggiornamenti automatici usando electron-updater con backend GitHub Releases, includendo UI per notifiche e progress bar download.",
            "dependencies": [
              1,
              2
            ],
            "details": "1. Installare electron-updater: npm install electron-updater\n2. Configurare forge.config.ts per generare file update:\n   - publishers: GitHubPublisher con repo e owner\n   - packagerConfig.protocols: deep link per update\n3. Implementare in main.ts:\n   - autoUpdater.setFeedURL() con GitHub repo\n   - autoUpdater.checkForUpdatesAndNotify() all'avvio\n   - Eventi: checking-for-update, update-available, update-downloaded, error\n4. Creare IPC handlers per comunicare stato update al renderer:\n   - 'update:check', 'update:download', 'update:install'\n5. Implementare componente Svelte UpdateNotification.svelte:\n   - Banner 'Nuovo aggiornamento disponibile'\n   - Progress bar durante download\n   - Pulsante 'Riavvia e Installa'\n6. Configurare electron-builder.yml / forge publishers per:\n   - Generare latest.yml/latest-mac.yml/latest-linux.yml\n   - Upload automatico assets a GitHub Release\n7. Gestire canali: stable, beta (opzionale)\n8. Implementare rollback in caso di update fallito",
            "status": "pending",
            "testStrategy": "1) Creare release v0.0.2 di test su GitHub, 2) Installare v0.0.1, verificare che rilevi update, 3) Testare download progress in UI, 4) Verificare installazione automatica al riavvio, 5) Testare rollback se update corrotto, 6) Verificare firma codice post-update su macOS/Windows.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Setup GitHub Actions CI/CD Pipeline per Build e Publish Automatico",
            "description": "Creare workflow GitHub Actions per build automatico multi-piattaforma, code signing in CI, upload a GitHub Releases, e gestione versioning semantico.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "1. Creare .github/workflows/build.yml per build su ogni push:\n   - Matrix: macos-latest, windows-latest, ubuntu-latest\n   - Cache node_modules e Python venv\n   - npm ci && npm run make\n   - Upload artifacts per testing\n2. Creare .github/workflows/release.yml trigger su tag v*:\n   - Build per tutte le piattaforme in parallelo\n   - macOS: import certificati da secrets, notarize\n   - Windows: import certificato .pfx da secrets, sign\n   - Linux: build DEB e RPM\n   - Upload tutti gli assets a GitHub Release\n3. Configurare GitHub Secrets:\n   - APPLE_ID, APPLE_ID_PASSWORD, APPLE_TEAM_ID, APPLE_CERTIFICATE_P12, APPLE_CERTIFICATE_PASSWORD\n   - WINDOWS_CERTIFICATE_PFX (base64), WINDOWS_CERTIFICATE_PASSWORD\n4. Creare script release.sh per bump version e tag\n5. Configurare electron-forge publish per GitHub:\n   - GITHUB_TOKEN per upload assets\n6. Aggiungere workflow per PR checks (lint, test, build)\n7. Implementare caching aggressivo per ridurre build time",
            "status": "pending",
            "testStrategy": "1) Push branch feature e verificare build passa su tutte le piattaforme, 2) Creare tag v0.1.0-test e verificare release workflow, 3) Verificare assets uploadati correttamente a GitHub Release, 4) Download e installare su ogni OS per verifica E2E, 5) Verificare code signing valido negli artifacts.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Documentazione Installazione e Troubleshooting per Utenti Finali",
            "description": "Creare documentazione completa per installazione su macOS, Windows e Linux, incluse FAQ, troubleshooting per errori comuni, e guida per sviluppatori che vogliono contribuire.",
            "dependencies": [
              4,
              5
            ],
            "details": "1. Creare docs/installation/README.md con sezioni:\n   - Requisiti di sistema (OS version, RAM, disk space)\n   - Download links per ogni piattaforma\n   - Istruzioni passo-passo con screenshot\n2. Creare docs/installation/macos.md:\n   - Gestione Gatekeeper ('app da sviluppatore non identificato')\n   - Permessi Privacy: Accessibilità, Full Disk Access se necessari\n   - Troubleshooting notarization issues\n3. Creare docs/installation/windows.md:\n   - SmartScreen warning per prime esecuzioni\n   - Windows Defender exceptions se necessario\n   - Installazione silente con parametri CLI\n4. Creare docs/installation/linux.md:\n   - Istruzioni per DEB (apt), RPM (yum/dnf), AppImage\n   - Permessi e dipendenze (libsecret per keychain)\n5. Creare docs/troubleshooting.md:\n   - Errori comuni e soluzioni\n   - Come raccogliere logs (Console.app, Event Viewer, journalctl)\n   - Come segnalare bug con template issue\n6. Creare CHANGELOG.md template per release notes\n7. Aggiornare README.md principale con quick start",
            "status": "pending",
            "testStrategy": "1) Far seguire la guida a utente non tecnico su ogni OS, 2) Verificare che tutti i link di download funzionino, 3) Testare ogni scenario di troubleshooting documentato, 4) Review da parte di QA per completezza, 5) Verificare rendering corretto su GitHub.",
            "parentId": "undefined"
          }
        ],
        "tags": [
          "infrastructure",
          "deployment",
          "phase-5-polish",
          "electron"
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Configurazione Electron Forge Maker DMG con notarization macOS, 2) Configurazione Maker Squirrel Windows con code signing Authenticode, 3) Bundling Python sidecar con PyInstaller cross-platform, 4) Implementazione auto-update con electron-updater e GitHub Releases, 5) Setup GitHub Releases e CI/CD pipeline per publish automatico, 6) Documentazione installazione e troubleshooting per utenti finali"
      },
      {
        "id": 15,
        "title": "Integrazione Docker MCP Gateway per Gestione Centralizzata Tool MCP",
        "description": "Implementare l'integrazione con Docker MCP Gateway per la gestione centralizzata dei tool MCP, includendo detection di Docker Engine, auto-installazione del plugin CLI Gateway, UI Settings per toggle Cloud/Local per-tool, e generazione dinamica cagent.yaml con fallback chain intelligente.",
        "details": "## Struttura File\n\n```\nelectron/\n├── docker-detector.ts          # Detection Docker Engine\n├── mcp-gateway-installer.ts    # Auto-install CLI plugin\n└── ipc-handlers.ts             # Estensione con handler Docker/Gateway\n\nsrc/lib/\n├── services/\n│   ├── docker-gateway.ts       # Client per Docker MCP Gateway\n│   └── mcp-mode-manager.ts     # Gestione modalità Cloud/Local\n├── stores/\n│   └── mcp-settings.svelte.ts  # Store Svelte 5 per settings MCP\n└── components/custom/\n    └── MCPToolToggle.svelte    # Toggle per-tool Cloud/Local\n\npython/\n└── tools/\n    └── mcp_resolver.py         # Risoluzione dinamica ref MCP\n```\n\n## 1. Docker Engine Detection (`electron/docker-detector.ts`)\n\n```typescript\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\nexport interface DockerStatus {\n  isInstalled: boolean;\n  isRunning: boolean;\n  version: string | null;\n  isDesktop: boolean;  // true = Desktop, false = Engine only\n  gatewayInstalled: boolean;\n  gatewayVersion: string | null;\n}\n\nexport async function detectDocker(): Promise<DockerStatus> {\n  const status: DockerStatus = {\n    isInstalled: false,\n    isRunning: false,\n    version: null,\n    isDesktop: false,\n    gatewayInstalled: false,\n    gatewayVersion: null\n  };\n\n  try {\n    // Check docker info (verifica sia installazione che running)\n    const { stdout } = await execAsync('docker info --format \"{{.ServerVersion}}\"', {\n      timeout: 5000\n    });\n    status.isInstalled = true;\n    status.isRunning = true;\n    status.version = stdout.trim();\n\n    // Detect if Docker Desktop (check for Desktop-specific indicators)\n    const { stdout: infoFull } = await execAsync('docker info', { timeout: 5000 });\n    status.isDesktop = infoFull.includes('Docker Desktop') || \n                       infoFull.includes('desktop-linux');\n\n    // Check MCP Gateway plugin\n    await checkGatewayPlugin(status);\n  } catch (error) {\n    // docker command exists ma daemon non running\n    try {\n      await execAsync('docker --version');\n      status.isInstalled = true;\n    } catch {\n      status.isInstalled = false;\n    }\n  }\n\n  return status;\n}\n\nasync function checkGatewayPlugin(status: DockerStatus): Promise<void> {\n  try {\n    const { stdout } = await execAsync('docker mcp --version', { timeout: 3000 });\n    status.gatewayInstalled = true;\n    status.gatewayVersion = stdout.trim();\n  } catch {\n    status.gatewayInstalled = false;\n  }\n}\n```\n\n## 2. MCP Gateway Auto-Installer (`electron/mcp-gateway-installer.ts`)\n\n```typescript\nimport { app } from 'electron';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\nimport * as https from 'https';\nimport { createWriteStream } from 'fs';\n\nconst GATEWAY_RELEASES_URL = 'https://api.github.com/repos/docker/mcp-gateway/releases/latest';\n\ninterface ReleaseAsset {\n  name: string;\n  browser_download_url: string;\n}\n\nexport async function installMCPGateway(): Promise<{ success: boolean; error?: string }> {\n  try {\n    // 1. Fetch latest release info\n    const releaseInfo = await fetchLatestRelease();\n    \n    // 2. Determine platform-specific binary\n    const platform = process.platform;\n    const arch = process.arch === 'arm64' ? 'arm64' : 'amd64';\n    const binaryName = `docker-mcp-${platform === 'darwin' ? 'darwin' : 'linux'}-${arch}`;\n    \n    const asset = releaseInfo.assets.find((a: ReleaseAsset) => a.name === binaryName);\n    if (!asset) {\n      return { success: false, error: `Binary non trovato per ${platform}-${arch}` };\n    }\n\n    // 3. Download binary\n    const cliPluginsDir = path.join(process.env.HOME || '', '.docker', 'cli-plugins');\n    await fs.mkdir(cliPluginsDir, { recursive: true });\n    \n    const destPath = path.join(cliPluginsDir, 'docker-mcp');\n    await downloadFile(asset.browser_download_url, destPath);\n    \n    // 4. Make executable\n    await fs.chmod(destPath, 0o755);\n\n    return { success: true };\n  } catch (error) {\n    return { success: false, error: String(error) };\n  }\n}\n\nasync function fetchLatestRelease(): Promise<{ assets: ReleaseAsset[] }> {\n  return new Promise((resolve, reject) => {\n    https.get(GATEWAY_RELEASES_URL, { \n      headers: { 'User-Agent': 'Trae-Extractor-App' } \n    }, (res) => {\n      let data = '';\n      res.on('data', chunk => data += chunk);\n      res.on('end', () => resolve(JSON.parse(data)));\n    }).on('error', reject);\n  });\n}\n\nasync function downloadFile(url: string, dest: string): Promise<void> {\n  return new Promise((resolve, reject) => {\n    const file = createWriteStream(dest);\n    https.get(url, { headers: { 'User-Agent': 'Trae-Extractor-App' } }, (res) => {\n      // Handle redirects\n      if (res.statusCode === 302 && res.headers.location) {\n        https.get(res.headers.location, (redirectRes) => {\n          redirectRes.pipe(file);\n          file.on('finish', () => { file.close(); resolve(); });\n        }).on('error', reject);\n      } else {\n        res.pipe(file);\n        file.on('finish', () => { file.close(); resolve(); });\n      }\n    }).on('error', reject);\n  });\n}\n\nexport async function enableGatewayServer(serverName: string): Promise<boolean> {\n  const { exec } = require('child_process');\n  return new Promise((resolve) => {\n    exec(`docker mcp server enable ${serverName}`, (error: Error | null) => {\n      resolve(!error);\n    });\n  });\n}\n```\n\n## 3. UI Settings Toggle (`src/lib/components/custom/MCPToolToggle.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { Switch } from '$lib/components/ui/switch';\n  import { Label } from '$lib/components/ui/label';\n  import { Badge } from '$lib/components/ui/badge';\n  import { mcpSettings } from '$lib/stores/mcp-settings.svelte';\n  \n  interface Props {\n    toolId: string;\n    toolName: string;\n    description: string;\n    supportsGateway: boolean;\n  }\n  \n  let { toolId, toolName, description, supportsGateway }: Props = $props();\n  \n  const dockerStatus = $derived(mcpSettings.dockerStatus);\n  const toolMode = $derived(mcpSettings.getToolMode(toolId));\n  const canUseGateway = $derived(\n    supportsGateway && \n    dockerStatus.isRunning && \n    dockerStatus.gatewayInstalled\n  );\n  \n  function toggleMode() {\n    if (!canUseGateway) return;\n    mcpSettings.setToolMode(toolId, toolMode === 'gateway' ? 'local' : 'gateway');\n  }\n</script>\n\n<div class=\"flex items-center justify-between p-4 border rounded-lg\">\n  <div class=\"space-y-1\">\n    <div class=\"flex items-center gap-2\">\n      <Label class=\"text-base font-medium\">{toolName}</Label>\n      {#if toolMode === 'gateway'}\n        <Badge variant=\"secondary\">Cloud</Badge>\n      {:else}\n        <Badge variant=\"outline\">Local</Badge>\n      {/if}\n    </div>\n    <p class=\"text-sm text-muted-foreground\">{description}</p>\n    {#if !canUseGateway && supportsGateway}\n      <p class=\"text-xs text-yellow-600\">\n        {#if !dockerStatus.isRunning}\n          Docker non attivo - usando modalità locale\n        {:else if !dockerStatus.gatewayInstalled}\n          MCP Gateway non installato\n        {/if}\n      </p>\n    {/if}\n  </div>\n  \n  <Switch \n    checked={toolMode === 'gateway'}\n    disabled={!canUseGateway}\n    onCheckedChange={toggleMode}\n  />\n</div>\n```\n\n## 4. MCP Settings Store (`src/lib/stores/mcp-settings.svelte.ts`)\n\n```typescript\nimport { writable } from 'svelte/store';\n\ninterface DockerStatus {\n  isInstalled: boolean;\n  isRunning: boolean;\n  gatewayInstalled: boolean;\n  gatewayVersion: string | null;\n}\n\ntype ToolMode = 'gateway' | 'local';\n\ninterface MCPToolConfig {\n  mode: ToolMode;\n  gatewayRef: string;    // es: 'mcp/cloudinary'\n  localRef: string;      // es: 'npx @cloudinary/mcp-server'\n  envVars: string[];     // es: ['CLOUDINARY_URL']\n}\n\nconst SUPPORTED_TOOLS: Record<string, MCPToolConfig> = {\n  cloudinary: {\n    mode: 'gateway',\n    gatewayRef: 'mcp/cloudinary',\n    localRef: 'npx @cloudinary/mcp-server',\n    envVars: ['CLOUDINARY_URL']\n  },\n  duckduckgo: {\n    mode: 'gateway',\n    gatewayRef: 'mcp/duckduckgo',\n    localRef: 'npx @anthropics/duckduckgo-mcp-server',\n    envVars: []\n  }\n};\n\nfunction createMCPSettingsStore() {\n  let dockerStatus = $state<DockerStatus>({\n    isInstalled: false,\n    isRunning: false,\n    gatewayInstalled: false,\n    gatewayVersion: null\n  });\n  \n  let toolModes = $state<Record<string, ToolMode>>({\n    cloudinary: 'gateway',\n    duckduckgo: 'gateway'\n  });\n\n  return {\n    get dockerStatus() { return dockerStatus; },\n    get toolModes() { return toolModes; },\n    \n    setDockerStatus(status: DockerStatus) {\n      dockerStatus = status;\n    },\n    \n    getToolMode(toolId: string): ToolMode {\n      return toolModes[toolId] ?? 'local';\n    },\n    \n    setToolMode(toolId: string, mode: ToolMode) {\n      toolModes[toolId] = mode;\n      // Trigger cagent.yaml regeneration\n      window.electronAPI?.regenerateCagentConfig();\n    },\n    \n    getToolRef(toolId: string): string {\n      const config = SUPPORTED_TOOLS[toolId];\n      if (!config) return '';\n      \n      const mode = this.getToolMode(toolId);\n      if (mode === 'gateway' && dockerStatus.isRunning && dockerStatus.gatewayInstalled) {\n        return config.gatewayRef;\n      }\n      return config.localRef;\n    },\n    \n    async refreshDockerStatus() {\n      const status = await window.electronAPI?.detectDocker();\n      if (status) this.setDockerStatus(status);\n    }\n  };\n}\n\nexport const mcpSettings = createMCPSettingsStore();\n```\n\n## 5. Generazione Dinamica cagent.yaml (Estensione `src/lib/services/cagent-config.ts`)\n\n```typescript\n// Aggiungere alla funzione generateCagentYaml esistente (Task 5)\n\ninterface MCPToolsetConfig {\n  type: 'mcp';\n  ref: string;\n  env?: Record<string, string>;\n}\n\nexport function generateMCPToolsets(\n  toolModes: Record<string, ToolMode>,\n  dockerStatus: DockerStatus\n): MCPToolsetConfig[] {\n  const toolsets: MCPToolsetConfig[] = [];\n  \n  for (const [toolId, mode] of Object.entries(toolModes)) {\n    const config = SUPPORTED_TOOLS[toolId];\n    if (!config) continue;\n    \n    const useGateway = mode === 'gateway' && \n                       dockerStatus.isRunning && \n                       dockerStatus.gatewayInstalled;\n    \n    toolsets.push({\n      type: 'mcp',\n      ref: useGateway ? config.gatewayRef : config.localRef,\n      env: config.envVars.reduce((acc, envVar) => {\n        acc[envVar] = `\\${${envVar}}`;  // Placeholder per env vars\n        return acc;\n      }, {} as Record<string, string>)\n    });\n  }\n  \n  return toolsets;\n}\n```\n\n## 6. Fallback Chain Implementation (`python/tools/mcp_resolver.py`)\n\n```python\nimport subprocess\nimport asyncio\nfrom typing import Optional, Tuple\nfrom dataclasses import dataclass\nfrom enum import Enum\n\nclass MCPMode(Enum):\n    GATEWAY = \"gateway\"\n    LOCAL = \"local\"\n    ERROR = \"error\"\n\n@dataclass\nclass MCPResolution:\n    mode: MCPMode\n    ref: str\n    error_message: Optional[str] = None\n\nclass MCPResolver:\n    \"\"\"Risolve il modo MCP con fallback chain: Gateway → Local → Error\"\"\"\n    \n    def __init__(self, tool_id: str, gateway_ref: str, local_ref: str):\n        self.tool_id = tool_id\n        self.gateway_ref = gateway_ref\n        self.local_ref = local_ref\n    \n    async def resolve(self, preferred_mode: str = \"gateway\") -> MCPResolution:\n        \"\"\"\n        Fallback chain:\n        1. Se preferred_mode == gateway: prova Gateway, fallback a Local\n        2. Se preferred_mode == local: usa direttamente Local\n        3. Se tutto fallisce: Error con istruzioni\n        \"\"\"\n        if preferred_mode == \"gateway\":\n            # Try Gateway first\n            gateway_ok = await self._check_gateway()\n            if gateway_ok:\n                return MCPResolution(MCPMode.GATEWAY, self.gateway_ref)\n            \n            # Fallback to Local\n            local_ok = await self._check_local()\n            if local_ok:\n                return MCPResolution(MCPMode.LOCAL, self.local_ref)\n        else:\n            # Direct Local mode\n            local_ok = await self._check_local()\n            if local_ok:\n                return MCPResolution(MCPMode.LOCAL, self.local_ref)\n        \n        # Error state\n        return MCPResolution(\n            MCPMode.ERROR,\n            \"\",\n            error_message=self._generate_error_instructions()\n        )\n    \n    async def _check_gateway(self) -> bool:\n        \"\"\"Verifica se Docker MCP Gateway è disponibile\"\"\"\n        try:\n            proc = await asyncio.create_subprocess_exec(\n                'docker', 'mcp', 'server', 'list',\n                stdout=asyncio.subprocess.PIPE,\n                stderr=asyncio.subprocess.PIPE\n            )\n            await proc.wait()\n            return proc.returncode == 0\n        except Exception:\n            return False\n    \n    async def _check_local(self) -> bool:\n        \"\"\"Verifica se il tool locale è disponibile\"\"\"\n        try:\n            # Check if npx command would work\n            proc = await asyncio.create_subprocess_exec(\n                'which', 'npx',\n                stdout=asyncio.subprocess.PIPE\n            )\n            await proc.wait()\n            return proc.returncode == 0\n        except Exception:\n            return False\n    \n    def _generate_error_instructions(self) -> str:\n        return f\"\"\"\nTool MCP '{self.tool_id}' non disponibile.\n\nPer risolvere:\n\nOPZIONE 1 - Docker MCP Gateway (consigliato):\n  1. Installa Docker Engine: https://docs.docker.com/engine/install/\n  2. Avvia Docker: `sudo systemctl start docker` o avvia Docker Desktop\n  3. Installa MCP Gateway: Settings > Tools > Installa Gateway\n\nOPZIONE 2 - Modalità Locale:\n  1. Assicurati che Node.js sia installato\n  2. Configura le API keys in Settings > Providers\n  3. Il tool verrà eseguito via npx: {self.local_ref}\n\"\"\"\n```\n\n## 7. IPC Handlers Estensione (`electron/ipc-handlers.ts`)\n\n```typescript\n// Aggiungere ai handler esistenti\n\nimport { detectDocker } from './docker-detector';\nimport { installMCPGateway, enableGatewayServer } from './mcp-gateway-installer';\n\nexport function registerDockerHandlers(ipcMain: Electron.IpcMain) {\n  ipcMain.handle('docker:detect', async () => {\n    return await detectDocker();\n  });\n  \n  ipcMain.handle('docker:install-gateway', async () => {\n    return await installMCPGateway();\n  });\n  \n  ipcMain.handle('docker:enable-server', async (_, serverName: string) => {\n    return await enableGatewayServer(serverName);\n  });\n  \n  ipcMain.handle('docker:start-gateway', async () => {\n    const { exec } = require('child_process');\n    return new Promise((resolve) => {\n      exec('docker mcp gateway run --detach', (error: Error | null) => {\n        resolve(!error);\n      });\n    });\n  });\n}\n```\n\n## 8. Settings Page Integration (`src/routes/settings/tools/+page.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { onMount } from 'svelte';\n  import { Button } from '$lib/components/ui/button';\n  import { Card, CardContent, CardHeader, CardTitle } from '$lib/components/ui/card';\n  import { Alert, AlertDescription } from '$lib/components/ui/alert';\n  import MCPToolToggle from '$lib/components/custom/MCPToolToggle.svelte';\n  import { mcpSettings } from '$lib/stores/mcp-settings.svelte';\n  \n  let installing = $state(false);\n  let installError = $state<string | null>(null);\n  \n  const dockerStatus = $derived(mcpSettings.dockerStatus);\n  \n  onMount(() => {\n    mcpSettings.refreshDockerStatus();\n  });\n  \n  async function installGateway() {\n    installing = true;\n    installError = null;\n    \n    const result = await window.electronAPI.installMCPGateway();\n    if (result.success) {\n      await mcpSettings.refreshDockerStatus();\n    } else {\n      installError = result.error ?? 'Installazione fallita';\n    }\n    \n    installing = false;\n  }\n</script>\n\n<div class=\"space-y-6\">\n  <Card>\n    <CardHeader>\n      <CardTitle>Docker MCP Gateway</CardTitle>\n    </CardHeader>\n    <CardContent class=\"space-y-4\">\n      <div class=\"flex items-center justify-between\">\n        <div>\n          <p class=\"font-medium\">Stato Docker Engine</p>\n          <p class=\"text-sm text-muted-foreground\">\n            {#if dockerStatus.isRunning}\n              ✅ Docker attivo (v{dockerStatus.version})\n            {:else if dockerStatus.isInstalled}\n              ⚠️ Docker installato ma non attivo\n            {:else}\n              ❌ Docker non installato\n            {/if}\n          </p>\n        </div>\n      </div>\n      \n      <div class=\"flex items-center justify-between\">\n        <div>\n          <p class=\"font-medium\">MCP Gateway Plugin</p>\n          <p class=\"text-sm text-muted-foreground\">\n            {#if dockerStatus.gatewayInstalled}\n              ✅ Installato (v{dockerStatus.gatewayVersion})\n            {:else}\n              ❌ Non installato\n            {/if}\n          </p>\n        </div>\n        {#if !dockerStatus.gatewayInstalled && dockerStatus.isRunning}\n          <Button onclick={installGateway} disabled={installing}>\n            {installing ? 'Installazione...' : 'Installa Gateway'}\n          </Button>\n        {/if}\n      </div>\n      \n      {#if installError}\n        <Alert variant=\"destructive\">\n          <AlertDescription>{installError}</AlertDescription>\n        </Alert>\n      {/if}\n    </CardContent>\n  </Card>\n  \n  <Card>\n    <CardHeader>\n      <CardTitle>Configurazione Tool MCP</CardTitle>\n    </CardHeader>\n    <CardContent class=\"space-y-4\">\n      <MCPToolToggle\n        toolId=\"cloudinary\"\n        toolName=\"Cloudinary\"\n        description=\"Background removal, upscale, auto-crop\"\n        supportsGateway={true}\n      />\n      <MCPToolToggle\n        toolId=\"duckduckgo\"\n        toolName=\"DuckDuckGo Search\"\n        description=\"Web search senza API key\"\n        supportsGateway={true}\n      />\n    </CardContent>\n  </Card>\n</div>\n```\n\n## Note Implementative\n\n1. **Docker Engine vs Desktop**: Il codice usa `docker info` che funziona sia con Engine che Desktop. Il flag `isDesktop` è informativo ma non bloccante.\n\n2. **Sicurezza download**: Il download del binary Gateway usa HTTPS e verifica il redirect di GitHub releases.\n\n3. **Fallback automatico**: La chain Gateway → Local → Error è implementata sia lato UI (disabilita toggle) che lato Python (runtime resolution).\n\n4. **Regenerazione cagent.yaml**: Ogni cambio di modalità triggera la rigenerazione del file config tramite IPC.\n\n5. **Tool supportati iniziali**: Cloudinary e DuckDuckGo come da specifiche, facilmente estendibile aggiungendo entry a `SUPPORTED_TOOLS`.",
        "testStrategy": "## Test Unitari TypeScript\n\n1. **test/docker-detector.test.ts**\n   - Test detectDocker() con mock exec che simula Docker running\n   - Test detectDocker() con mock exec che simula Docker non installato\n   - Test detectDocker() con mock exec che simula daemon non running\n   - Test checkGatewayPlugin() con Gateway installato/non installato\n   - Test timeout handling per comandi docker lenti\n\n2. **test/mcp-gateway-installer.test.ts**\n   - Test fetchLatestRelease() con mock GitHub API response\n   - Test downloadFile() con mock HTTPS e redirect handling\n   - Test installMCPGateway() su diverse piattaforme (darwin-arm64, darwin-amd64, linux-amd64)\n   - Test gestione errori per download falliti o permessi file\n\n3. **test/mcp-settings.svelte.test.ts**\n   - Test getToolRef() ritorna gateway ref quando Docker è attivo\n   - Test getToolRef() fallback a local ref quando Docker non disponibile\n   - Test setToolMode() persiste correttamente le preferenze\n   - Test refreshDockerStatus() aggiorna lo stato correttamente\n\n## Test Unitari Python\n\n4. **tests/test_mcp_resolver.py**\n   - Test resolve() con Gateway disponibile → ritorna GATEWAY mode\n   - Test resolve() con Gateway fallito → fallback a LOCAL mode\n   - Test resolve() con tutto fallito → ritorna ERROR con istruzioni\n   - Test _check_gateway() con subprocess mock\n   - Test _check_local() verifica presenza npx\n   - Test _generate_error_instructions() formato corretto\n\n## Test Integrazione\n\n5. **test/integration/docker-gateway.test.ts**\n   - Test E2E flusso completo: detect → install → enable server\n   - Test IPC handlers docker:detect, docker:install-gateway\n   - Test regenerateCagentConfig triggera correttamente la rigenerazione\n\n6. **test/integration/settings-ui.test.ts**\n   - Test rendering pagina settings/tools con Playwright\n   - Test toggle Cloud/Local aggiorna store\n   - Test bottone \"Installa Gateway\" appare quando Docker attivo ma Gateway mancante\n   - Test alert errore appare su installazione fallita\n\n## Test E2E\n\n7. **e2e/mcp-gateway-workflow.test.ts**\n   - Test workflow completo: apertura Settings → Tools → toggle tool → verifica cagent.yaml aggiornato\n   - Test fallback visuale: disabilita toggle quando Docker non disponibile\n   - Test messaggio errore user-friendly quando nessun backend disponibile\n\n## Verifiche Manuali\n\n8. **Checklist manuale**\n   - [ ] Su macOS con Docker Engine: `docker info` funziona\n   - [ ] Su macOS senza Docker: app mostra stato \"non installato\"\n   - [ ] Download Gateway da GitHub releases completa correttamente\n   - [ ] Binary ha permessi esecuzione (755) dopo installazione\n   - [ ] `docker mcp --version` funziona dopo installazione\n   - [ ] Toggle Cloud/Local persiste dopo restart app\n   - [ ] cagent.yaml contiene ref corretti ('mcp/cloudinary' vs 'npx @cloudinary/mcp-server')\n   - [ ] Fallback chain funziona runtime (Gateway down → usa Local)",
        "status": "pending",
        "dependencies": [
          "2",
          "4",
          "5",
          "7"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 8,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Setup Unix socket server Python con JSON-RPC 2.0, 2) Implementazione path validator con whitelist directory per export sicuro, 3) Wrapper PhotosService per osxphotos con metadata extraction, 4) Network blocking via monkey-patching socket per isolamento, 5) Supervisor TypeScript con circuit breaker e auto-restart, 6) IPC handlers per comunicazione con processo sandboxed"
      },
      {
        "id": 16,
        "title": "Alternativa Locale per Media Processing Privacy-First",
        "description": "Implementare un sistema di elaborazione media locale come alternativa privacy-first a Cloudinary, includendo background removal con rembg, upscaling con Real-ESRGAN, e smart crop con OpenCV, con UI toggle nelle settings e fallback chain intelligente.",
        "details": "## Struttura Directory\n\n```\npython/\n├── local_media/\n│   ├── __init__.py\n│   ├── background_remover.py      # Wrapper rembg (U2-Net)\n│   ├── upscaler.py                # Wrapper Real-ESRGAN\n│   ├── smart_cropper.py           # OpenCV + face detection\n│   ├── model_manager.py           # Download on-demand modelli\n│   └── processor.py               # Orchestrator locale\nsrc/lib/\n├── services/\n│   └── local-media-processor.ts   # Client TypeScript per sidecar\n├── stores/\n│   └── media-processing-settings.svelte.ts  # Store Svelte 5 runes\n└── components/custom/\n    └── MediaProcessingToggle.svelte  # UI toggle settings\nelectron/\n└── model-downloader.ts            # Download manager con progress\n```\n\n## 1. Background Removal (`background_remover.py`)\n\n```python\nfrom rembg import remove\nfrom PIL import Image\nimport io\nfrom typing import Optional\n\nclass BackgroundRemover:\n    \"\"\"Background removal usando rembg con U2-Net model (~90% accuratezza Cloudinary)\"\"\"\n    \n    def __init__(self):\n        # rembg scarica automaticamente u2net.onnx (~168MB) al primo uso\n        self._model_name = \"u2net\"\n    \n    async def remove_background(\n        self, \n        image_bytes: bytes,\n        alpha_matting: bool = False,\n        alpha_matting_foreground_threshold: int = 240,\n        alpha_matting_background_threshold: int = 10\n    ) -> bytes:\n        \"\"\"\n        Rimuove lo sfondo dall'immagine.\n        \n        Args:\n            image_bytes: Bytes dell'immagine input\n            alpha_matting: Abilita alpha matting per bordi più smooth\n            \n        Returns:\n            Bytes dell'immagine PNG con sfondo trasparente\n        \"\"\"\n        try:\n            input_image = Image.open(io.BytesIO(image_bytes))\n            output_image = remove(\n                input_image,\n                alpha_matting=alpha_matting,\n                alpha_matting_foreground_threshold=alpha_matting_foreground_threshold,\n                alpha_matting_background_threshold=alpha_matting_background_threshold\n            )\n            \n            output_buffer = io.BytesIO()\n            output_image.save(output_buffer, format=\"PNG\")\n            return output_buffer.getvalue()\n            \n        except Exception as e:\n            raise LocalProcessingError(f\"Background removal failed: {e}\")\n```\n\n## 2. Upscaling (`upscaler.py`)\n\n```python\nfrom pathlib import Path\nimport numpy as np\nfrom PIL import Image\nimport io\nfrom typing import Literal\nfrom .model_manager import ModelManager\n\nclass Upscaler:\n    \"\"\"Super-resolution con Real-ESRGAN (x2, x4 scale)\"\"\"\n    \n    MODELS = {\n        \"x2\": {\n            \"name\": \"RealESRGAN_x2plus.pth\",\n            \"url\": \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.1/RealESRGAN_x2plus.pth\",\n            \"size_mb\": 64\n        },\n        \"x4\": {\n            \"name\": \"RealESRGAN_x4plus.pth\",\n            \"url\": \"https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\",\n            \"size_mb\": 64\n        }\n    }\n    \n    def __init__(self, model_manager: ModelManager):\n        self._model_manager = model_manager\n        self._loaded_models = {}\n    \n    async def ensure_model(self, scale: Literal[\"x2\", \"x4\"]) -> Path:\n        \"\"\"Scarica modello se non presente (download on-demand)\"\"\"\n        model_info = self.MODELS[scale]\n        return await self._model_manager.ensure_model(\n            model_info[\"name\"],\n            model_info[\"url\"],\n            model_info[\"size_mb\"]\n        )\n    \n    async def upscale(\n        self, \n        image_bytes: bytes, \n        scale: Literal[\"x2\", \"x4\"] = \"x2\"\n    ) -> bytes:\n        \"\"\"\n        Upscale immagine con Real-ESRGAN.\n        \n        Args:\n            image_bytes: Bytes dell'immagine input\n            scale: Fattore di upscaling (\"x2\" o \"x4\")\n            \n        Returns:\n            Bytes dell'immagine upscalata\n        \"\"\"\n        from basicsr.archs.rrdbnet_arch import RRDBNet\n        from realesrgan import RealESRGANer\n        \n        model_path = await self.ensure_model(scale)\n        \n        # Configurazione modello\n        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, \n                       num_block=23, num_grow_ch=32, scale=int(scale[1]))\n        \n        upsampler = RealESRGANer(\n            scale=int(scale[1]),\n            model_path=str(model_path),\n            model=model,\n            tile=0,  # 0 = no tiling, usa più memoria ma più veloce\n            tile_pad=10,\n            pre_pad=0,\n            half=False  # True per GPU con supporto FP16\n        )\n        \n        # Process\n        img = Image.open(io.BytesIO(image_bytes))\n        img_array = np.array(img)\n        output, _ = upsampler.enhance(img_array, outscale=int(scale[1]))\n        \n        output_buffer = io.BytesIO()\n        Image.fromarray(output).save(output_buffer, format=\"PNG\", quality=95)\n        return output_buffer.getvalue()\n```\n\n## 3. Smart Crop (`smart_cropper.py`)\n\n```python\nimport cv2\nimport numpy as np\nfrom PIL import Image\nimport io\nfrom typing import Tuple, Optional\n\nclass SmartCropper:\n    \"\"\"Smart crop con face detection (fallback: center crop)\"\"\"\n    \n    def __init__(self):\n        # Carica Haar cascade per face detection\n        self._face_cascade = cv2.CascadeClassifier(\n            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n        )\n    \n    def _detect_faces(self, img_array: np.ndarray) -> list:\n        \"\"\"Rileva volti nell'immagine\"\"\"\n        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n        faces = self._face_cascade.detectMultiScale(\n            gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30)\n        )\n        return faces\n    \n    def _calculate_focus_point(\n        self, \n        img_shape: Tuple[int, int], \n        faces: list\n    ) -> Tuple[int, int]:\n        \"\"\"Calcola punto focale basato su volti rilevati\"\"\"\n        if len(faces) == 0:\n            # Fallback: center\n            return img_shape[1] // 2, img_shape[0] // 2\n        \n        # Centro pesato dei volti\n        total_weight = 0\n        cx, cy = 0, 0\n        for (x, y, w, h) in faces:\n            weight = w * h  # Peso = area del volto\n            cx += (x + w/2) * weight\n            cy += (y + h/2) * weight\n            total_weight += weight\n        \n        return int(cx / total_weight), int(cy / total_weight)\n    \n    async def smart_crop(\n        self, \n        image_bytes: bytes,\n        target_width: int,\n        target_height: int,\n        gravity: Optional[str] = None  # \"face\", \"center\", \"auto\"\n    ) -> bytes:\n        \"\"\"\n        Smart crop con rilevamento automatico punto focale.\n        \n        Args:\n            image_bytes: Bytes dell'immagine input\n            target_width: Larghezza target\n            target_height: Altezza target\n            gravity: \"face\" (usa face detection), \"center\", \"auto\" (face con fallback center)\n            \n        Returns:\n            Bytes dell'immagine croppata\n        \"\"\"\n        img = Image.open(io.BytesIO(image_bytes))\n        img_array = np.array(img)\n        \n        orig_h, orig_w = img_array.shape[:2]\n        \n        # Determina punto focale\n        if gravity == \"center\":\n            focus_x, focus_y = orig_w // 2, orig_h // 2\n        else:  # \"face\" o \"auto\"\n            faces = self._detect_faces(img_array)\n            focus_x, focus_y = self._calculate_focus_point(img_array.shape, faces)\n        \n        # Calcola crop box mantenendo aspect ratio\n        target_ratio = target_width / target_height\n        orig_ratio = orig_w / orig_h\n        \n        if orig_ratio > target_ratio:\n            # Immagine più larga: crop orizzontale\n            new_w = int(orig_h * target_ratio)\n            new_h = orig_h\n        else:\n            # Immagine più alta: crop verticale\n            new_w = orig_w\n            new_h = int(orig_w / target_ratio)\n        \n        # Centro crop sul punto focale\n        left = max(0, min(focus_x - new_w // 2, orig_w - new_w))\n        top = max(0, min(focus_y - new_h // 2, orig_h - new_h))\n        \n        cropped = img.crop((left, top, left + new_w, top + new_h))\n        resized = cropped.resize((target_width, target_height), Image.LANCZOS)\n        \n        output_buffer = io.BytesIO()\n        resized.save(output_buffer, format=\"PNG\")\n        return output_buffer.getvalue()\n```\n\n## 4. Model Manager (`model_manager.py`)\n\n```python\nfrom pathlib import Path\nimport aiohttp\nimport asyncio\nfrom typing import Callable, Optional\n\nclass ModelManager:\n    \"\"\"Gestisce download on-demand dei modelli ML (~100MB per modello)\"\"\"\n    \n    def __init__(self, models_dir: Path):\n        self.models_dir = models_dir\n        self.models_dir.mkdir(parents=True, exist_ok=True)\n        self._download_callbacks: list[Callable] = []\n    \n    def on_download_progress(self, callback: Callable[[str, float], None]):\n        \"\"\"Registra callback per progress download\"\"\"\n        self._download_callbacks.append(callback)\n    \n    async def ensure_model(\n        self, \n        name: str, \n        url: str, \n        expected_size_mb: int\n    ) -> Path:\n        \"\"\"Scarica modello se non presente, ritorna path\"\"\"\n        model_path = self.models_dir / name\n        \n        if model_path.exists():\n            return model_path\n        \n        # Download con progress\n        async with aiohttp.ClientSession() as session:\n            async with session.get(url) as response:\n                total = int(response.headers.get('content-length', 0))\n                downloaded = 0\n                \n                with open(model_path, 'wb') as f:\n                    async for chunk in response.content.iter_chunked(8192):\n                        f.write(chunk)\n                        downloaded += len(chunk)\n                        progress = downloaded / total if total else 0\n                        for cb in self._download_callbacks:\n                            cb(name, progress)\n        \n        return model_path\n```\n\n## 5. Local Processor Orchestrator (`processor.py`)\n\n```python\nfrom typing import Literal, Optional\nfrom .background_remover import BackgroundRemover\nfrom .upscaler import Upscaler\nfrom .smart_cropper import SmartCropper\nfrom .model_manager import ModelManager\n\nclass LocalMediaProcessor:\n    \"\"\"Orchestrator per processing media locale\"\"\"\n    \n    def __init__(self, models_dir: Path):\n        self.model_manager = ModelManager(models_dir)\n        self.bg_remover = BackgroundRemover()\n        self.upscaler = Upscaler(self.model_manager)\n        self.cropper = SmartCropper()\n    \n    async def process(\n        self,\n        image_bytes: bytes,\n        operations: list[dict]\n    ) -> bytes:\n        \"\"\"\n        Applica sequenza di operazioni.\n        \n        Args:\n            image_bytes: Bytes immagine input\n            operations: Lista di operazioni es. [\n                {\"type\": \"remove_bg\"},\n                {\"type\": \"upscale\", \"scale\": \"x2\"},\n                {\"type\": \"crop\", \"width\": 1080, \"height\": 1080, \"gravity\": \"face\"}\n            ]\n            \n        Returns:\n            Bytes immagine processata\n        \"\"\"\n        result = image_bytes\n        \n        for op in operations:\n            op_type = op[\"type\"]\n            \n            if op_type == \"remove_bg\":\n                result = await self.bg_remover.remove_background(result)\n            elif op_type == \"upscale\":\n                result = await self.upscaler.upscale(result, op.get(\"scale\", \"x2\"))\n            elif op_type == \"crop\":\n                result = await self.cropper.smart_crop(\n                    result,\n                    op[\"width\"],\n                    op[\"height\"],\n                    op.get(\"gravity\", \"auto\")\n                )\n        \n        return result\n```\n\n## 6. FastAPI Endpoints (`python/main.py` estensione)\n\n```python\nfrom fastapi import APIRouter, File, UploadFile, HTTPException\nfrom pydantic import BaseModel\nfrom typing import List, Literal, Optional\nfrom local_media.processor import LocalMediaProcessor\n\nrouter = APIRouter(prefix=\"/local-media\", tags=[\"local-media\"])\nprocessor = LocalMediaProcessor(Path(\"./models\"))\n\nclass Operation(BaseModel):\n    type: Literal[\"remove_bg\", \"upscale\", \"crop\"]\n    scale: Optional[Literal[\"x2\", \"x4\"]] = None\n    width: Optional[int] = None\n    height: Optional[int] = None\n    gravity: Optional[Literal[\"face\", \"center\", \"auto\"]] = None\n\nclass ProcessRequest(BaseModel):\n    operations: List[Operation]\n\n@router.post(\"/process\")\nasync def process_image(\n    file: UploadFile = File(...),\n    operations: str = None  # JSON encoded operations\n):\n    \"\"\"Processa immagine con operazioni locali\"\"\"\n    try:\n        image_bytes = await file.read()\n        ops = json.loads(operations) if operations else []\n        result = await processor.process(image_bytes, ops)\n        return Response(content=result, media_type=\"image/png\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@router.get(\"/models/status\")\nasync def models_status():\n    \"\"\"Ritorna stato download modelli\"\"\"\n    return {\n        \"upscale_x2\": processor.model_manager.is_downloaded(\"RealESRGAN_x2plus.pth\"),\n        \"upscale_x4\": processor.model_manager.is_downloaded(\"RealESRGAN_x4plus.pth\"),\n        \"rembg\": True  # Auto-downloaded by rembg\n    }\n\n@router.post(\"/models/download/{model_name}\")\nasync def download_model(model_name: str):\n    \"\"\"Trigger download manuale modello\"\"\"\n    await processor.model_manager.ensure_model(...)\n    return {\"status\": \"downloaded\"}\n```\n\n## 7. TypeScript Client (`src/lib/services/local-media-processor.ts`)\n\n```typescript\ninterface ProcessingOperation {\n  type: 'remove_bg' | 'upscale' | 'crop';\n  scale?: 'x2' | 'x4';\n  width?: number;\n  height?: number;\n  gravity?: 'face' | 'center' | 'auto';\n}\n\ninterface ModelStatus {\n  upscale_x2: boolean;\n  upscale_x4: boolean;\n  rembg: boolean;\n}\n\nexport class LocalMediaProcessor {\n  private baseUrl = 'http://localhost:8765';\n  \n  async process(file: File, operations: ProcessingOperation[]): Promise<Blob> {\n    const formData = new FormData();\n    formData.append('file', file);\n    formData.append('operations', JSON.stringify(operations));\n    \n    const response = await fetch(`${this.baseUrl}/local-media/process`, {\n      method: 'POST',\n      body: formData\n    });\n    \n    if (!response.ok) {\n      throw new Error(`Local processing failed: ${response.statusText}`);\n    }\n    \n    return response.blob();\n  }\n  \n  async getModelsStatus(): Promise<ModelStatus> {\n    const response = await fetch(`${this.baseUrl}/local-media/models/status`);\n    return response.json();\n  }\n  \n  async downloadModel(modelName: string): Promise<void> {\n    await fetch(`${this.baseUrl}/local-media/models/download/${modelName}`, {\n      method: 'POST'\n    });\n  }\n}\n```\n\n## 8. Svelte Store (`src/lib/stores/media-processing-settings.svelte.ts`)\n\n```typescript\nimport { writable } from 'svelte/store';\n\ninterface MediaProcessingSettings {\n  preferLocalProcessing: boolean;\n  fallbackToCloud: boolean;\n  downloadModelsAutomatically: boolean;\n}\n\nconst defaultSettings: MediaProcessingSettings = {\n  preferLocalProcessing: false,\n  fallbackToCloud: true,\n  downloadModelsAutomatically: false\n};\n\nfunction createMediaProcessingStore() {\n  const { subscribe, set, update } = writable<MediaProcessingSettings>(defaultSettings);\n  \n  return {\n    subscribe,\n    setPreferLocal: (value: boolean) => update(s => ({ ...s, preferLocalProcessing: value })),\n    setFallbackToCloud: (value: boolean) => update(s => ({ ...s, fallbackToCloud: value })),\n    load: async () => {\n      const saved = await window.electronAPI?.getStore('mediaProcessing');\n      if (saved) set(saved);\n    },\n    save: async (settings: MediaProcessingSettings) => {\n      await window.electronAPI?.setStore('mediaProcessing', settings);\n      set(settings);\n    }\n  };\n}\n\nexport const mediaProcessingSettings = createMediaProcessingStore();\n```\n\n## 9. UI Toggle Component (`src/lib/components/custom/MediaProcessingToggle.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { Switch } from '$lib/components/ui/switch';\n  import { Label } from '$lib/components/ui/label';\n  import { Card, CardContent, CardDescription, CardHeader, CardTitle } from '$lib/components/ui/card';\n  import { Badge } from '$lib/components/ui/badge';\n  import { mediaProcessingSettings } from '$lib/stores/media-processing-settings.svelte';\n  import { LocalMediaProcessor } from '$lib/services/local-media-processor';\n  \n  let processor = new LocalMediaProcessor();\n  let modelsStatus = $state({ upscale_x2: false, upscale_x4: false, rembg: false });\n  \n  $effect(() => {\n    processor.getModelsStatus().then(status => modelsStatus = status);\n  });\n</script>\n\n<Card>\n  <CardHeader>\n    <CardTitle>Elaborazione Media Locale</CardTitle>\n    <CardDescription>\n      Alternativa privacy-first a Cloudinary. Nessun upload su server esterni.\n    </CardDescription>\n  </CardHeader>\n  <CardContent class=\"space-y-4\">\n    <div class=\"flex items-center justify-between\">\n      <div class=\"space-y-0.5\">\n        <Label>Preferisci elaborazione locale</Label>\n        <p class=\"text-sm text-muted-foreground\">\n          Background removal, upscaling e smart crop eseguiti sul tuo Mac\n        </p>\n      </div>\n      <Switch \n        checked={$mediaProcessingSettings.preferLocalProcessing}\n        onCheckedChange={(v) => mediaProcessingSettings.setPreferLocal(v)}\n      />\n    </div>\n    \n    <div class=\"flex items-center justify-between\">\n      <div class=\"space-y-0.5\">\n        <Label>Fallback a Cloudinary</Label>\n        <p class=\"text-sm text-muted-foreground\">\n          Usa Cloudinary se l'elaborazione locale fallisce\n        </p>\n      </div>\n      <Switch \n        checked={$mediaProcessingSettings.fallbackToCloud}\n        onCheckedChange={(v) => mediaProcessingSettings.setFallbackToCloud(v)}\n      />\n    </div>\n    \n    <div class=\"pt-4 border-t\">\n      <h4 class=\"text-sm font-medium mb-2\">Stato Modelli ML</h4>\n      <div class=\"flex gap-2 flex-wrap\">\n        <Badge variant={modelsStatus.rembg ? 'default' : 'secondary'}>\n          rembg {modelsStatus.rembg ? '✓' : '~168MB'}\n        </Badge>\n        <Badge variant={modelsStatus.upscale_x2 ? 'default' : 'secondary'}>\n          ESRGAN x2 {modelsStatus.upscale_x2 ? '✓' : '~64MB'}\n        </Badge>\n        <Badge variant={modelsStatus.upscale_x4 ? 'default' : 'secondary'}>\n          ESRGAN x4 {modelsStatus.upscale_x4 ? '✓' : '~64MB'}\n        </Badge>\n      </div>\n    </div>\n  </CardContent>\n</Card>\n```\n\n## 10. Editing Agent Integrazione (`python/agents/editing_agent.py` update)\n\n```python\nclass EditingAgent(Agent):\n    \"\"\"Editing agent con supporto locale e cloud\"\"\"\n    \n    async def process_media(self, request: EditRequest) -> EditResult:\n        settings = await self.get_user_settings()\n        \n        if settings.prefer_local_processing:\n            try:\n                return await self._process_local(request)\n            except LocalProcessingError as e:\n                if settings.fallback_to_cloud:\n                    logger.warning(f\"Local processing failed, fallback to Cloudinary: {e}\")\n                    return await self._process_cloudinary(request)\n                raise\n        else:\n            return await self._process_cloudinary(request)\n    \n    async def _process_local(self, request: EditRequest) -> EditResult:\n        \"\"\"Processing locale con rembg, Real-ESRGAN, OpenCV\"\"\"\n        from local_media.processor import LocalMediaProcessor\n        processor = LocalMediaProcessor(self.models_dir)\n        \n        operations = self._map_request_to_operations(request)\n        result_bytes = await processor.process(request.image_bytes, operations)\n        \n        return EditResult(\n            success=True,\n            output_bytes=result_bytes,\n            processing_mode=\"local\"\n        )\n    \n    async def _process_cloudinary(self, request: EditRequest) -> EditResult:\n        \"\"\"Processing via Cloudinary MCP\"\"\"\n        # Existing Cloudinary implementation\n        ...\n```\n\n## Dipendenze Python (`python/requirements.txt` aggiunte)\n\n```txt\n# Local Media Processing\nrembg>=2.0.50\nrealesrgan>=0.3.0\nbasicsr>=1.4.2\nopencv-python-headless>=4.8.0\npillow>=10.0.0\naiohttp>=3.9.0\nnumpy>=1.24.0\n```\n\n## Trade-offs Documentati\n\n| Aspetto | Locale | Cloudinary |\n|---------|--------|------------|\n| Privacy | ✅ 100% locale | ⚠️ Upload su server |\n| Costo | ✅ Zero API costs | ⚠️ Pay-per-transform |\n| Velocità | ⚠️ Dipende da hardware | ✅ Server ottimizzati |\n| Qualità BG Removal | ~90% | 100% (baseline) |\n| Modelli | ~300MB download | Zero download |\n| Edge cases | ⚠️ Può fallire | ✅ Più robusto |",
        "testStrategy": "## Test Unitari Python\n\n### 1. `tests/unit/test_background_remover.py`\n- Test che immagine con sfondo semplice venga processata correttamente\n- Test che immagine con sfondo complesso ritorni PNG con alpha channel\n- Test che alpha_matting migliori bordi per immagini specifiche\n- Test gestione errori per immagini corrotte\n\n### 2. `tests/unit/test_upscaler.py`\n- Test che upscale x2 raddoppi effettivamente le dimensioni\n- Test che upscale x4 quadruplichi le dimensioni\n- Test che modello venga scaricato on-demand se mancante\n- Test progress callback durante download modello\n- Test gestione memoria per immagini molto grandi (>4K)\n\n### 3. `tests/unit/test_smart_cropper.py`\n- Test face detection con immagine contenente 1 volto\n- Test face detection con immagine contenente 3+ volti (centro pesato)\n- Test fallback a center crop quando nessun volto rilevato\n- Test crop mantenga aspect ratio target correttamente\n- Test gravity=\"center\" ignori face detection\n\n### 4. `tests/unit/test_model_manager.py`\n- Test download modello da URL valido\n- Test skip download se modello già presente\n- Test progress callback riceva valori 0.0 → 1.0\n- Test gestione errori per URL non raggiungibile\n- Test cleanup file parziali su download fallito\n\n## Test Integrazione Python\n\n### 5. `tests/integration/test_local_processor.py`\n- Test pipeline completa: remove_bg → upscale → crop\n- Test ordine operazioni rispettato\n- Test ogni operazione possa funzionare singolarmente\n- Test che risultato sia sempre PNG valido\n- Test performance: pipeline completa < 30s per immagine 1080p su M1\n\n### 6. `tests/integration/test_fastapi_endpoints.py`\n- Test POST `/local-media/process` con file valido\n- Test GET `/local-media/models/status` ritorna stato corretto\n- Test POST `/local-media/models/download/{name}` trigger download\n- Test error handling per file non-immagine\n- Test concurrent requests (max 3 simultanee)\n\n## Test TypeScript\n\n### 7. `tests/unit/local-media-processor.test.ts`\n- Test `process()` invia FormData corretta al sidecar\n- Test `getModelsStatus()` parsa risposta JSON\n- Test `downloadModel()` chiama endpoint corretto\n- Test error handling per network failures\n\n### 8. `tests/unit/media-processing-settings.test.ts`\n- Test store inizializza con valori default\n- Test `setPreferLocal()` aggiorna stato\n- Test `load()` recupera settings salvati\n- Test `save()` persiste via electronAPI\n\n## Test UI (Playwright)\n\n### 9. `e2e/media-processing-toggle.spec.ts`\n- Test toggle \"Preferisci elaborazione locale\" si attiva/disattiva\n- Test toggle \"Fallback a Cloudinary\" disabilitato quando local=false\n- Test badge modelli mostrano stato corretto (✓ vs dimensione)\n- Test settings persistono dopo refresh pagina\n\n## Test Fallback Chain\n\n### 10. `tests/integration/test_editing_agent_fallback.py`\n- Test con `prefer_local=true, fallback=true`: local fail → cloudinary success\n- Test con `prefer_local=true, fallback=false`: local fail → raise error\n- Test con `prefer_local=false`: skip locale, usa sempre cloudinary\n- Test log warning quando fallback attivato\n- Test `processing_mode` nel risultato indica quale metodo usato\n\n## Test Performance e Limiti\n\n### 11. `tests/performance/test_local_processing_limits.py`\n- Benchmark background removal: < 5s per 1080p\n- Benchmark upscale x2: < 10s per 1080p  \n- Benchmark upscale x4: < 30s per 1080p\n- Benchmark smart crop: < 1s per qualsiasi dimensione\n- Test memory usage non superi 4GB durante processing\n\n## Validazione Qualità\n\n### 12. Confronto manuale Cloudinary vs Local\n- Preparare 10 immagini test (volti, prodotti, landscape)\n- Confronto visivo background removal: acceptable se < 10% differenza percepita\n- Confronto upscaling: SSIM > 0.9 rispetto originale scalato\n- Confronto smart crop: volti sempre nel frame finale",
        "status": "pending",
        "dependencies": [
          "4",
          "5",
          "7"
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup Background Remover con rembg e U2-Net",
            "description": "Implementare il modulo background_remover.py con wrapper rembg che utilizza il modello U2-Net per la rimozione automatica dello sfondo dalle immagini.",
            "dependencies": [],
            "details": "Creare la classe BackgroundRemover in python/local_media/background_remover.py. Implementare il metodo remove_background() che accetta bytes immagine e parametri opzionali per alpha_matting. Il modello U2-Net (~168MB) viene scaricato automaticamente da rembg al primo utilizzo. Gestire la conversione PIL Image <-> bytes, output in formato PNG con canale alpha trasparente. Includere gestione errori con LocalProcessingError custom. Aggiungere dipendenze rembg>=2.0.50 e pillow>=10.0.0 a requirements.txt.",
            "status": "pending",
            "testStrategy": "Test unitari: verifica che immagine con sfondo semplice produca PNG con alpha channel; test che alpha_matting migliori bordi; test gestione errori per immagini corrotte o formati non supportati.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implementazione Upscaler con Real-ESRGAN",
            "description": "Creare il modulo upscaler.py che implementa super-resolution usando Real-ESRGAN con supporto per scale x2 e x4.",
            "dependencies": [
              4
            ],
            "details": "Implementare la classe Upscaler in python/local_media/upscaler.py. Definire dizionario MODELS con URL download per RealESRGAN_x2plus.pth e RealESRGAN_x4plus.pth (~64MB ciascuno). Metodo ensure_model() per download on-demand via ModelManager. Metodo upscale() che configura RRDBNet e RealESRGANer, processa l'immagine e ritorna bytes PNG. Aggiungere dipendenze realesrgan>=0.3.0, basicsr>=1.4.2, numpy>=1.24.0 a requirements.txt. Gestire conversione PIL <-> numpy array.",
            "status": "pending",
            "testStrategy": "Test che upscale x2 raddoppi le dimensioni immagine; test che upscale x4 quadruplichi; test download modello on-demand; benchmark performance su immagini di diverse dimensioni.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Smart Cropper con OpenCV e Face Detection",
            "description": "Implementare il modulo smart_cropper.py con rilevamento volti tramite Haar Cascade e crop intelligente basato su punto focale.",
            "dependencies": [],
            "details": "Creare la classe SmartCropper in python/local_media/smart_cropper.py. Caricare haarcascade_frontalface_default.xml da cv2.data.haarcascades. Implementare _detect_faces() con detectMultiScale. Implementare _calculate_focus_point() che calcola centro pesato dei volti rilevati o fallback al centro immagine. Metodo smart_crop() che: rileva volti, calcola punto focale, calcola crop box mantenendo aspect ratio target, centra sul punto focale, esegue resize con LANCZOS. Supportare gravity: 'face', 'center', 'auto'. Aggiungere opencv-python-headless>=4.8.0.",
            "status": "pending",
            "testStrategy": "Test con immagine contenente volto singolo verifica crop centrato sul volto; test con volti multipli verifica centro pesato; test senza volti verifica fallback center; test aspect ratio mantenuto correttamente.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Model Manager per Download On-Demand Modelli ML",
            "description": "Creare il sistema di gestione modelli che scarica i modelli ML (~300MB totali) on-demand con progress tracking e caching locale.",
            "dependencies": [],
            "details": "Implementare ModelManager in python/local_media/model_manager.py. Costruttore accetta models_dir (Path) e crea directory se non esiste. Metodo on_download_progress() per registrare callback progress. Metodo ensure_model(name, url, expected_size_mb) che: verifica se modello già presente in models_dir, altrimenti scarica con aiohttp in chunks da 8KB, notifica progress via callbacks registrati. Metodo is_downloaded(name) per verificare presenza. Aggiungere aiohttp>=3.9.0 a requirements.txt. Creare endpoint FastAPI GET /local-media/models/status e POST /local-media/models/download/{model_name}.",
            "status": "pending",
            "testStrategy": "Test download modello simulato con mock server; test progress callback riceve valori 0-1; test modello già presente non viene riscaricato; test gestione errori network.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "UI Toggle Settings e Svelte Store per Preferenze Processing",
            "description": "Creare componente MediaProcessingToggle.svelte e store Svelte 5 runes per gestire preferenze utente su elaborazione locale vs cloud.",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Creare store in src/lib/stores/media-processing-settings.svelte.ts con stato: preferLocalProcessing (boolean), fallbackToCloud (boolean), downloadModelsAutomatically (boolean). Metodi setPreferLocal(), setFallbackToCloud(), load() da electron store, save() verso electron store. Creare componente MediaProcessingToggle.svelte in src/lib/components/custom/ con Card shadcn contenente: Switch per preferire elaborazione locale, Switch per fallback Cloudinary, sezione stato modelli ML con Badge per rembg/ESRGAN x2/x4 che mostra checkmark se scaricato o dimensione se mancante. Usare $effect per caricare stato modelli da LocalMediaProcessor.getModelsStatus().",
            "status": "pending",
            "testStrategy": "Test store mantiene stato correttamente; test persistenza su electron store; test componente mostra stati corretti modelli; test toggle aggiorna store; test integrazione con settings page esistente.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Fallback Chain Local-Cloudinary e Integrazione Editing Agent",
            "description": "Implementare orchestrator LocalMediaProcessor, client TypeScript, endpoint FastAPI e logica fallback intelligente nell'editing agent.",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Creare processor.py in python/local_media/ con classe LocalMediaProcessor che orchestra bg_remover, upscaler, cropper. Metodo process(image_bytes, operations) che applica sequenza operazioni. Creare endpoint FastAPI POST /local-media/process in python/main.py. Creare client TypeScript LocalMediaProcessor in src/lib/services/local-media-processor.ts con metodi process(), getModelsStatus(), downloadModel(). Modificare EditingAgent in python/agents/editing_agent.py: leggere settings utente, se prefer_local_processing provare _process_local(), su LocalProcessingError e fallback_to_cloud abilitato chiamare _process_cloudinary(), altrimenti rilanciare errore. Loggare mode usato in EditResult.",
            "status": "pending",
            "testStrategy": "Test E2E flusso completo locale; test fallback attivato su errore locale; test rispetto impostazioni utente; test EditResult contiene processing_mode corretto; test concorrenza multiple richieste.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Docker Engine detection e status check, 2) Auto-installer MCP Gateway CLI plugin, 3) UI Settings toggle Cloud/Local per-tool con stato Docker, 4) Store MCP settings con Svelte 5 runes, 5) Generazione dinamica cagent.yaml con ref gateway vs local, 6) Fallback chain Python Gateway → Local → Error con istruzioni"
      },
      {
        "id": 17,
        "title": " MCP Deep Search con Jina AI e Firecrawl",
        "description": "Implementare l'integrazione opzionale di Jina AI MCP e Firecrawl MCP per ricerca web approfondita, con rate limiting configurabile, quota tracking in UI, e fallback automatico a DuckDuckGo quando i servizi non sono disponibili.",
        "details": "## Struttura Directory\n\n```\npython/\n├── mcp/\n│   ├── __init__.py\n│   ├── jina_client.py              # Wrapper Jina AI MCP\n│   ├── firecrawl_client.py         # Wrapper Firecrawl MCP\n│   ├── rate_limiter.py             # Token bucket rate limiter\n│   └── search_orchestrator.py      # Orchestrator con fallback chain\nsrc/lib/\n├── services/\n│   └── deep-search.ts              # Client TypeScript per sidecar\n├── stores/\n│   └── search-quota.svelte.ts      # Store Svelte 5 per quota tracking\n└── components/custom/\n    └── SearchQuotaWidget.svelte    # Widget UI per visualizzazione quota\nelectron/\n└── ipc-handlers.ts                 # Estensione con handler deep search\n```\n\n## 1. Configurazione MCP Servers in `.mcp.json`\n\n```json\n{\n  \"mcpServers\": {\n    \"jina-ai\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@anthropic/mcp-jina\"],\n      \"env\": {\n        \"JINA_API_KEY\": \"${JINA_API_KEY}\"\n      }\n    },\n    \"firecrawl\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"@anthropic/mcp-firecrawl\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"${FIRECRAWL_API_KEY}\"\n      }\n    }\n  }\n}\n```\n\n## 2. Rate Limiter (`python/mcp/rate_limiter.py`)\n\n```python\nimport time\nfrom dataclasses import dataclass\nfrom typing import Dict\nimport asyncio\n\n@dataclass\nclass RateLimitConfig:\n    requests_per_minute: int = 10\n    burst_limit: int = 3\n\nclass TokenBucketRateLimiter:\n    def __init__(self, config: RateLimitConfig):\n        self.config = config\n        self.tokens = config.burst_limit\n        self.last_refill = time.time()\n        self._lock = asyncio.Lock()\n    \n    async def acquire(self) -> bool:\n        async with self._lock:\n            self._refill()\n            if self.tokens > 0:\n                self.tokens -= 1\n                return True\n            return False\n    \n    def _refill(self):\n        now = time.time()\n        elapsed = now - self.last_refill\n        refill_amount = elapsed * (self.config.requests_per_minute / 60)\n        self.tokens = min(self.config.burst_limit, self.tokens + refill_amount)\n        self.last_refill = now\n\n    def get_wait_time(self) -> float:\n        if self.tokens > 0:\n            return 0\n        return (1 - self.tokens) * (60 / self.config.requests_per_minute)\n```\n\n## 3. Jina AI Client (`python/mcp/jina_client.py`)\n\n```python\nfrom typing import List, Dict, Optional\nfrom cagent import Tool\nfrom .rate_limiter import TokenBucketRateLimiter, RateLimitConfig\n\nclass JinaSearchClient:\n    def __init__(self, rate_limiter: TokenBucketRateLimiter):\n        self.rate_limiter = rate_limiter\n        self.tools = [\n            Tool('jina_search', 'Deep web search via Jina AI'),\n            Tool('jina_reader', 'Extract structured content from URL'),\n        ]\n    \n    async def deep_search(self, query: str, max_results: int = 10) -> List[Dict]:\n        \"\"\"Ricerca web approfondita con estrazione contenuto strutturato\"\"\"\n        if not await self.rate_limiter.acquire():\n            wait_time = self.rate_limiter.get_wait_time()\n            raise RateLimitExceeded(f\"Rate limit exceeded. Retry in {wait_time:.1f}s\")\n        \n        # Chiama Jina MCP tool via cagent\n        results = await self._call_mcp_tool('jina_search', {'query': query, 'limit': max_results})\n        return results\n    \n    async def read_url(self, url: str) -> Dict:\n        \"\"\"Estrae contenuto strutturato da una URL\"\"\"\n        if not await self.rate_limiter.acquire():\n            raise RateLimitExceeded(\"Rate limit exceeded\")\n        \n        return await self._call_mcp_tool('jina_reader', {'url': url})\n    \n    async def _call_mcp_tool(self, tool_name: str, params: dict) -> Dict:\n        # Implementazione chiamata MCP\n        pass\n```\n\n## 4. Firecrawl Client (`python/mcp/firecrawl_client.py`)\n\n```python\nfrom typing import List, Dict\nfrom .rate_limiter import TokenBucketRateLimiter\n\nclass FirecrawlClient:\n    def __init__(self, rate_limiter: TokenBucketRateLimiter):\n        self.rate_limiter = rate_limiter\n    \n    async def scrape_url(self, url: str, options: Dict = None) -> Dict:\n        \"\"\"Web scraping avanzato con rendering JavaScript\"\"\"\n        if not await self.rate_limiter.acquire():\n            raise RateLimitExceeded(\"Rate limit exceeded\")\n        \n        return await self._call_mcp_tool('firecrawl_scrape', {\n            'url': url,\n            'options': options or {'waitFor': 2000, 'formats': ['markdown', 'html']}\n        })\n    \n    async def crawl_site(self, start_url: str, max_pages: int = 10) -> List[Dict]:\n        \"\"\"Crawling multi-pagina con limite configurabile\"\"\"\n        if not await self.rate_limiter.acquire():\n            raise RateLimitExceeded(\"Rate limit exceeded\")\n        \n        return await self._call_mcp_tool('firecrawl_crawl', {\n            'url': start_url,\n            'limit': max_pages,\n            'scrapeOptions': {'formats': ['markdown']}\n        })\n```\n\n## 5. Search Orchestrator con Fallback Chain (`python/mcp/search_orchestrator.py`)\n\n```python\nfrom typing import List, Dict, Optional\nfrom enum import Enum\nimport logging\n\nclass SearchProvider(Enum):\n    JINA = \"jina\"\n    FIRECRAWL = \"firecrawl\"\n    DUCKDUCKGO = \"duckduckgo\"\n\nclass DeepSearchOrchestrator:\n    def __init__(self, jina: JinaSearchClient, firecrawl: FirecrawlClient, duckduckgo_tool):\n        self.jina = jina\n        self.firecrawl = firecrawl\n        self.duckduckgo = duckduckgo_tool\n        self.logger = logging.getLogger(__name__)\n        \n        # Quota tracking\n        self.quota_used = {p.value: 0 for p in SearchProvider}\n    \n    async def search(self, query: str, preferred_provider: SearchProvider = SearchProvider.JINA) -> Dict:\n        \"\"\"Ricerca con fallback chain automatico\"\"\"\n        providers = self._get_fallback_chain(preferred_provider)\n        \n        for provider in providers:\n            try:\n                result = await self._search_with_provider(provider, query)\n                self.quota_used[provider.value] += 1\n                return {'provider': provider.value, 'results': result, 'fallback_used': provider != preferred_provider}\n            except RateLimitExceeded as e:\n                self.logger.warning(f\"{provider.value} rate limited: {e}\")\n                continue\n            except ServiceUnavailable as e:\n                self.logger.warning(f\"{provider.value} unavailable: {e}\")\n                continue\n        \n        raise AllProvidersUnavailable(\"All search providers failed\")\n    \n    async def trend_research(self, topic: str, platforms: List[str]) -> Dict:\n        \"\"\"Ricerca trend per CaptioningAgent\"\"\"\n        results = {}\n        for platform in platforms:\n            query = f\"{topic} {platform} trends 2025 social media\"\n            try:\n                search_result = await self.search(query)\n                results[platform] = search_result\n            except AllProvidersUnavailable:\n                results[platform] = {'error': 'No providers available'}\n        return results\n    \n    def get_quota_status(self) -> Dict:\n        return {\n            'used': self.quota_used.copy(),\n            'limits': {\n                'jina': 10,  # per minute\n                'firecrawl': 10,\n                'duckduckgo': 'unlimited'\n            }\n        }\n    \n    def _get_fallback_chain(self, preferred: SearchProvider) -> List[SearchProvider]:\n        chain = [preferred]\n        if preferred != SearchProvider.JINA:\n            chain.append(SearchProvider.JINA)\n        if preferred != SearchProvider.FIRECRAWL:\n            chain.append(SearchProvider.FIRECRAWL)\n        chain.append(SearchProvider.DUCKDUCKGO)  # Always last fallback\n        return chain\n```\n\n## 6. Integrazione CaptioningAgent (`python/agents/captioning_agent.py` - estensione)\n\n```python\nclass CaptioningAgent:\n    def __init__(self, knowledge_base, llm_provider, search_orchestrator: DeepSearchOrchestrator = None):\n        self.knowledge_base = knowledge_base\n        self.llm_provider = llm_provider\n        self.search = search_orchestrator  # Optional deep search\n    \n    async def generate_caption_with_trends(self, content_desc: str, platform: str, tone: str) -> Dict:\n        \"\"\"Genera caption arricchita con trend research\"\"\"\n        # 1. Contesto brand da RAG\n        brand_context = self._get_brand_context(content_desc)\n        \n        # 2. Trend research (se disponibile)\n        trend_context = \"\"\n        if self.search:\n            try:\n                trends = await self.search.trend_research(content_desc, [platform])\n                trend_context = self._format_trends(trends.get(platform, {}))\n            except Exception as e:\n                logging.warning(f\"Trend research failed: {e}\")\n        \n        # 3. Genera caption con contesto arricchito\n        prompt = self._build_prompt(content_desc, platform, tone, brand_context, trend_context)\n        return await self.llm_provider.generate(prompt)\n```\n\n## 7. TypeScript Client (`src/lib/services/deep-search.ts`)\n\n```typescript\ninterface SearchQuota {\n  used: Record<string, number>;\n  limits: Record<string, number | 'unlimited'>;\n}\n\ninterface SearchResult {\n  provider: string;\n  results: any[];\n  fallback_used: boolean;\n}\n\nexport class DeepSearchClient {\n  async search(query: string, preferredProvider: 'jina' | 'firecrawl' = 'jina'): Promise<SearchResult> {\n    const response = await window.electronAPI.invoke('deep-search:query', { query, preferredProvider });\n    if (!response.success) throw new Error(response.error);\n    return response.data;\n  }\n  \n  async trendResearch(topic: string, platforms: string[]): Promise<Record<string, SearchResult>> {\n    const response = await window.electronAPI.invoke('deep-search:trends', { topic, platforms });\n    if (!response.success) throw new Error(response.error);\n    return response.data;\n  }\n  \n  async getQuotaStatus(): Promise<SearchQuota> {\n    const response = await window.electronAPI.invoke('deep-search:quota');\n    return response.data;\n  }\n}\n```\n\n## 8. Svelte 5 Store per Quota (`src/lib/stores/search-quota.svelte.ts`)\n\n```typescript\nimport { DeepSearchClient } from '$lib/services/deep-search';\n\nconst client = new DeepSearchClient();\n\nlet quota = $state<SearchQuota>({ used: {}, limits: {} });\nlet lastUpdated = $state<Date | null>(null);\n\nexport const searchQuotaStore = {\n  get quota() { return quota; },\n  get lastUpdated() { return lastUpdated; },\n  \n  async refresh() {\n    quota = await client.getQuotaStatus();\n    lastUpdated = new Date();\n  },\n  \n  getUsagePercentage(provider: string): number {\n    const used = quota.used[provider] || 0;\n    const limit = quota.limits[provider];\n    if (limit === 'unlimited') return 0;\n    return Math.min(100, (used / (limit as number)) * 100);\n  }\n};\n\n// Auto-refresh ogni 30 secondi\nsetInterval(() => searchQuotaStore.refresh(), 30000);\n```\n\n## 9. Widget UI Quota (`src/lib/components/custom/SearchQuotaWidget.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { searchQuotaStore } from '$lib/stores/search-quota.svelte';\n  import { Progress } from '$lib/components/ui/progress';\n  import { Card, CardContent, CardHeader, CardTitle } from '$lib/components/ui/card';\n  import { Badge } from '$lib/components/ui/badge';\n  \n  const providers = ['jina', 'firecrawl', 'duckduckgo'];\n</script>\n\n<Card class=\"w-64\">\n  <CardHeader class=\"pb-2\">\n    <CardTitle class=\"text-sm\">Search Quota</CardTitle>\n  </CardHeader>\n  <CardContent class=\"space-y-3\">\n    {#each providers as provider}\n      {@const percentage = searchQuotaStore.getUsagePercentage(provider)}\n      {@const used = searchQuotaStore.quota.used[provider] || 0}\n      {@const limit = searchQuotaStore.quota.limits[provider]}\n      <div class=\"space-y-1\">\n        <div class=\"flex justify-between text-xs\">\n          <span class=\"capitalize\">{provider}</span>\n          <span>{used}/{limit === 'unlimited' ? '∞' : limit}</span>\n        </div>\n        {#if limit !== 'unlimited'}\n          <Progress value={percentage} class=\"h-1\" />\n        {:else}\n          <Badge variant=\"outline\" class=\"text-xs\">Unlimited</Badge>\n        {/if}\n      </div>\n    {/each}\n    {#if searchQuotaStore.lastUpdated}\n      <p class=\"text-xs text-muted-foreground\">\n        Updated: {searchQuotaStore.lastUpdated.toLocaleTimeString()}\n      </p>\n    {/if}\n  </CardContent>\n</Card>\n```\n\n## 10. IPC Handlers (`electron/ipc-handlers.ts` - estensione)\n\n```typescript\n// Aggiungere a registerIpcHandlers()\nipcMain.handle('deep-search:query', async (_, { query, preferredProvider }) => {\n  try {\n    const result = await sidecarClient.post('/search/query', { query, preferredProvider });\n    return { success: true, data: result };\n  } catch (error) {\n    return { success: false, error: error.message };\n  }\n});\n\nipcMain.handle('deep-search:trends', async (_, { topic, platforms }) => {\n  try {\n    const result = await sidecarClient.post('/search/trends', { topic, platforms });\n    return { success: true, data: result };\n  } catch (error) {\n    return { success: false, error: error.message };\n  }\n});\n\nipcMain.handle('deep-search:quota', async () => {\n  try {\n    const result = await sidecarClient.get('/search/quota');\n    return { success: true, data: result };\n  } catch (error) {\n    return { success: false, error: error.message };\n  }\n});\n```\n\n## 11. FastAPI Endpoints (`python/main.py` - estensione)\n\n```python\nfrom fastapi import APIRouter\nfrom python.mcp.search_orchestrator import DeepSearchOrchestrator, SearchProvider\n\nsearch_router = APIRouter(prefix=\"/search\", tags=[\"search\"])\n\n@search_router.post(\"/query\")\nasync def search_query(query: str, preferredProvider: str = \"jina\"):\n    provider = SearchProvider(preferredProvider)\n    return await search_orchestrator.search(query, provider)\n\n@search_router.post(\"/trends\")\nasync def search_trends(topic: str, platforms: list[str]):\n    return await search_orchestrator.trend_research(topic, platforms)\n\n@search_router.get(\"/quota\")\nasync def get_quota():\n    return search_orchestrator.get_quota_status()\n```\n\n## Configurazione Rate Limiting\n\nIl rate limiting default è 10 req/min per Jina e Firecrawl, configurabile in:\n- `python/mcp/rate_limiter.py` - RateLimitConfig\n- UI Settings (futuro) per override utente",
        "testStrategy": "## Test Unitari Python\n\n### 1. `tests/unit/test_rate_limiter.py`\n- Test che TokenBucketRateLimiter blocchi dopo burst_limit richieste consecutive\n- Test che i token vengano ricaricati correttamente nel tempo (simulare 60s per refill completo)\n- Test che `get_wait_time()` ritorni valore corretto quando rate limited\n- Test concorrenza con asyncio.gather per verificare thread safety del lock\n\n### 2. `tests/unit/test_jina_client.py`\n- Test `deep_search()` con mock MCP tool che ritorna risultati validi\n- Test che `RateLimitExceeded` venga sollevata quando rate limiter blocca\n- Test `read_url()` con URL valida e mock response\n- Test gestione errori per URL malformata\n\n### 3. `tests/unit/test_firecrawl_client.py`\n- Test `scrape_url()` con opzioni default\n- Test `scrape_url()` con opzioni custom (waitFor, formats)\n- Test `crawl_site()` rispetti max_pages limit\n- Test rate limiting integrato\n\n### 4. `tests/unit/test_search_orchestrator.py`\n- Test fallback chain: Jina → Firecrawl → DuckDuckGo\n- Test che quota tracking incrementi correttamente per ogni provider\n- Test `trend_research()` con multiple piattaforme\n- Test che `AllProvidersUnavailable` venga sollevata quando tutti falliscono\n- Test `get_quota_status()` ritorna struttura corretta\n\n## Test Integrazione\n\n### 5. `tests/integration/test_captioning_with_trends.py`\n- Test CaptioningAgent con mock DeepSearchOrchestrator\n- Test che trend context venga incluso nel prompt quando disponibile\n- Test graceful degradation quando search fallisce (caption generata comunque)\n- Test che quota venga aggiornata dopo trend research\n\n### 6. `tests/integration/test_ipc_deep_search.py`\n- Test IPC handler `deep-search:query` con mock sidecar\n- Test IPC handler `deep-search:trends` ritorna risultati per ogni piattaforma\n- Test IPC handler `deep-search:quota` con quota parzialmente esaurita\n- Test error handling per sidecar non disponibile\n\n## Test Componenti Svelte\n\n### 7. `tests/components/SearchQuotaWidget.test.ts`\n- Test rendering con quota vuota\n- Test rendering con quota parziale (50% jina, 80% firecrawl)\n- Test che \"unlimited\" mostri badge invece di progress bar\n- Test aggiornamento timestamp \"lastUpdated\"\n- Test responsive su diverse dimensioni schermo\n\n### 8. `tests/stores/search-quota.test.ts`\n- Test `refresh()` aggiorna stato correttamente\n- Test `getUsagePercentage()` calcola percentuale corretta\n- Test `getUsagePercentage()` ritorna 0 per 'unlimited'\n- Test auto-refresh interval (mock timers)\n\n## Test E2E\n\n### 9. `tests/e2e/deep-search-flow.test.ts`\n- Test flusso completo: Settings → Abilita Jina API key → Caption generation con trends\n- Test fallback visibile in UI quando Jina rate limited\n- Test quota widget si aggiorna dopo ricerche\n- Test che DuckDuckGo funzioni come fallback finale senza API key\n\n## Test Fallback\n\n### 10. `tests/fallback/test_duckduckgo_fallback.py`\n- Test che ricerca funzioni con solo DuckDuckGo disponibile\n- Test che risultati DuckDuckGo siano formattati consistentemente con Jina/Firecrawl\n- Test performance: DuckDuckGo risponda entro 5s\n\n## Metriche di Qualità\n\n- Copertura test: minimo 80% per moduli search\n- Latenza media ricerca: < 3s per Jina, < 5s per Firecrawl, < 2s per DuckDuckGo\n- Rate limit accuracy: 10 ± 1 req/min\n- Fallback success rate: > 99% quando almeno un provider disponibile",
        "status": "pending",
        "dependencies": [
          "4",
          "5",
          "8"
        ],
        "priority": "low",
        "subtasks": [
          {
            "id": 1,
            "title": "Configurazione MCP Servers per Jina AI e Firecrawl",
            "description": "Configurare i server MCP per Jina AI e Firecrawl nel file .mcp.json, implementare il wrapper client base per entrambi i servizi e gestire le API keys tramite variabili d'ambiente.",
            "dependencies": [],
            "details": "Creare la configurazione MCP in .mcp.json con i server jina-ai e firecrawl utilizzando npx per l'esecuzione. Implementare python/mcp/__init__.py e le classi base JinaSearchClient e FirecrawlClient con integrazione cagent Tool. Gestire le API keys JINA_API_KEY e FIRECRAWL_API_KEY tramite variabili d'ambiente. Implementare i metodi _call_mcp_tool per invocare i tool MCP tramite cagent. Includere gestione errori per API keys mancanti e servizi non disponibili con eccezioni ServiceUnavailable.",
            "status": "pending",
            "testStrategy": "Test unitari per verificare parsing corretto della configurazione MCP. Test mock per chiamate MCP tool con cagent. Test che ServiceUnavailable venga sollevata quando le API keys sono mancanti o i servizi non rispondono.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "Implementazione Token Bucket Rate Limiter",
            "description": "Implementare il sistema di rate limiting con algoritmo token bucket per controllare il numero di richieste API verso Jina AI e Firecrawl, con configurazione personalizzabile e calcolo del tempo di attesa.",
            "dependencies": [],
            "details": "Creare python/mcp/rate_limiter.py con la classe TokenBucketRateLimiter che implementa l'algoritmo token bucket. Definire RateLimitConfig con requests_per_minute=10 e burst_limit=3 come default. Implementare il metodo acquire() con lock asincrono per thread-safety, il metodo _refill() per ricaricare i token in base al tempo trascorso, e get_wait_time() per calcolare quanto tempo attendere prima della prossima richiesta disponibile. Sollevare eccezione RateLimitExceeded quando i token sono esauriti.",
            "status": "pending",
            "testStrategy": "Test unitari in tests/unit/test_rate_limiter.py: verificare che acquire() blocchi dopo burst_limit richieste consecutive, testare ricarica token simulando il passaggio del tempo (60s per refill completo), verificare che get_wait_time() ritorni valori corretti quando i token sono esauriti.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Search Orchestrator con Fallback Chain Automatico",
            "description": "Implementare l'orchestratore di ricerca che coordina Jina AI, Firecrawl e DuckDuckGo con fallback automatico, quota tracking e gestione intelligente dei provider non disponibili.",
            "dependencies": [
              1,
              2
            ],
            "details": "Creare python/mcp/search_orchestrator.py con DeepSearchOrchestrator che gestisce JinaSearchClient, FirecrawlClient e DuckDuckGo tool. Implementare il metodo search() che tenta i provider in ordine di preferenza (Jina → Firecrawl → DuckDuckGo) con gestione eccezioni RateLimitExceeded e ServiceUnavailable. Implementare _get_fallback_chain() per costruire la catena di fallback dinamica. Aggiungere quota_used tracking per ogni provider e metodo get_quota_status() per esporre le statistiche. Implementare _search_with_provider() per normalizzare le risposte dei diversi provider. Sollevare AllProvidersUnavailable solo quando tutti i provider falliscono.",
            "status": "pending",
            "testStrategy": "Test unitari per verificare che il fallback passi al provider successivo quando uno fallisce. Test che DuckDuckGo venga sempre usato come ultimo fallback. Test che quota_used venga incrementata correttamente. Test che AllProvidersUnavailable venga sollevata solo quando tutti i provider falliscono. Test con mock per simulare rate limiting e service unavailable su provider specifici.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Integrazione Trend Research in CaptioningAgent",
            "description": "Estendere il CaptioningAgent per utilizzare il DeepSearchOrchestrator per ricerche di trend social media, arricchendo la generazione di caption con insight contestuali aggiornati.",
            "dependencies": [
              3
            ],
            "details": "Modificare python/agents/captioning_agent.py per accettare un parametro opzionale search_orchestrator: DeepSearchOrchestrator. Implementare il metodo trend_research() in DeepSearchOrchestrator che esegue ricerche multi-piattaforma usando query ottimizzate '{topic} {platform} trends 2025 social media'. Estendere generate_caption_with_trends() per combinare brand_context da RAG con trend_context da deep search. Implementare _format_trends() per normalizzare i risultati di ricerca in formato utilizzabile dal prompt LLM. Gestire gracefully i fallimenti di ricerca trend con logging warning e fallback a generazione senza trend context.",
            "status": "pending",
            "testStrategy": "Test unitari per verificare che CaptioningAgent funzioni correttamente sia con che senza search_orchestrator. Test che trend_research() generi query corrette per diverse piattaforme. Test mock per simulare ricerche trend riuscite e fallite. Test che _format_trends() normalizzi correttamente risultati da diversi provider. Test di integrazione per generazione caption con e senza trend context.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "UI Quota Widget e IPC Handlers per Deep Search",
            "description": "Implementare il widget Svelte 5 per visualizzare le quote di utilizzo dei provider di ricerca, il client TypeScript per comunicare con il sidecar, e gli handler IPC Electron per collegare frontend e backend.",
            "dependencies": [
              3,
              4
            ],
            "details": "Creare src/lib/services/deep-search.ts con DeepSearchClient che espone metodi search(), trendResearch() e getQuotaStatus() tramite window.electronAPI. Implementare src/lib/stores/search-quota.svelte.ts come Svelte 5 runes store con stato reattivo per quota, lastUpdated, e metodi refresh() e getUsagePercentage(). Creare src/lib/components/custom/SearchQuotaWidget.svelte con Progress bar per Jina e Firecrawl e Badge 'Unlimited' per DuckDuckGo. Estendere electron/ipc-handlers.ts con handler 'deep-search:query', 'deep-search:trends' e 'deep-search:quota' che chiamano il sidecar FastAPI. Aggiungere FastAPI endpoints in python/main.py: POST /search/query, POST /search/trends, GET /search/quota. Implementare auto-refresh quota ogni 30 secondi nel store.",
            "status": "pending",
            "testStrategy": "Test unitari TypeScript per DeepSearchClient con mock window.electronAPI. Test Svelte per SearchQuotaWidget verificando rendering corretto di progress bar e badge. Test IPC handlers con mock sidecar responses. Test FastAPI endpoints con pytest per verificare serializzazione corretta delle risposte. Test E2E per verificare aggiornamento reattivo della UI quando le quote cambiano.",
            "parentId": "undefined"
          }
        ],
        "complexity": 7,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Setup rembg per background removal con U2-Net, 2) Implementazione upscaler con Real-ESRGAN (x2, x4), 3) Smart cropper con OpenCV e face detection, 4) Model manager per download on-demand modelli ML (~300MB totali), 5) UI toggle nelle settings e integration con editing agent, 6) Fallback chain local → Cloudinary con gestione errori"
      },
      {
        "id": 18,
        "title": "OPTIONAL UPGRADE: Docker Model Runner per LLM Locali",
        "description": "Implementare l'integrazione opzionale con Docker Model Runner per l'esecuzione locale di modelli LLM (Qwen, Llama, Mistral, Gemma) senza costi API, includendo detection Docker Desktop 4.40+, UI Model Browser con download manager, benchmark performance e integrazione come provider 'dmr' in cagent.yaml con fallback automatico a cloud.",
        "details": "## Struttura Directory\n\n```\nelectron/\n├── docker-model-runner.ts          # Detection e gestione Docker Model Runner\n├── dmr-benchmark.ts                 # Benchmark locale vs cloud\n└── ipc-handlers.ts                  # Estensione con handler DMR\n\npython/\n├── providers/\n│   ├── __init__.py\n│   ├── dmr_provider.py              # Provider LLM per Docker Model Runner\n│   └── fallback_manager.py          # Gestione fallback locale → cloud\n\nsrc/lib/\n├── services/\n│   └── dmr-client.ts                # Client TypeScript per Docker Model Runner\n├── stores/\n│   └── dmr-models.svelte.ts         # Store Svelte 5 per modelli locali\n└── components/custom/\n    ├── DMRModelBrowser.svelte       # Browser modelli disponibili\n    ├── DMRDownloadManager.svelte    # Download con progress bar\n    └── DMRBenchmarkCard.svelte      # Risultati benchmark\n\nsrc/routes/settings/\n└── local-llm/\n    └── +page.svelte                 # Pagina settings LLM locali\n```\n\n## 1. Detection Docker Desktop e Model Runner (`electron/docker-model-runner.ts`)\n\n```typescript\nimport { exec } from 'child_process';\nimport { promisify } from 'util';\n\nconst execAsync = promisify(exec);\n\ninterface DockerDesktopInfo {\n  installed: boolean;\n  version: string | null;\n  modelRunnerEnabled: boolean;\n  platform: 'macos' | 'windows' | 'linux';\n  architecture: 'arm64' | 'amd64';\n}\n\ninterface DMRModel {\n  name: string;\n  size: string;\n  quantization: string;\n  downloaded: boolean;\n  downloadProgress?: number;\n}\n\nexport class DockerModelRunnerDetector {\n  async detectDockerDesktop(): Promise<DockerDesktopInfo> {\n    try {\n      // Verifica Docker Desktop (NON solo Engine)\n      const { stdout: versionOutput } = await execAsync('docker version --format \"{{.Server.Platform.Name}}\"');\n      const isDesktop = versionOutput.includes('Docker Desktop');\n      \n      if (!isDesktop) {\n        return { installed: false, version: null, modelRunnerEnabled: false, platform: this.getPlatform(), architecture: this.getArch() };\n      }\n      \n      // Estrai versione Docker Desktop\n      const { stdout: fullVersion } = await execAsync('docker version --format \"{{.Client.Version}}\"');\n      const version = fullVersion.trim();\n      const [major, minor] = version.split('.').map(Number);\n      \n      // Richiede Docker Desktop 4.40+\n      const meetsMinVersion = major > 4 || (major === 4 && minor >= 40);\n      \n      // Verifica Model Runner enabled\n      const modelRunnerEnabled = meetsMinVersion && await this.checkModelRunnerEnabled();\n      \n      return {\n        installed: true,\n        version,\n        modelRunnerEnabled,\n        platform: this.getPlatform(),\n        architecture: this.getArch()\n      };\n    } catch (error) {\n      return { installed: false, version: null, modelRunnerEnabled: false, platform: this.getPlatform(), architecture: this.getArch() };\n    }\n  }\n  \n  private async checkModelRunnerEnabled(): Promise<boolean> {\n    try {\n      // Docker Model Runner espone endpoint OpenAI-compatibile su localhost\n      const { stdout } = await execAsync('curl -s http://localhost:12434/v1/models');\n      return stdout.includes('models');\n    } catch {\n      return false;\n    }\n  }\n  \n  async listAvailableModels(): Promise<DMRModel[]> {\n    // Modelli supportati da Docker Model Runner\n    return [\n      { name: 'ai/qwen2.5:7B-Q4_K_M', size: '4.4GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/qwen2.5:14B-Q4_K_M', size: '8.9GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/llama3.2:3B-Q4_K_M', size: '2.0GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/llama3.1:8B-Q4_K_M', size: '4.9GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/mistral:7B-Q4_K_M', size: '4.4GB', quantization: 'Q4_K_M', downloaded: false },\n      { name: 'ai/gemma2:9B-Q4_K_M', size: '5.4GB', quantization: 'Q4_K_M', downloaded: false },\n    ];\n  }\n  \n  async pullModel(modelName: string, onProgress: (progress: number) => void): Promise<boolean> {\n    return new Promise((resolve, reject) => {\n      const proc = exec(`docker model pull ${modelName}`);\n      \n      proc.stdout?.on('data', (data) => {\n        // Parse progress da output Docker\n        const match = data.match(/(\\d+)%/);\n        if (match) onProgress(parseInt(match[1]));\n      });\n      \n      proc.on('close', (code) => resolve(code === 0));\n      proc.on('error', reject);\n    });\n  }\n}\n```\n\n## 2. Provider Python per Docker Model Runner (`python/providers/dmr_provider.py`)\n\n```python\nfrom typing import AsyncIterator, Optional\nimport httpx\nimport json\n\nclass DockerModelRunnerProvider:\n    \"\"\"Provider LLM che utilizza Docker Model Runner via API OpenAI-compatibile.\"\"\"\n    \n    def __init__(self, base_url: str = \"http://localhost:12434/v1\"):\n        self.base_url = base_url\n        self.client = httpx.AsyncClient(base_url=base_url, timeout=120.0)\n    \n    async def health_check(self) -> bool:\n        \"\"\"Verifica che Docker Model Runner sia attivo.\"\"\"\n        try:\n            response = await self.client.get(\"/models\")\n            return response.status_code == 200\n        except httpx.RequestError:\n            return False\n    \n    async def list_models(self) -> list[dict]:\n        \"\"\"Elenca modelli disponibili localmente.\"\"\"\n        response = await self.client.get(\"/models\")\n        data = response.json()\n        return data.get(\"data\", [])\n    \n    async def chat_completion(\n        self,\n        model: str,\n        messages: list[dict],\n        temperature: float = 0.7,\n        max_tokens: int = 2048,\n        stream: bool = False\n    ) -> AsyncIterator[str] | dict:\n        \"\"\"Esegue inference locale con streaming opzionale.\"\"\"\n        payload = {\n            \"model\": model,\n            \"messages\": messages,\n            \"temperature\": temperature,\n            \"max_tokens\": max_tokens,\n            \"stream\": stream\n        }\n        \n        if stream:\n            async with self.client.stream(\"POST\", \"/chat/completions\", json=payload) as response:\n                async for line in response.aiter_lines():\n                    if line.startswith(\"data: \"):\n                        chunk = line[6:]\n                        if chunk != \"[DONE]\":\n                            yield json.loads(chunk)[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n        else:\n            response = await self.client.post(\"/chat/completions\", json=payload)\n            return response.json()\n    \n    async def close(self):\n        await self.client.aclose()\n```\n\n## 3. Fallback Manager (`python/providers/fallback_manager.py`)\n\n```python\nfrom typing import Optional\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass FallbackManager:\n    \"\"\"Gestisce fallback automatico da locale a cloud.\"\"\"\n    \n    def __init__(self, local_provider, cloud_providers: dict):\n        self.local = local_provider\n        self.cloud_providers = cloud_providers  # {'anthropic': ..., 'openai': ...}\n        self.local_failures = 0\n        self.max_local_failures = 3\n    \n    async def execute_with_fallback(\n        self,\n        model: str,\n        messages: list[dict],\n        preferred_cloud: str = \"anthropic\",\n        **kwargs\n    ):\n        \"\"\"Esegue locale con fallback automatico a cloud.\"\"\"\n        \n        # Tentativo locale\n        if self.local_failures < self.max_local_failures:\n            try:\n                if await self.local.health_check():\n                    result = await self.local.chat_completion(model, messages, **kwargs)\n                    self.local_failures = 0  # Reset su successo\n                    return {\"source\": \"local\", \"result\": result}\n            except Exception as e:\n                self.local_failures += 1\n                logger.warning(f\"Local model failed ({self.local_failures}/{self.max_local_failures}): {e}\")\n        \n        # Fallback a cloud\n        cloud = self.cloud_providers.get(preferred_cloud)\n        if cloud:\n            logger.info(f\"Falling back to cloud provider: {preferred_cloud}\")\n            result = await cloud.chat_completion(messages, **kwargs)\n            return {\"source\": \"cloud\", \"provider\": preferred_cloud, \"result\": result}\n        \n        raise RuntimeError(\"No available LLM provider (local failed, no cloud configured)\")\n```\n\n## 4. UI Model Browser (`src/lib/components/custom/DMRModelBrowser.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { Card, CardContent, CardHeader, CardTitle } from '$lib/components/ui/card';\n  import { Button } from '$lib/components/ui/button';\n  import { Progress } from '$lib/components/ui/progress';\n  import { Badge } from '$lib/components/ui/badge';\n  import { dmrModelsStore } from '$lib/stores/dmr-models.svelte';\n  import { Download, Check, Cpu, HardDrive } from 'lucide-svelte';\n  \n  interface Model {\n    name: string;\n    displayName: string;\n    size: string;\n    quantization: string;\n    downloaded: boolean;\n    downloading: boolean;\n    downloadProgress: number;\n    recommended: boolean;\n    minRam: string;\n  }\n  \n  let { models, dockerStatus } = $derived(dmrModelsStore);\n  \n  async function downloadModel(model: Model) {\n    await window.electronAPI.dmr.pullModel(model.name);\n  }\n  \n  function formatModelName(name: string): string {\n    return name.replace('ai/', '').replace(/:.*/, '');\n  }\n</script>\n\n<div class=\"space-y-4\">\n  {#if !dockerStatus.modelRunnerEnabled}\n    <Card class=\"border-yellow-500 bg-yellow-50 dark:bg-yellow-950\">\n      <CardContent class=\"pt-6\">\n        <p class=\"text-yellow-800 dark:text-yellow-200\">\n          Docker Desktop 4.40+ con Model Runner è richiesto per i modelli locali.\n          <a href=\"https://docs.docker.com/desktop/features/model-runner/\" class=\"underline\" target=\"_blank\">\n            Scopri come abilitarlo\n          </a>\n        </p>\n      </CardContent>\n    </Card>\n  {:else}\n    <div class=\"grid gap-4 md:grid-cols-2\">\n      {#each models as model}\n        <Card class:border-green-500={model.downloaded}>\n          <CardHeader class=\"pb-2\">\n            <div class=\"flex items-center justify-between\">\n              <CardTitle class=\"text-lg\">{formatModelName(model.name)}</CardTitle>\n              {#if model.recommended}\n                <Badge variant=\"secondary\">Raccomandato</Badge>\n              {/if}\n            </div>\n          </CardHeader>\n          <CardContent>\n            <div class=\"flex items-center gap-4 text-sm text-muted-foreground mb-4\">\n              <span class=\"flex items-center gap-1\">\n                <HardDrive class=\"h-4 w-4\" />\n                {model.size}\n              </span>\n              <span class=\"flex items-center gap-1\">\n                <Cpu class=\"h-4 w-4\" />\n                {model.minRam} RAM min\n              </span>\n              <Badge variant=\"outline\">{model.quantization}</Badge>\n            </div>\n            \n            {#if model.downloading}\n              <Progress value={model.downloadProgress} class=\"mb-2\" />\n              <p class=\"text-sm text-muted-foreground\">{model.downloadProgress}% completato</p>\n            {:else if model.downloaded}\n              <Button variant=\"outline\" disabled class=\"w-full\">\n                <Check class=\"mr-2 h-4 w-4\" />\n                Installato\n              </Button>\n            {:else}\n              <Button onclick={() => downloadModel(model)} class=\"w-full\">\n                <Download class=\"mr-2 h-4 w-4\" />\n                Download\n              </Button>\n            {/if}\n          </CardContent>\n        </Card>\n      {/each}\n    </div>\n  {/if}\n</div>\n```\n\n## 5. Integrazione cagent.yaml con provider 'dmr'\n\nEstendere `src/lib/services/cagent-config.ts` per supportare il provider DMR:\n\n```typescript\n// Aggiungere a CagentConfig interface\ntype LLMProvider = 'anthropic' | 'openai' | 'google' | 'perplexity' | 'dmr';\n\ninterface AgentRole {\n  name: string;\n  model: string;\n  provider: LLMProvider;\n  fallbackProvider?: LLMProvider; // Fallback automatico se locale fallisce\n  // ...\n}\n\n// Template YAML per DMR\nconst DMR_CONFIG_TEMPLATE = `\nagents:\n  captioning_agent:\n    provider: dmr\n    model: ai/qwen2.5:7B-Q4_K_M\n    fallback_provider: anthropic\n    fallback_model: claude-3-haiku\n  extraction_agent:\n    provider: dmr\n    model: ai/llama3.2:3B-Q4_K_M\n    fallback_provider: openai\n    fallback_model: gpt-4o-mini\n`;\n```\n\n## 6. Benchmark Performance (`electron/dmr-benchmark.ts`)\n\n```typescript\ninterface BenchmarkResult {\n  model: string;\n  provider: 'local' | 'cloud';\n  tokensPerSecond: number;\n  latencyMs: number;\n  memoryUsageMB: number;\n  quality: 'high' | 'medium' | 'low';\n}\n\nexport async function runBenchmark(\n  localModel: string,\n  cloudProvider: string,\n  cloudModel: string,\n  testPrompt: string\n): Promise<{local: BenchmarkResult, cloud: BenchmarkResult}> {\n  // Benchmark locale\n  const localStart = Date.now();\n  const localResult = await callDMR(localModel, testPrompt);\n  const localLatency = Date.now() - localStart;\n  \n  // Benchmark cloud\n  const cloudStart = Date.now();\n  const cloudResult = await callCloud(cloudProvider, cloudModel, testPrompt);\n  const cloudLatency = Date.now() - cloudStart;\n  \n  return {\n    local: {\n      model: localModel,\n      provider: 'local',\n      tokensPerSecond: calculateTPS(localResult, localLatency),\n      latencyMs: localLatency,\n      memoryUsageMB: await getProcessMemory(),\n      quality: evaluateQuality(localResult, cloudResult) // Usa cloud come riferimento\n    },\n    cloud: {\n      model: cloudModel,\n      provider: 'cloud',\n      tokensPerSecond: calculateTPS(cloudResult, cloudLatency),\n      latencyMs: cloudLatency,\n      memoryUsageMB: 0,\n      quality: 'high'\n    }\n  };\n}\n```\n\n## Requisiti Hardware Documentati\n\nAggiungere in UI e documentazione:\n\n| Modello | RAM Minima | RAM Raccomandata | Note |\n|---------|------------|------------------|------|\n| 3B (Llama 3.2) | 8GB | 12GB | Veloce, qualità base |\n| 7B (Qwen, Mistral) | 16GB | 24GB | Buon compromesso |\n| 14B (Qwen) | 32GB | 48GB | Alta qualità, lento |\n\n- Apple Silicon M1+ raccomandato per performance ottimali\n- Su Intel/AMD, aspettarsi 2-5x più lento rispetto a Apple Silicon\n- GPU dedicata non utilizzata (Docker Model Runner usa CPU)",
        "testStrategy": "## Test Unitari TypeScript\n\n### 1. `test/docker-model-runner.test.ts`\n- Test `detectDockerDesktop()` con mock exec che simula Docker Desktop 4.40+ installato\n- Test `detectDockerDesktop()` con mock che simula solo Docker Engine (non Desktop)\n- Test `detectDockerDesktop()` con versione < 4.40 (modelRunnerEnabled deve essere false)\n- Test `checkModelRunnerEnabled()` con mock curl response successo\n- Test `checkModelRunnerEnabled()` con timeout/errore connessione\n- Test `listAvailableModels()` ritorna lista modelli corretta\n- Test `pullModel()` con mock progress events\n\n### 2. `test/dmr-client.test.ts`\n- Test client HTTP verso endpoint DMR mock\n- Test streaming response parsing\n- Test timeout handling (modelli locali possono essere lenti)\n- Test retry logic su errori temporanei\n\n## Test Unitari Python\n\n### 1. `tests/unit/test_dmr_provider.py`\n- Test `health_check()` con mock server attivo → True\n- Test `health_check()` con connection refused → False\n- Test `chat_completion()` non-streaming con risposta valida\n- Test `chat_completion()` streaming con chunks multipli\n- Test handling errori API (4xx, 5xx)\n- Test timeout su risposte lente\n\n### 2. `tests/unit/test_fallback_manager.py`\n- Test che locale venga usato se disponibile\n- Test fallback a cloud dopo 3 fallimenti locali consecutivi\n- Test reset contatore fallimenti dopo successo\n- Test errore se né locale né cloud disponibili\n- Test preferenza cloud provider rispettata\n\n## Test Integrazione\n\n### 1. `tests/integration/test_dmr_e2e.py`\n- Test con Docker Model Runner reale (skip se non disponibile)\n- Test pull modello piccolo (3B) e verifica download\n- Test inference base con prompt semplice\n- Test performance: latency < 30s per prompt corto su M1+\n\n### 2. Test UI Svelte\n- Test rendering DMRModelBrowser con modelli mock\n- Test progress bar aggiornamento durante download\n- Test stato \"non disponibile\" quando Docker Desktop manca\n- Test click download triggera IPC corretto\n- Test badge \"Installato\" appare dopo download completato\n\n## Test Benchmark\n\n### 1. `tests/benchmark/test_performance.ts`\n- Test calcolo tokens/secondo corretto\n- Test comparazione locale vs cloud produce risultati validi\n- Test memory usage tracking durante inference\n\n## Test E2E\n\n### 1. `e2e/dmr-flow.test.ts`\n- Flow completo: detect Docker → mostra UI → download modello → configura come provider → esegui inference\n- Verifica fallback automatico: disabilita Docker → verifica switch a cloud\n- Verifica persistenza: riavvia app → modelli scaricati ancora visibili\n- Test settings: assegna modello locale a ruolo → verifica cagent.yaml generato correttamente",
        "status": "pending",
        "dependencies": [
          "3",
          "4",
          "5",
          "16"
        ],
        "priority": "low",
        "subtasks": [
          {
            "id": 1,
            "title": "Detection Docker Desktop 4.40+ e Model Runner Status",
            "description": "Implementare il modulo di rilevamento Docker Desktop con verifica versione minima 4.40+ e stato di abilitazione del Model Runner.",
            "dependencies": [],
            "details": "Creare `electron/docker-model-runner.ts` con classe `DockerModelRunnerDetector` che: 1) Esegue `docker version` per verificare presenza Docker Desktop (non solo Engine), 2) Estrae e valida versione >= 4.40, 3) Verifica Model Runner attivo tramite health check su `http://localhost:12434/v1/models`, 4) Rileva piattaforma (macos/windows/linux) e architettura (arm64/amd64), 5) Espone IPC handlers in `ipc-handlers.ts` per query stato da renderer. Gestire tutti i casi di errore con fallback graceful.",
            "status": "pending",
            "testStrategy": "Test unitari con mock di exec per simulare: Docker Desktop installato 4.40+, versione < 4.40, solo Docker Engine senza Desktop, Docker non installato. Test integrazione per health check Model Runner con mock HTTP.",
            "parentId": "undefined"
          },
          {
            "id": 2,
            "title": "UI Model Browser con Lista Modelli Disponibili",
            "description": "Creare interfaccia Svelte per visualizzare i modelli LLM disponibili (Qwen, Llama, Mistral, Gemma) con informazioni su dimensione, quantizzazione e requisiti hardware.",
            "dependencies": [
              1
            ],
            "details": "Implementare: 1) Store Svelte 5 `dmr-models.svelte.ts` con stato modelli e Docker status usando runes ($state, $derived), 2) Componente `DMRModelBrowser.svelte` con grid card per ogni modello mostrando: nome, dimensione disco, quantizzazione (Q4_K_M), RAM minima richiesta, badge 'Raccomandato' per modelli ottimali, 3) Warning card se Docker Desktop < 4.40 o Model Runner disabilitato con link documentazione, 4) Pagina settings `src/routes/settings/local-llm/+page.svelte` integrata nel menu esistente. Utilizzare componenti shadcn-svelte (Card, Badge, Button).",
            "status": "pending",
            "testStrategy": "Test componente con mock store per verificare rendering corretto card modelli, stato Docker warning, badge raccomandato. Test accessibilità e responsive design.",
            "parentId": "undefined"
          },
          {
            "id": 3,
            "title": "Download Manager con Progress Tracking",
            "description": "Implementare sistema di download modelli con progress bar real-time, gestione errori e resume capability.",
            "dependencies": [
              1,
              2
            ],
            "details": "Estendere `DockerModelRunnerDetector` con metodo `pullModel()` che: 1) Esegue `docker model pull <nome>` in background, 2) Parsa output per estrarre percentuale progresso, 3) Emette eventi IPC per aggiornare UI in tempo reale. Creare componente `DMRDownloadManager.svelte` con: Progress bar per download attivo, stato 'Installato' per modelli già scaricati, gestione cancellazione download, persistenza stato in store. Gestire edge cases: interruzione rete, spazio disco insufficiente, download paralleli.",
            "status": "pending",
            "testStrategy": "Test mock processo docker con output simulato per parsing progress. Test UI per transizioni stato pending→downloading→installed. Test gestione errori con mock failure scenarios.",
            "parentId": "undefined"
          },
          {
            "id": 4,
            "title": "Provider Python per Docker Model Runner API OpenAI-compatibile",
            "description": "Creare provider Python che utilizza l'API OpenAI-compatibile esposta da Docker Model Runner per inference locale.",
            "dependencies": [],
            "details": "Implementare `python/providers/dmr_provider.py` con classe `DockerModelRunnerProvider`: 1) Client httpx async con base URL `http://localhost:12434/v1`, 2) Metodo `health_check()` per verifica disponibilità, 3) Metodo `list_models()` per elenco modelli installati, 4) Metodo `chat_completion()` con supporto streaming SSE, 5) Parametri: model, messages, temperature, max_tokens. Timeout configurabile (default 120s per modelli lenti). Gestione errori con eccezioni specifiche per timeout, connessione refused, modello non trovato.",
            "status": "pending",
            "testStrategy": "Test unitari con mock httpx per verificare: chiamate API corrette, parsing response, streaming chunks, gestione timeout. Test integrazione con Docker Model Runner reale se disponibile.",
            "parentId": "undefined"
          },
          {
            "id": 5,
            "title": "Fallback Manager Locale → Cloud",
            "description": "Implementare gestore fallback automatico che passa da modello locale a provider cloud quando l'inference locale fallisce.",
            "dependencies": [
              4
            ],
            "details": "Creare `python/providers/fallback_manager.py` con classe `FallbackManager`: 1) Accetta provider locale + dizionario provider cloud (anthropic, openai), 2) Metodo `execute_with_fallback()` che tenta prima locale, poi cloud su failure, 3) Circuit breaker: dopo 3 fallimenti consecutivi locali, bypassa diretto a cloud per N minuti, 4) Logging dettagliato source (local/cloud) per analytics, 5) Reset contatore fallimenti su successo locale. Integrare in FastAPI sidecar come middleware per tutti gli endpoint agent. Configurazione fallback_provider in cagent.yaml per-agent.",
            "status": "pending",
            "testStrategy": "Test unitari per: fallback dopo N failures, circuit breaker activation/reset, selezione provider cloud corretto. Test integrazione con mock providers per verificare retry logic.",
            "parentId": "undefined"
          },
          {
            "id": 6,
            "title": "Benchmark Performance Locale vs Cloud",
            "description": "Creare sistema di benchmark per confrontare performance (tokens/sec, latenza) tra modelli locali Docker Model Runner e provider cloud.",
            "dependencies": [
              1,
              4
            ],
            "details": "Implementare `electron/dmr-benchmark.ts` con funzione `runBenchmark()`: 1) Prompt di test standardizzato (~100 token input), 2) Misura tempo risposta e calcola tokens/secondo per locale e cloud, 3) Rileva memoria utilizzata dal processo Docker, 4) Valutazione qualità comparando output locale vs cloud reference. Creare componente `DMRBenchmarkCard.svelte` con: bottone 'Esegui Benchmark', risultati tabulari (locale vs cloud), indicatori visivi performance (verde/giallo/rosso), raccomandazione automatica quale modello usare per ogni ruolo agent. Salvare risultati in localStorage per riferimento.",
            "status": "pending",
            "testStrategy": "Test con mock timing per verificare calcoli TPS corretti. Test UI per rendering risultati e raccomandazioni. Test persistenza localStorage.",
            "parentId": "undefined"
          }
        ],
        "complexity": 5,
        "recommendedSubtasks": 5,
        "expansionPrompt": "Espandi in subtask: 1) Configurazione Jina AI e Firecrawl MCP servers, 2) Rate limiter con token bucket per API calls, 3) Search orchestrator con fallback chain Jina → Firecrawl → DuckDuckGo, 4) Integrazione con CaptioningAgent per trend research, 5) UI quota widget e settings per configurazione"
      },
      {
        "id": 19,
        "title": "Integrazione Runtime Cagent in Sidecar Python",
        "description": "Integrare il motore di esecuzione Cagent nel server FastAPI (main.py) per permettere l'esecuzione reale degli agenti definiti in team.yaml. Sostituire i placeholder con la logica di caricamento configurazione e dispatch delle richieste.",
        "details": "1.  Aggiungere `cagent` (o il pacchetto corretto) a `python/requirements.txt`.\\n2.  Modificare `python/main.py` per inizializzare il runtime Cagent all'avvio (`lifespan`).\\n3.  Implementare la funzione `get_agent_runner()` per recuperare l'istanza dell'agente richiesto.\\n4.  Aggiornare l'endpoint `POST /agent/execute` per invocare l'agente e restituire la risposta reale.\\n5.  Collegare il sistema di eventi Cagent alla coda SSE esistente per lo streaming del pensiero/tool usage.\\n6.  Verificare che `team.yaml` venga caricato correttamente.",
        "testStrategy": "Unit test con mock del runner Cagent. Integration test chiamando /agent/execute con un agente semplice (es. orchestrator) e verificando la risposta non-placeholder.",
        "status": "done",
        "dependencies": [
          "4",
          "5"
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 6,
        "recommendedSubtasks": 6,
        "expansionPrompt": "Espandi in subtask: 1) Detection Docker Desktop 4.40+ e Model Runner status, 2) UI Model Browser con lista modelli disponibili (Qwen, Llama, Mistral, Gemma), 3) Download manager con progress tracking, 4) Provider Python per Docker Model Runner API OpenAI-compatibile, 5) Fallback manager locale → cloud, 6) Benchmark performance locale vs cloud",
        "updatedAt": "2026-02-07T11:42:59.315Z"
      },
      {
        "id": 20,
        "title": "Ristrutturazione Navigation + Nuove Tab",
        "description": "Rinominare la navigazione sidebar: \"Modifica\" diventa \"Idea Studio\", \"Pubblica\" diventa \"Scheduling\", e aggiungere una nuova tab \"Creative Output\" tra Idea Studio e Scheduling. Aggiornare layout sidebar, routing SvelteKit e breadcrumb.",
        "details": "## Struttura File Coinvolti\n\n```\nsrc/\n├── routes/\n│   ├── edit/+page.svelte          → RINOMINARE in idea-studio/+page.svelte\n│   ├── publish/+page.svelte       → RINOMINARE in scheduling/+page.svelte\n│   └── creative-output/+page.svelte   → NUOVO FILE\n├── lib/\n│   └── components/\n│       └── custom/\n│           └── AppSidebar.svelte  → AGGIORNARE routes array\n└── routes/+layout.svelte          → AGGIORNARE breadcrumb logic\n```\n\n## 1. Aggiornare AppSidebar.svelte\n\nModificare l'array `routes` in `src/lib/components/custom/AppSidebar.svelte`:\n\n```typescript\nimport { Bot, Folder, House, Image, Lightbulb, Sparkles, Calendar, Settings } from '@lucide/svelte';\n\nconst routes = [\n  { path: '/', label: 'Dashboard', icon: House },\n  { path: '/brands', label: 'Brand', icon: Folder },\n  { path: '/extract', label: 'Estrai', icon: Image },\n  { path: '/idea-studio', label: 'Idea Studio', icon: Lightbulb },      // ex \"Modifica\"\n  { path: '/creative-output', label: 'Creative Output', icon: Sparkles }, // NUOVO\n  { path: '/scheduling', label: 'Scheduling', icon: Calendar },         // ex \"Pubblica\"\n];\n```\n\n**Icone suggerite:**\n- `Lightbulb` per Idea Studio (brainstorming, idee)\n- `Sparkles` per Creative Output (output creativo/magia)\n- `Calendar` per Scheduling (pianificazione)\n\n## 2. Rinominare Route \"edit\" → \"idea-studio\"\n\nSpostare `src/routes/edit/+page.svelte` → `src/routes/idea-studio/+page.svelte`\n\nAggiornare il contenuto:\n- Titolo pagina: \"Idea Studio - Trae Extractor\"\n- Header h1: \"Idea Studio\" con icona Lightbulb\n- Descrizione: adattare al nuovo nome\n\n```svelte\n<svelte:head>\n  <title>Idea Studio - Trae Extractor</title>\n</svelte:head>\n\n<h1 class=\"text-3xl font-bold tracking-tight flex items-center gap-2\">\n  <Lightbulb class=\"size-8\" />\n  Idea Studio\n</h1>\n<p class=\"text-muted-foreground\">\n  Sviluppa e raffina le tue idee creative prima della produzione.\n</p>\n```\n\n## 3. Rinominare Route \"publish\" → \"scheduling\"\n\nSpostare `src/routes/publish/+page.svelte` → `src/routes/scheduling/+page.svelte`\n\nAggiornare il contenuto:\n- Titolo pagina: \"Scheduling - Trae Extractor\"\n- Header h1: \"Scheduling\" con icona Calendar\n- Descrizione: mantenere focus su pianificazione pubblicazioni\n\n```svelte\n<svelte:head>\n  <title>Scheduling - Trae Extractor</title>\n</svelte:head>\n\n<h1 class=\"text-3xl font-bold tracking-tight flex items-center gap-2\">\n  <Calendar class=\"size-8\" />\n  Scheduling\n</h1>\n<p class=\"text-muted-foreground\">\n  Pianifica e programma la pubblicazione dei tuoi contenuti su diverse piattaforme.\n</p>\n```\n\n## 4. Creare Nuova Route \"creative-output\"\n\nCreare `src/routes/creative-output/+page.svelte`:\n\n```svelte\n<script lang=\"ts\">\n  import { Sparkles, Video, ImageIcon, FileText, Palette } from '@lucide/svelte';\n  import * as Card from '$lib/components/ui/card/index.js';\n  import { Button } from '$lib/components/ui/button/index.js';\n</script>\n\n<svelte:head>\n  <title>Creative Output - Trae Extractor</title>\n</svelte:head>\n\n<div class=\"flex flex-col gap-6 py-4\">\n  <!-- Header -->\n  <div class=\"flex flex-col gap-2\">\n    <h1 class=\"text-3xl font-bold tracking-tight flex items-center gap-2\">\n      <Sparkles class=\"size-8\" />\n      Creative Output\n    </h1>\n    <p class=\"text-muted-foreground\">\n      Visualizza e gestisci i contenuti generati dagli agenti creativi.\n    </p>\n  </div>\n\n  <!-- Empty State -->\n  <Card.Root class=\"flex flex-col items-center justify-center py-12\">\n    <Card.Header class=\"text-center\">\n      <div class=\"mx-auto mb-4 rounded-full bg-muted p-4\">\n        <Sparkles class=\"size-8 text-muted-foreground\" />\n      </div>\n      <Card.Title>Nessun output creativo</Card.Title>\n      <Card.Description class=\"max-w-sm\">\n        Gli output creativi generati dagli agenti appariranno qui.\n        Inizia dal processo di estrazione per generare contenuti.\n      </Card.Description>\n    </Card.Header>\n    <Card.Content>\n      <Button href=\"/idea-studio\">\n        Vai a Idea Studio\n      </Button>\n    </Card.Content>\n  </Card.Root>\n\n  <!-- Output Types Grid -->\n  <div class=\"grid gap-4 md:grid-cols-3\">\n    <Card.Root>\n      <Card.Header>\n        <Card.Title class=\"flex items-center gap-2\">\n          <ImageIcon class=\"size-5\" />\n          Immagini Elaborate\n        </Card.Title>\n      </Card.Header>\n      <Card.Content>\n        <p class=\"text-sm text-muted-foreground\">\n          Immagini processate da Cloudinary con filtri, crop e ottimizzazioni.\n        </p>\n      </Card.Content>\n    </Card.Root>\n\n    <Card.Root>\n      <Card.Header>\n        <Card.Title class=\"flex items-center gap-2\">\n          <Video class=\"size-5\" />\n          Video Renderizzati\n        </Card.Title>\n      </Card.Header>\n      <Card.Content>\n        <p class=\"text-sm text-muted-foreground\">\n          Video timeline generati da Shotstack pronti per la pubblicazione.\n        </p>\n      </Card.Content>\n    </Card.Root>\n\n    <Card.Root>\n      <Card.Header>\n        <Card.Title class=\"flex items-center gap-2\">\n          <FileText class=\"size-5\" />\n          Caption Generate\n        </Card.Title>\n      </Card.Header>\n      <Card.Content>\n        <p class=\"text-sm text-muted-foreground\">\n          Testi e caption generati dall'agente Captioning con brand voice.\n        </p>\n      </Card.Content>\n    </Card.Root>\n  </div>\n\n  <!-- Future Features -->\n  <Card.Root>\n    <Card.Header>\n      <Card.Title>Funzionalità in arrivo</Card.Title>\n      <Card.Description>Queste funzionalità saranno disponibili nelle prossime versioni</Card.Description>\n    </Card.Header>\n    <Card.Content>\n      <ul class=\"list-inside list-disc space-y-2 text-sm text-muted-foreground\">\n        <li>Gallery view con preview in tempo reale</li>\n        <li>Confronto versioni A/B degli output</li>\n        <li>Export batch in vari formati</li>\n        <li>Integrazione con Creative Planner per revisioni</li>\n        <li>Statistiche di utilizzo risorse (Cloudinary, Shotstack)</li>\n      </ul>\n    </Card.Content>\n  </Card.Root>\n</div>\n```\n\n## 5. Aggiornare Breadcrumb in Layout\n\nModificare `src/routes/+layout.svelte` per supportare breadcrumb dinamici basati sulla route corrente:\n\n```svelte\n<script lang=\"ts\">\n  import { page } from '$app/stores';\n  import * as Sidebar from '$lib/components/ui/sidebar/index.js';\n  import { AppSidebar } from '$lib/components/custom/index.js';\n  import { Toaster } from '$lib/components/ui/sonner/index.js';\n\n  let { children } = $props();\n\n  // Mappa route → label per breadcrumb\n  const routeLabels: Record<string, string> = {\n    '/': 'Dashboard',\n    '/brands': 'Brand',\n    '/extract': 'Estrai',\n    '/idea-studio': 'Idea Studio',\n    '/creative-output': 'Creative Output',\n    '/scheduling': 'Scheduling',\n    '/settings': 'Impostazioni',\n    '/settings/agents': 'Agent Configuration',\n    '/settings/llm-providers': 'LLM Providers',\n  };\n\n  const currentLabel = $derived(routeLabels[$page.url.pathname] || 'Trae Extractor');\n</script>\n\n<header ...>\n  <nav class=\"flex items-center gap-1 text-sm text-muted-foreground\">\n    <a href=\"/\" class=\"hover:text-foreground\">Trae Extractor</a>\n    {#if $page.url.pathname !== '/'}\n      <span class=\"mx-1\">/</span>\n      <span class=\"font-medium text-foreground\">{currentLabel}</span>\n    {/if}\n  </nav>\n</header>\n```\n\n## 6. Aggiornare Link Interni\n\nCercare e sostituire tutti i riferimenti:\n- `href=\"/edit\"` → `href=\"/idea-studio\"`\n- `href=\"/publish\"` → `href=\"/scheduling\"`\n\nFile da controllare:\n- `src/routes/+page.svelte` (dashboard)\n- `src/routes/extract/+page.svelte`\n- Qualsiasi altro file con link interni\n\n## 7. Ordine Finale Navigation\n\nL'ordine nella sidebar deve essere:\n1. Dashboard (/)\n2. Brand (/brands)\n3. Estrai (/extract)\n4. **Idea Studio** (/idea-studio) - ex Modifica\n5. **Creative Output** (/creative-output) - NUOVO\n6. **Scheduling** (/scheduling) - ex Pubblica\n\nQuesto ordine riflette il flusso utente: Dashboard → Brand setup → Estrazione → Ideazione → Output creativi → Scheduling pubblicazione.",
        "testStrategy": "## Test Manuali\n\n### 1. Verifica Navigazione Sidebar\n- Avviare l'app con `pnpm run dev`\n- Verificare che la sidebar mostri le 6 voci nell'ordine corretto\n- Verificare che i label siano: Dashboard, Brand, Estrai, **Idea Studio**, **Creative Output**, **Scheduling**\n- Verificare che le icone siano appropriate (Lightbulb, Sparkles, Calendar)\n\n### 2. Verifica Routing\n- Cliccare su \"Idea Studio\" → deve navigare a `/idea-studio`\n- Cliccare su \"Creative Output\" → deve navigare a `/creative-output`\n- Cliccare su \"Scheduling\" → deve navigare a `/scheduling`\n- Verificare che le vecchie route (`/edit`, `/publish`) restituiscano 404\n\n### 3. Verifica Breadcrumb\n- Navigare a ogni pagina e verificare che il breadcrumb mostri:\n  - \"/\" → solo \"Trae Extractor\"\n  - \"/idea-studio\" → \"Trae Extractor / Idea Studio\"\n  - \"/creative-output\" → \"Trae Extractor / Creative Output\"\n  - \"/scheduling\" → \"Trae Extractor / Scheduling\"\n\n### 4. Verifica Contenuto Pagine\n- `/idea-studio`: titolo \"Idea Studio\", icona Lightbulb, descrizione aggiornata\n- `/creative-output`: titolo \"Creative Output\", icona Sparkles, empty state con link a Idea Studio\n- `/scheduling`: titolo \"Scheduling\", icona Calendar, contenuto pubblicazione/pianificazione\n\n### 5. Verifica Link Interni\n- Dalla pagina `/creative-output`, il bottone \"Vai a Idea Studio\" deve portare a `/idea-studio`\n- Dalla pagina `/extract`, eventuali link a modifica/pubblicazione devono puntare alle nuove route\n\n### 6. Verifica Active State Sidebar\n- Quando su `/idea-studio`, la voce \"Idea Studio\" deve essere evidenziata (isActive=true)\n- Quando su `/creative-output`, la voce \"Creative Output\" deve essere evidenziata\n- Quando su `/scheduling`, la voce \"Scheduling\" deve essere evidenziata\n\n## Test Automatici\n\n### TypeScript Type Check\n```bash\npnpm run check\n```\nVerificare zero errori di tipo.\n\n### Test E2E (se disponibili)\n```bash\npnpm run test:e2e\n```\nAggiornare eventuali test E2E che facevano riferimento alle vecchie route `/edit` e `/publish`.\n\n### Build Test\n```bash\npnpm run package\n```\nVerificare che il build completi senza errori.",
        "status": "pending",
        "dependencies": [
          1
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "Idea Studio Tab — Workflow IDEA-VALIDATOR",
        "description": "Implementare la tab Idea Studio con workflow IDEA-VALIDATOR che analizza asset estratti, upload al volo e brief testuali, proponendo N opzioni workflow interattive tramite card A2UI. Include 1-2 passaggi iterativi di rifinitura via chat AI per definire angles, posizionamenti e tone of voice, con output finale JSON passato a Creative Output.",
        "details": "## Struttura Directory\n\n```\nsrc/\n├── routes/\n│   └── idea-studio/\n│       ├── +page.svelte              # Pagina principale Idea Studio (Task 20 rinomina)\n│       └── +page.ts                  # Load function per stato iniziale\n├── lib/\n│   ├── components/\n│   │   ├── custom/\n│   │   │   ├── IdeaStudioInput.svelte    # Form unificato per asset/upload/brief\n│   │   │   ├── WorkflowOptionCard.svelte  # Card A2UI per singola opzione workflow\n│   │   │   ├── WorkflowOptionsGrid.svelte # Griglia di card opzioni\n│   │   │   ├── RefinementChat.svelte      # Chat AI per rifinitura iterativa\n│   │   │   └── WorkflowPlanPreview.svelte # Preview JSON workflow approvato\n│   │   └── agent-widgets/\n│   │       └── IdeaValidatorWidget.svelte # Widget A2UI generato da IDEA-VALIDATOR\n│   ├── stores/\n│   │   └── idea-studio.svelte.ts     # Store Svelte 5 per stato Idea Studio\n│   ├── services/\n│   │   └── idea-validator-client.ts  # Client per chiamate a IDEA-VALIDATOR agent\n│   └── types/\n│       └── idea-studio.ts            # TypeScript interfaces per workflow plan\npython/\n├── prompts/\n│   └── idea-validator/\n│       ├── workflow-options.md       # Prompt per generazione opzioni workflow\n│       └── refinement.md             # Prompt per rifinitura iterativa\n└── agents/\n    └── idea_validator_extensions.py  # Estensioni per generazione workflow options\n```\n\n## 1. Componente IdeaStudioInput.svelte\n\nInput unificato con 3 modalità:\n\n```svelte\n<script lang=\"ts\">\n  import { Upload, FileImage, FileText, Plus } from '@lucide/svelte';\n  import * as Tabs from '$lib/components/ui/tabs/index.js';\n  import * as Card from '$lib/components/ui/card/index.js';\n  import { Button } from '$lib/components/ui/button/index.js';\n  import { Textarea } from '$lib/components/ui/textarea/index.js';\n  \n  interface Props {\n    onSubmit: (input: IdeaInput) => void;\n    extractedAssets?: ExtractedAsset[];\n  }\n  \n  let { onSubmit, extractedAssets = [] }: Props = $props();\n  let activeTab = $state<'assets' | 'upload' | 'brief'>('assets');\n  let briefText = $state('');\n  let uploadedFiles = $state<File[]>([]);\n</script>\n```\n\n- **Tab 1 (Assets)**: Griglia selezionabile di asset già estratti (da Task 6 Extract)\n- **Tab 2 (Upload)**: Drag-and-drop per file al volo (PNG, JPG, MP4)\n- **Tab 3 (Brief)**: Textarea per descrizione testuale senza asset\n\n## 2. Store idea-studio.svelte.ts\n\n```typescript\nimport { writable } from 'svelte/store';\n\nexport interface WorkflowOption {\n  id: string;\n  title: string;           // es: \"1 blog + 1 video YT + 2 reel\"\n  description: string;\n  contents: ContentItem[];\n  estimatedReach: string;\n  platforms: string[];\n  selected: boolean;\n}\n\nexport interface IdeaStudioState {\n  input: IdeaInput | null;\n  workflowOptions: WorkflowOption[];\n  selectedOption: WorkflowOption | null;\n  refinementHistory: RefinementMessage[];\n  approvedPlan: WorkflowPlan | null;\n  status: 'idle' | 'analyzing' | 'options' | 'refining' | 'approved';\n}\n\n// Svelte 5 runes store\nlet state = $state<IdeaStudioState>({\n  input: null,\n  workflowOptions: [],\n  selectedOption: null,\n  refinementHistory: [],\n  approvedPlan: null,\n  status: 'idle'\n});\n\nexport const ideaStudioStore = {\n  get current() { return state; },\n  setInput(input: IdeaInput) { state.input = input; state.status = 'analyzing'; },\n  setOptions(options: WorkflowOption[]) { state.workflowOptions = options; state.status = 'options'; },\n  selectOption(id: string) { /* ... */ },\n  addRefinement(msg: RefinementMessage) { /* ... */ },\n  approvePlan(plan: WorkflowPlan) { state.approvedPlan = plan; state.status = 'approved'; }\n};\n```\n\n## 3. WorkflowOptionCard.svelte (A2UI-style)\n\nCard interattiva per singola opzione workflow:\n\n```svelte\n<script lang=\"ts\">\n  import * as Card from '$lib/components/ui/card/index.js';\n  import { Badge } from '$lib/components/ui/badge/index.js';\n  import { Button } from '$lib/components/ui/button/index.js';\n  import { Check, Edit2 } from '@lucide/svelte';\n  \n  interface Props {\n    option: WorkflowOption;\n    onSelect: () => void;\n    onModify: () => void;\n  }\n  \n  let { option, onSelect, onModify }: Props = $props();\n</script>\n\n<Card.Root class=\"cursor-pointer hover:border-primary transition-colors\" \n           class:border-primary={option.selected}>\n  <Card.Header>\n    <Card.Title class=\"flex items-center justify-between\">\n      {option.title}\n      {#if option.selected}<Check class=\"size-5 text-primary\" />{/if}\n    </Card.Title>\n  </Card.Header>\n  <Card.Content>\n    <p class=\"text-sm text-muted-foreground mb-3\">{option.description}</p>\n    <div class=\"flex flex-wrap gap-1 mb-3\">\n      {#each option.platforms as platform}\n        <Badge variant=\"secondary\">{platform}</Badge>\n      {/each}\n    </div>\n    <p class=\"text-xs text-muted-foreground\">Reach stimato: {option.estimatedReach}</p>\n  </Card.Content>\n  <Card.Footer class=\"flex gap-2\">\n    <Button size=\"sm\" variant=\"outline\" onclick={onModify}>\n      <Edit2 class=\"size-4 mr-1\" /> Modifica\n    </Button>\n    <Button size=\"sm\" onclick={onSelect}>Seleziona</Button>\n  </Card.Footer>\n</Card.Root>\n```\n\n## 4. RefinementChat.svelte\n\nChat iterativa per rifinitura (1-2 passaggi):\n\n```svelte\n<script lang=\"ts\">\n  import { Input } from '$lib/components/ui/input/index.js';\n  import { Button } from '$lib/components/ui/button/index.js';\n  import { ScrollArea } from '$lib/components/ui/scroll-area/index.js';\n  import { ideaStudioStore } from '$lib/stores/idea-studio.svelte';\n  \n  interface Props {\n    onApprove: (plan: WorkflowPlan) => void;\n  }\n  \n  let { onApprove }: Props = $props();\n  let userMessage = $state('');\n  \n  async function sendRefinement() {\n    // Chiamata a IDEA-VALIDATOR per raffinamento\n    const response = await refineWorkflow(userMessage, ideaStudioStore.current.selectedOption);\n    ideaStudioStore.addRefinement({ role: 'user', content: userMessage });\n    ideaStudioStore.addRefinement({ role: 'assistant', content: response.suggestion });\n    userMessage = '';\n  }\n</script>\n\n<!-- UI chat con history e suggestions per angles/tone/posizionamento -->\n```\n\n## 5. Integrazione IDEA-VALIDATOR Agent\n\nEstendere `python/team.yaml` per workflow options:\n\n```yaml\nidea_validator:\n  model: sonnet\n  instruction: |\n    # Esteso per Idea Studio\n    Quando ricevi un input (asset + brief):\n    1. Analizza contenuto e obiettivi\n    2. Genera 3-5 opzioni workflow con formati diversi\n    3. Per ogni opzione specifica: piattaforme, formati, reach stimato\n    4. Struttura output in JSON per card A2UI\n    \n    Durante rifinitura:\n    - Raccogli preferenze su angles (educativo, entertainment, promotional)\n    - Definisci posizionamento (es: thought leader, community, product showcase)\n    - Applica tone of voice specifico del brand (consulta RAG brand_guidelines)\n    \n    Output finale: JSON workflow plan completo per Creative Output\n  toolsets:\n    - type: mcp\n      command: npx\n      args: [\"-y\", \"@perplexity-ai/mcp-server\"]\n    - type: think\n    - type: memory\n      path: ./memory/idea_validator.db\n```\n\n## 6. Client TypeScript idea-validator-client.ts\n\n```typescript\nexport interface WorkflowPlan {\n  id: string;\n  createdAt: string;\n  input: IdeaInput;\n  selectedOption: WorkflowOption;\n  refinements: {\n    angles: string[];\n    positioning: string;\n    toneOfVoice: string;\n  };\n  contents: ContentPlan[];\n  schedule?: ScheduleHint[];\n}\n\nexport async function analyzeIdea(input: IdeaInput): Promise<WorkflowOption[]> {\n  const response = await fetch('http://localhost:8765/agent/execute', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n      agent: 'idea_validator',\n      action: 'generate_workflow_options',\n      payload: input\n    })\n  });\n  return response.json();\n}\n\nexport async function refineWorkflow(\n  message: string, \n  currentOption: WorkflowOption\n): Promise<RefinementResponse> {\n  // SSE streaming per risposta iterativa\n}\n\nexport async function approveWorkflow(plan: WorkflowPlan): Promise<void> {\n  // Salva in store e passa a Creative Output\n}\n```\n\n## 7. Workflow Plan JSON Schema\n\n```typescript\ninterface WorkflowPlan {\n  version: \"1.0\";\n  metadata: {\n    createdAt: string;\n    createdBy: \"idea_validator\";\n    brandId: string;\n  };\n  input: {\n    type: \"assets\" | \"upload\" | \"brief\";\n    assets?: string[];\n    briefText?: string;\n  };\n  selectedWorkflow: {\n    id: string;\n    title: string;\n    contents: Array<{\n      type: \"blog\" | \"video\" | \"reel\" | \"story\" | \"carousel\" | \"thread\";\n      platform: string;\n      format: { width: number; height: number; duration?: number };\n      priority: number;\n    }>;\n  };\n  creative: {\n    angles: string[];\n    positioning: string;\n    toneOfVoice: string;\n    keyMessages: string[];\n    hashtags?: string[];\n  };\n  status: \"draft\" | \"approved\" | \"in_production\";\n}\n```\n\n## 8. Pagina idea-studio/+page.svelte\n\n```svelte\n<script lang=\"ts\">\n  import { ideaStudioStore } from '$lib/stores/idea-studio.svelte';\n  import IdeaStudioInput from '$lib/components/custom/IdeaStudioInput.svelte';\n  import WorkflowOptionsGrid from '$lib/components/custom/WorkflowOptionsGrid.svelte';\n  import RefinementChat from '$lib/components/custom/RefinementChat.svelte';\n  import WorkflowPlanPreview from '$lib/components/custom/WorkflowPlanPreview.svelte';\n  import { goto } from '$app/navigation';\n  \n  function handleApprove(plan: WorkflowPlan) {\n    ideaStudioStore.approvePlan(plan);\n    // Passa a Creative Output con il plan approvato\n    goto('/creative-output?planId=' + plan.id);\n  }\n</script>\n\n<svelte:head>\n  <title>Idea Studio - Trae Extractor</title>\n</svelte:head>\n\n<div class=\"flex flex-col gap-6 py-4\">\n  {#if ideaStudioStore.current.status === 'idle'}\n    <IdeaStudioInput onSubmit={...} />\n  {:else if ideaStudioStore.current.status === 'options'}\n    <WorkflowOptionsGrid options={ideaStudioStore.current.workflowOptions} />\n  {:else if ideaStudioStore.current.status === 'refining'}\n    <RefinementChat onApprove={handleApprove} />\n  {:else if ideaStudioStore.current.status === 'approved'}\n    <WorkflowPlanPreview plan={ideaStudioStore.current.approvedPlan} />\n  {/if}\n</div>\n```\n\n## 9. Integrazione con Creative Planner (sotto il cofano)\n\nCreative Planner opera dietro le quinte:\n- Riceve il WorkflowPlan approvato\n- Genera execution plan dettagliato per Creative Worker\n- Nessuna UI dedicata, solo logging interno\n\n```python\n# In orchestrator o routing logic\nasync def handle_approved_workflow(plan: WorkflowPlan):\n    # Creative Planner genera piano esecutivo\n    execution_plan = await creative_planner.create_execution_plan(plan)\n    # Passa a Creative Output per visualizzazione\n    return execution_plan\n```",
        "testStrategy": "## Test Unitari TypeScript (Vitest)\n\n### 1. `src/lib/stores/__tests__/idea-studio.test.ts`\n- Test che `setInput()` aggiorni lo stato a 'analyzing'\n- Test che `setOptions()` popoli `workflowOptions` e imposti stato 'options'\n- Test che `selectOption()` marchi l'opzione corretta come selected\n- Test che `addRefinement()` aggiunga messaggi alla history\n- Test che `approvePlan()` salvi il piano e imposti stato 'approved'\n- Test reset dello store tra sessioni\n\n### 2. `src/lib/services/__tests__/idea-validator-client.test.ts`\n- Test `analyzeIdea()` con mock fetch che ritorni array di WorkflowOption\n- Test `refineWorkflow()` con SSE streaming simulato\n- Test `approveWorkflow()` che invii correttamente il JSON plan\n- Test gestione errori di rete e retry logic\n- Test timeout per chiamate lunghe\n\n### 3. Componenti Svelte (Testing Library)\n```typescript\n// IdeaStudioInput.svelte\n- Test rendering 3 tabs (assets, upload, brief)\n- Test drag-drop upload trigger callback\n- Test submit con brief testuale\n- Test selezione asset estratti\n\n// WorkflowOptionCard.svelte\n- Test rendering titolo, descrizione, badge piattaforme\n- Test click su \"Seleziona\" chiami onSelect\n- Test click su \"Modifica\" chiami onModify\n- Test stile visual diverso quando selected=true\n\n// RefinementChat.svelte\n- Test invio messaggio aggiunga alla history\n- Test bottone \"Approva\" visibile dopo 1+ raffinamenti\n- Test scroll automatico su nuovi messaggi\n```\n\n## Test Integrazione\n\n### 4. `tests/integration/idea-studio-flow.test.ts`\n- Test flusso completo: input → analisi → opzioni → selezione → rifinitura → approvazione\n- Test che il WorkflowPlan JSON finale abbia tutti i campi richiesti\n- Test navigazione a Creative Output con planId corretto\n- Test persistenza stato durante navigazione back/forward\n\n### 5. `python/tests/test_idea_validator_workflow.py`\n- Test endpoint `/agent/execute` con action `generate_workflow_options`\n- Test che le opzioni generate rispettino lo schema atteso\n- Test rifinitura iterativa con context preservation\n- Test integrazione RAG brand_guidelines nel tone of voice\n\n## Test E2E (Playwright)\n\n### 6. `tests/e2e/idea-studio.spec.ts`\n```typescript\ntest('complete idea studio workflow', async ({ page }) => {\n  await page.goto('/idea-studio');\n  \n  // Step 1: Input brief testuale\n  await page.click('[data-tab=\"brief\"]');\n  await page.fill('textarea', 'Lancio prodotto sostenibile per Gen Z');\n  await page.click('button:has-text(\"Analizza\")');\n  \n  // Step 2: Verifica opzioni workflow\n  await expect(page.locator('[data-testid=\"workflow-card\"]')).toHaveCount.greaterThan(1);\n  \n  // Step 3: Seleziona opzione\n  await page.click('[data-testid=\"workflow-card\"]:first-child button:has-text(\"Seleziona\")');\n  \n  // Step 4: Rifinitura\n  await page.fill('[data-testid=\"refinement-input\"]', 'Voglio un tono ironico e giovane');\n  await page.click('button:has-text(\"Invia\")');\n  await expect(page.locator('[data-testid=\"refinement-response\"]')).toBeVisible();\n  \n  // Step 5: Approvazione\n  await page.click('button:has-text(\"Approva Piano\")');\n  await expect(page).toHaveURL(/creative-output/);\n});\n\ntest('upload asset and generate options', async ({ page }) => {\n  // Test con file upload al volo\n});\n\ntest('use extracted assets from Extract tab', async ({ page }) => {\n  // Test con asset già estratti\n});\n```\n\n## Validazione Schema JSON\n\n### 7. `tests/unit/workflow-plan-schema.test.ts`\n- Test validazione JSON schema con Zod o AJV\n- Test che piani malformati vengano rifiutati\n- Test campi obbligatori presenti\n- Test enum values validi per type e platform",
        "status": "pending",
        "dependencies": [
          5,
          8,
          11,
          20
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 22,
        "title": "Creative Output Tab — Multi-Posizionamento con Editor Specializzati",
        "description": "Implementare la tab Creative Output che riceve workflow plan da Idea Studio e presenta sezioni UI verticali per ogni posizionamento (Video, Carousel, Immagine, Blog, Newsletter), con editor specializzati, bottone Kill per rimuovere posizionamenti, generazione draft via Creative Worker MCP e Design Compliance Check automatico.",
        "details": "## Struttura Directory\n\n```\nsrc/\n├── routes/\n│   └── creative-output/\n│       ├── +page.svelte              # Pagina principale Creative Output\n│       └── +page.ts                  # Load function per stato iniziale\n├── lib/\n│   ├── components/\n│   │   └── custom/\n│   │       ├── CreativeOutputPage.svelte     # Container principale\n│   │       ├── PositioningSection.svelte     # Sezione singolo posizionamento\n│   │       ├── KillButton.svelte             # Bottone rimozione posizionamento\n│   │       ├── editors/\n│   │       │   ├── VideoEditor.svelte        # Shotstack Studio SDK wrapper\n│   │       │   ├── CarouselEditor.svelte     # Multi-slide editor\n│   │       │   ├── ImageEditor.svelte        # Preview + editing tools\n│   │       │   ├── BlogEditor.svelte         # Rich text editor (TipTap/ProseMirror)\n│   │       │   └── NewsletterEditor.svelte   # Template editor email\n│   │       ├── DesignComplianceCheck.svelte  # UI feedback compliance\n│   │       └── AIChatPanel.svelte            # Chat AI per modifiche\n│   ├── stores/\n│   │   └── creative-output.svelte.ts   # Store Svelte 5 runes per stato\n│   └── services/\n│       ├── creative-worker-client.ts   # Client per Creative Worker MCP\n│       └── design-compliance.ts        # Validazione brand compliance\n```\n\n## 1. Store Svelte 5 Runes (`src/lib/stores/creative-output.svelte.ts`)\n\n```typescript\nimport type { WorkflowPlan, Positioning, CreativeOutput } from '$lib/types';\n\nexport type PositioningType = 'video_yt' | 'video_reel' | 'video_tiktok' | 'carousel' | 'collage' | 'image' | 'blog' | 'newsletter';\nexport type ComplianceStatus = 'pending' | 'checking' | 'passed' | 'failed' | 'warning';\n\nexport interface PositioningState {\n  id: string;\n  type: PositioningType;\n  draft: CreativeOutput | null;\n  isGenerating: boolean;\n  complianceStatus: ComplianceStatus;\n  complianceIssues: ComplianceIssue[];\n  isKilled: boolean;\n}\n\nlet workflowPlan = $state<WorkflowPlan | null>(null);\nlet positionings = $state<PositioningState[]>([]);\nlet activePositioningId = $state<string | null>(null);\nlet aiChatMessages = $state<ChatMessage[]>([]);\n\nexport const creativeOutputState = {\n  get workflowPlan() { return workflowPlan; },\n  get positionings() { return positionings.filter(p => !p.isKilled); },\n  get activePositioning() { return positionings.find(p => p.id === activePositioningId); },\n  \n  setWorkflowPlan: (plan: WorkflowPlan) => {\n    workflowPlan = plan;\n    positionings = plan.positionings.map(p => ({\n      id: crypto.randomUUID(),\n      type: p.type,\n      draft: null,\n      isGenerating: false,\n      complianceStatus: 'pending',\n      complianceIssues: [],\n      isKilled: false\n    }));\n  },\n  \n  killPositioning: (id: string) => {\n    const idx = positionings.findIndex(p => p.id === id);\n    if (idx !== -1) positionings[idx].isKilled = true;\n  },\n  \n  setDraft: (id: string, draft: CreativeOutput) => {\n    const idx = positionings.findIndex(p => p.id === id);\n    if (idx !== -1) positionings[idx].draft = draft;\n  },\n  \n  setComplianceResult: (id: string, status: ComplianceStatus, issues: ComplianceIssue[]) => {\n    const idx = positionings.findIndex(p => p.id === id);\n    if (idx !== -1) {\n      positionings[idx].complianceStatus = status;\n      positionings[idx].complianceIssues = issues;\n    }\n  }\n};\n```\n\n## 2. Componente PositioningSection (`src/lib/components/custom/PositioningSection.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { creativeOutputState } from '$lib/stores/creative-output.svelte';\n  import KillButton from './KillButton.svelte';\n  import DesignComplianceCheck from './DesignComplianceCheck.svelte';\n  import VideoEditor from './editors/VideoEditor.svelte';\n  import CarouselEditor from './editors/CarouselEditor.svelte';\n  import ImageEditor from './editors/ImageEditor.svelte';\n  import BlogEditor from './editors/BlogEditor.svelte';\n  import NewsletterEditor from './editors/NewsletterEditor.svelte';\n  import { Card, CardHeader, CardContent } from '$lib/components/ui/card';\n  import { Badge } from '$lib/components/ui/badge';\n  \n  interface Props {\n    positioning: PositioningState;\n  }\n  \n  let { positioning }: Props = $props();\n  \n  const editorMap: Record<PositioningType, Component> = {\n    video_yt: VideoEditor,\n    video_reel: VideoEditor,\n    video_tiktok: VideoEditor,\n    carousel: CarouselEditor,\n    collage: CarouselEditor,\n    image: ImageEditor,\n    blog: BlogEditor,\n    newsletter: NewsletterEditor\n  };\n  \n  function handleKill() {\n    creativeOutputState.killPositioning(positioning.id);\n  }\n</script>\n\n<Card class=\"mb-4 relative\">\n  <CardHeader class=\"flex flex-row items-center justify-between\">\n    <div class=\"flex items-center gap-2\">\n      <Badge variant=\"outline\">{positioning.type}</Badge>\n      <DesignComplianceCheck \n        status={positioning.complianceStatus} \n        issues={positioning.complianceIssues} \n      />\n    </div>\n    <KillButton onclick={handleKill} />\n  </CardHeader>\n  <CardContent>\n    {#if positioning.isGenerating}\n      <div class=\"flex items-center justify-center py-8\">\n        <Spinner />\n        <span class=\"ml-2\">Generazione draft in corso...</span>\n      </div>\n    {:else if positioning.draft}\n      <svelte:component \n        this={editorMap[positioning.type]} \n        draft={positioning.draft}\n        positioningId={positioning.id}\n      />\n    {:else}\n      <div class=\"text-center text-muted-foreground py-8\">\n        In attesa del draft dal Creative Worker...\n      </div>\n    {/if}\n  </CardContent>\n</Card>\n```\n\n## 3. Video Editor con Shotstack SDK (`src/lib/components/custom/editors/VideoEditor.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { onMount } from 'svelte';\n  import { Button } from '$lib/components/ui/button';\n  import { Tabs, TabsContent, TabsList, TabsTrigger } from '$lib/components/ui/tabs';\n  \n  interface Props {\n    draft: VideoCreativeOutput;\n    positioningId: string;\n  }\n  \n  let { draft, positioningId }: Props = $props();\n  let studioContainer: HTMLDivElement;\n  let studioInstance: any = $state(null);\n  \n  onMount(async () => {\n    // Carica Shotstack Studio SDK dinamicamente\n    const { ShotstackStudio } = await import('@shotstack/studio-sdk');\n    \n    studioInstance = new ShotstackStudio({\n      container: studioContainer,\n      apiKey: await window.electronAPI.getCredential('shotstack', 'api_key'),\n      timeline: draft.timeline,\n      onSave: async (updatedTimeline) => {\n        creativeOutputState.setDraft(positioningId, {\n          ...draft,\n          timeline: updatedTimeline\n        });\n        await runComplianceCheck(positioningId);\n      }\n    });\n  });\n  \n  async function renderPreview() {\n    const renderResult = await window.electronAPI.invokeAgent('creative_worker', {\n      action: 'render_preview',\n      timeline: studioInstance.getTimeline()\n    });\n    // Mostra preview video\n  }\n</script>\n\n<div class=\"space-y-4\">\n  <Tabs defaultValue=\"editor\">\n    <TabsList>\n      <TabsTrigger value=\"editor\">Editor</TabsTrigger>\n      <TabsTrigger value=\"preview\">Preview</TabsTrigger>\n    </TabsList>\n    <TabsContent value=\"editor\">\n      <div bind:this={studioContainer} class=\"min-h-[400px] border rounded-lg\" />\n    </TabsContent>\n    <TabsContent value=\"preview\">\n      <video src={draft.previewUrl} controls class=\"w-full rounded-lg\" />\n    </TabsContent>\n  </Tabs>\n  <div class=\"flex gap-2\">\n    <Button onclick={renderPreview}>Genera Preview</Button>\n    <Button variant=\"outline\">Esporta</Button>\n  </div>\n</div>\n```\n\n## 4. Design Compliance Check Service (`src/lib/services/design-compliance.ts`)\n\n```typescript\nimport { creativeOutputState } from '$lib/stores/creative-output.svelte';\n\nexport interface ComplianceIssue {\n  type: 'error' | 'warning';\n  rule: string;\n  message: string;\n  autoFixable: boolean;\n}\n\nexport interface ComplianceResult {\n  passed: boolean;\n  issues: ComplianceIssue[];\n}\n\nexport async function runComplianceCheck(positioningId: string): Promise<ComplianceResult> {\n  const positioning = creativeOutputState.positionings.find(p => p.id === positioningId);\n  if (!positioning?.draft) return { passed: false, issues: [] };\n  \n  creativeOutputState.setComplianceResult(positioningId, 'checking', []);\n  \n  try {\n    // Chiama RAG brand_guidelines tramite orchestrator\n    const result = await window.electronAPI.invokeAgent('orchestrator', {\n      action: 'check_design_compliance',\n      draft: positioning.draft,\n      positioningType: positioning.type\n    });\n    \n    const status = result.passed ? 'passed' : (result.issues.some(i => i.type === 'error') ? 'failed' : 'warning');\n    creativeOutputState.setComplianceResult(positioningId, status, result.issues);\n    \n    return result;\n  } catch (error) {\n    creativeOutputState.setComplianceResult(positioningId, 'failed', [{\n      type: 'error',\n      rule: 'system',\n      message: `Errore compliance check: ${error.message}`,\n      autoFixable: false\n    }]);\n    throw error;\n  }\n}\n\n// Trigger automatico prima di mostrare draft\nexport async function onDraftReceived(positioningId: string, draft: CreativeOutput): Promise<boolean> {\n  creativeOutputState.setDraft(positioningId, draft);\n  const result = await runComplianceCheck(positioningId);\n  return result.passed;\n}\n```\n\n## 5. Integrazione Creative Worker MCP (`src/lib/services/creative-worker-client.ts`)\n\n```typescript\nexport class CreativeWorkerClient {\n  async generateDraft(positioning: PositioningState, workflowPlan: WorkflowPlan): Promise<CreativeOutput> {\n    const response = await window.electronAPI.invokeAgent('creative_worker', {\n      action: 'generate_draft',\n      positioningType: positioning.type,\n      workflowPlan: workflowPlan,\n      brandContext: await this.getBrandContext()\n    });\n    \n    return response.draft;\n  }\n  \n  async applyAIEdit(positioningId: string, instruction: string): Promise<CreativeOutput> {\n    const positioning = creativeOutputState.positionings.find(p => p.id === positioningId);\n    \n    const response = await window.electronAPI.invokeAgent('creative_worker', {\n      action: 'apply_edit',\n      currentDraft: positioning?.draft,\n      instruction: instruction\n    });\n    \n    // Compliance check automatico dopo modifica\n    await onDraftReceived(positioningId, response.draft);\n    \n    return response.draft;\n  }\n  \n  private async getBrandContext() {\n    return window.electronAPI.invokeAgent('orchestrator', {\n      action: 'get_brand_context'\n    });\n  }\n}\n\nexport const creativeWorkerClient = new CreativeWorkerClient();\n```\n\n## 6. Pagina Principale (`src/routes/creative-output/+page.svelte`)\n\n```svelte\n<script lang=\"ts\">\n  import { onMount } from 'svelte';\n  import { creativeOutputState } from '$lib/stores/creative-output.svelte';\n  import PositioningSection from '$lib/components/custom/PositioningSection.svelte';\n  import AIChatPanel from '$lib/components/custom/AIChatPanel.svelte';\n  import { creativeWorkerClient } from '$lib/services/creative-worker-client';\n  import { Button } from '$lib/components/ui/button';\n  import { ScrollArea } from '$lib/components/ui/scroll-area';\n  \n  // Riceve workflowPlan da Idea Studio via navigation state o store\n  onMount(async () => {\n    // Se non c'è workflow plan, redirect a Idea Studio\n    if (!creativeOutputState.workflowPlan) {\n      // goto('/idea-studio');\n    }\n    \n    // Genera draft per ogni posizionamento\n    for (const positioning of creativeOutputState.positionings) {\n      if (!positioning.isKilled && !positioning.draft) {\n        positioning.isGenerating = true;\n        try {\n          const draft = await creativeWorkerClient.generateDraft(\n            positioning, \n            creativeOutputState.workflowPlan!\n          );\n          await onDraftReceived(positioning.id, draft);\n        } finally {\n          positioning.isGenerating = false;\n        }\n      }\n    }\n  });\n</script>\n\n<div class=\"flex h-full\">\n  <!-- Sezioni posizionamenti verticali -->\n  <ScrollArea class=\"flex-1 p-4\">\n    <h1 class=\"text-2xl font-bold mb-4\">Creative Output</h1>\n    \n    {#each creativeOutputState.positionings as positioning (positioning.id)}\n      <PositioningSection {positioning} />\n    {/each}\n    \n    {#if creativeOutputState.positionings.length === 0}\n      <div class=\"text-center text-muted-foreground py-16\">\n        Nessun posizionamento attivo. Torna a Idea Studio per creare un workflow.\n        <Button variant=\"link\" href=\"/idea-studio\">Vai a Idea Studio</Button>\n      </div>\n    {/if}\n  </ScrollArea>\n  \n  <!-- Panel chat AI laterale -->\n  <aside class=\"w-96 border-l\">\n    <AIChatPanel />\n  </aside>\n</div>\n```\n\n## 7. Dipendenze da Installare\n\n```bash\n# Rich text editor per Blog\npnpm add @tiptap/core @tiptap/svelte @tiptap/starter-kit @tiptap/extension-image\n\n# Shotstack Studio SDK (se disponibile come npm package, altrimenti via CDN)\n# Verificare docs: https://shotstack.io/docs/studio/\n```\n\n## 8. Aggiornare AppSidebar.svelte\n\nAggiungere la route Creative Output nell'array `routes` (già previsto in Task 20).",
        "testStrategy": "## Test Unitari TypeScript (Vitest)\n\n### 1. `src/lib/stores/__tests__/creative-output.test.ts`\n- Test che `setWorkflowPlan()` inizializzi correttamente i posizionamenti dallo workflow plan\n- Test che `killPositioning()` imposti `isKilled: true` e venga filtrato dal getter `positionings`\n- Test che `setDraft()` aggiorni il draft del posizionamento corretto\n- Test che `setComplianceResult()` aggiorni status e issues correttamente\n- Test reattività: verificare che le modifiche allo store si propaghino ai componenti\n\n### 2. `src/lib/services/__tests__/design-compliance.test.ts`\n- Test `runComplianceCheck()` con mock agent che ritorna passed: true\n- Test `runComplianceCheck()` con mock agent che ritorna issues di tipo error\n- Test `runComplianceCheck()` con mock agent che ritorna issues di tipo warning\n- Test che lo stato cambi a 'checking' durante l'esecuzione\n- Test gestione errore quando l'agent fallisce\n- Test `onDraftReceived()` che triggera automaticamente il compliance check\n\n### 3. `src/lib/services/__tests__/creative-worker-client.test.ts`\n- Test `generateDraft()` chiami l'agent con i parametri corretti\n- Test `applyAIEdit()` applichi la modifica e triggeri compliance check\n- Test gestione errori e retry logic\n\n## Test Componenti (Vitest + Testing Library)\n\n### 4. `src/lib/components/custom/__tests__/PositioningSection.test.ts`\n- Test rendering con positioning in stato 'generating'\n- Test rendering con draft presente (mostra editor corretto)\n- Test rendering senza draft (stato attesa)\n- Test click KillButton rimuove il posizionamento\n- Test che DesignComplianceCheck mostri lo stato corretto\n\n### 5. `src/lib/components/custom/__tests__/KillButton.test.ts`\n- Test rendering icona X o Trash\n- Test conferma prima di kill (dialog)\n- Test emissione evento onclick\n\n### 6. `src/lib/components/custom/__tests__/DesignComplianceCheck.test.ts`\n- Test badge verde per status 'passed'\n- Test badge giallo per status 'warning'\n- Test badge rosso per status 'failed'\n- Test spinner per status 'checking'\n- Test tooltip con lista issues\n\n## Test E2E (Playwright)\n\n### 7. `tests/e2e/creative-output.spec.ts`\n- Test navigazione da Idea Studio a Creative Output con workflow plan\n- Test redirect a Idea Studio se manca workflow plan\n- Test generazione draft automatica per ogni posizionamento\n- Test kill di un posizionamento e rimozione dalla lista\n- Test modifica via chat AI e aggiornamento draft\n- Test compliance check badge si aggiorna dopo modifica\n\n## Test Integrazione\n\n### 8. Test IPC per Creative Worker\n- Test chiamata `invokeAgent('creative_worker', ...)` con mock sidecar\n- Test SSE streaming durante generazione draft\n- Test timeout handling per generazioni lunghe\n\n## Verifica Manuale\n\n### Pre-PR Checklist\n- [ ] Avviare app con `pnpm run dev`\n- [ ] Navigare a Creative Output dopo aver completato workflow in Idea Studio\n- [ ] Verificare che ogni posizionamento generi un draft\n- [ ] Verificare che il compliance check venga eseguito prima di mostrare il draft\n- [ ] Testare kill di un posizionamento\n- [ ] Testare modifica via editor integrato (video, carousel, immagine)\n- [ ] Testare modifica via chat AI\n- [ ] Verificare responsive design su viewport diverse",
        "status": "pending",
        "dependencies": [
          7,
          21
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 23,
        "title": "Integrazione Shotstack Studio SDK + MCP Server",
        "description": "Integrate Shotstack Studio SDK for video editing with Brand Elements Kit templates and cloud rendering.",
        "details": "Install Shotstack Studio, embed in Svelte, configure MCP, load templates, implement event bridge, handle cloud rendering and local caching.",
        "status": "pending",
        "dependencies": [
          5,
          7
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 5,
        "recommendedSubtasks": 5
      },
      {
        "id": 24,
        "title": "Design Compliance Agent (Visual QA Automatico)",
        "description": "Implement automated design compliance checking with programmatic and vision AI layers for visual quality assurance.",
        "details": "Create design-compliance-checker cagent with fast programmatic checks (resolution, colors, logo, text) and vision AI for complex cases.",
        "status": "pending",
        "dependencies": [
          5,
          8,
          26
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 6,
        "recommendedSubtasks": 5
      },
      {
        "id": 25,
        "title": "Brand Elements Kit -- Folder Structure + Asset Management UI",
        "description": "Restructure brand folders with knowledge (RAG) and elements (graphics) separation with asset management UI.",
        "details": "Create python/brands/{brand-slug}/ structure with knowledge/ and elements/ folders. Implement asset UI in Brands tab. Auto-extract color palette.",
        "status": "pending",
        "dependencies": [
          12
        ],
        "priority": "medium",
        "subtasks": [],
        "complexity": 5,
        "recommendedSubtasks": 5
      },
      {
        "id": 26,
        "title": "Arricchimento platforms.md -- SOP + Piattaforme Mancanti",
        "description": "Move platforms.md to shared location, add missing platforms, document SOPs, checklists, fallbacks, EXIF specs.",
        "details": "Move to python/knowledge/platforms.md. Add Shopify, Meta Ads, Google Ads, Klaviyo, LinkedIn, X/Twitter with SOPs and specs.",
        "status": "pending",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [],
        "complexity": 4,
        "recommendedSubtasks": 5
      },
      {
        "id": 27,
        "title": "Chat AI Persistente Cross-Tab con Thread Unico",
        "description": "Implement persistent AI chat panel with single thread across all tabs, tab-aware routing, and streaming responses.",
        "details": "Create bottom chat panel with persistent state. Tab-aware context routing to appropriate agents. SSE streaming for real-time responses.",
        "status": "pending",
        "dependencies": [
          5,
          19,
          11
        ],
        "priority": "high",
        "subtasks": [],
        "complexity": 5,
        "recommendedSubtasks": 5
      },
      {
        "id": 28,
        "title": "Integrazione Canva MCP (Opzionale per Power User)",
        "description": "Optional Canva MCP integration for power users as alternative to in-app pipeline. Post-MVP feature.",
        "details": "Toggle-able Canva MCP integration for Creative Worker. Falls back to Shotstack + Cloudinary if unavailable or disabled.",
        "status": "pending",
        "dependencies": [
          5,
          23
        ],
        "priority": "low",
        "subtasks": [],
        "complexity": 4,
        "recommendedSubtasks": 5
      }
    ],
    "metadata": {
      "version": "1.0.0",
      "lastModified": "2026-02-07T11:42:59.318Z",
      "taskCount": 28,
      "completedCount": 6,
      "tags": [
        "master"
      ],
      "created": "2026-02-07T11:43:09.753Z",
      "description": "Tasks for master context",
      "updated": "2026-02-07T11:58:10.803Z"
    }
  }
}